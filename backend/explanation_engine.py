# backend/explanation_engine.py
import numpy as np
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass, field
from enum import Enum
import math
import re


class ExplanationLevel(Enum):
    """èª¬æ˜ãƒ¬ãƒ™ãƒ«"""
    BASIC = "basic"           # åŸºæœ¬çš„ãªèª¬æ˜
    DETAILED = "detailed"     # è©³ç´°ãªèª¬æ˜
    EXPERT = "expert"         # å°‚é–€çš„ãªèª¬æ˜
    USER_FRIENDLY = "user_friendly"  # ä¸€èˆ¬ãƒ¦ãƒ¼ã‚¶ãƒ¼å‘ã‘


class CertaintyLevel(Enum):
    """ç¢ºä¿¡åº¦ãƒ¬ãƒ™ãƒ«"""
    VERY_HIGH = "very_high"   # 90%+
    HIGH = "high"             # 75-90%
    MEDIUM = "medium"         # 50-75%
    LOW = "low"               # 25-50%
    VERY_LOW = "very_low"     # <25%


@dataclass
class ExplanationComponent:
    """èª¬æ˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ"""
    type: str                           # 'decision', 'feature', 'confidence', 'comparison'
    content: str                        # èª¬æ˜æ–‡
    confidence: float                   # ä¿¡é ¼åº¦
    importance: float                   # é‡è¦åº¦
    technical_details: Dict = field(default_factory=dict)
    visual_aids: List[str] = field(default_factory=list)


@dataclass
class DecisionExplanation:
    """æ±ºå®šèª¬æ˜"""
    overall_conclusion: str             # å…¨ä½“çµè«–
    confidence_level: CertaintyLevel   # ç¢ºä¿¡åº¦ãƒ¬ãƒ™ãƒ«
    components: List[ExplanationComponent] = field(default_factory=list)
    reasoning_chain: List[str] = field(default_factory=list)
    alternative_scenarios: List[str] = field(default_factory=list)
    caveats: List[str] = field(default_factory=list)
    recommendations: List[str] = field(default_factory=list)


class FuzzyExplanationEngine:
    """ãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨èª¬æ˜ã‚¨ãƒ³ã‚¸ãƒ³"""

    def __init__(self, language: str = "ja", explanation_level: ExplanationLevel = ExplanationLevel.USER_FRIENDLY):
        self.language = language
        self.explanation_level = explanation_level

        # èª¬æ˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
        self.templates = self._load_explanation_templates()

        # åŸºæº–ãƒ©ãƒ™ãƒ«
        self.criteria_info = {
            'research_intensity': {
                'name_ja': 'ç ”ç©¶å¼·åº¦',
                'name_en': 'Research Intensity',
                'description_ja': 'ç ”ç©¶æ´»å‹•ã®é›†ä¸­åº¦ãƒ»æœ€å…ˆç«¯æ€§',
                'scale_labels_ja': {1: 'åŸºç¤çš„', 5: 'æ¨™æº–çš„', 10: 'æœ€å…ˆç«¯'},
                'importance_keywords': ['é©æ–°çš„', 'å…ˆç«¯æŠ€è¡“', 'ç ”ç©¶é›†ç´„', 'å­¦è¡“æ€§']
            },
            'advisor_style': {
                'name_ja': 'æŒ‡å°ã‚¹ã‚¿ã‚¤ãƒ«',
                'name_en': 'Advisor Style',
                'description_ja': 'æ•™æˆã®æŒ‡å°æ–¹é‡ãƒ»ã‚¢ãƒ—ãƒ­ãƒ¼ãƒ',
                'scale_labels_ja': {1: 'å³æ ¼', 5: 'ãƒãƒ©ãƒ³ã‚¹', 10: 'è‡ªç”±'},
                'importance_keywords': ['ãƒ¡ãƒ³ã‚¿ãƒ¼ã‚·ãƒƒãƒ—', 'è‡ªä¸»æ€§', 'æŒ‡å°å¯†åº¦', 'è‡ªç”±åº¦']
            },
            'team_work': {
                'name_ja': 'ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯',
                'name_en': 'Team Work',
                'description_ja': 'ç ”ç©¶ã§ã®å”åƒãƒ»é€£æºã®åº¦åˆã„',
                'scale_labels_ja': {1: 'å€‹äººç ”ç©¶', 5: 'æ··åˆ', 10: 'ãƒãƒ¼ãƒ ç ”ç©¶'},
                'importance_keywords': ['å”åƒ', 'é€£æº', 'ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³', 'å…±åŒç ”ç©¶']
            },
            'workload': {
                'name_ja': 'ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰',
                'name_en': 'Workload',
                'description_ja': 'ç ”ç©¶ã®è² è·ãƒ»å¿™ã—ã•ã®ç¨‹åº¦',
                'scale_labels_ja': {1: 'è»½ã„', 5: 'é©åº¦', 10: 'é‡ã„'},
                'importance_keywords': ['è² è·', 'æ™‚é–“æŠ•å…¥', 'é›†ä¸­åº¦', 'å¿™ã—ã•']
            },
            'theory_practice': {
                'name_ja': 'ç†è«–ãƒ»å®Ÿè·µãƒãƒ©ãƒ³ã‚¹',
                'name_en': 'Theory-Practice Balance',
                'description_ja': 'ç†è«–ç ”ç©¶ã¨å®Ÿè·µçš„ç ”ç©¶ã®æ¯”é‡',
                'scale_labels_ja': {1: 'ç†è«–é‡è¦–', 5: 'ãƒãƒ©ãƒ³ã‚¹', 10: 'å®Ÿè·µé‡è¦–'},
                'importance_keywords': ['å¿œç”¨æ€§', 'å®Ÿè£…', 'ç†è«–çš„æ·±åº¦', 'å®Ÿç”¨æ€§']
            }
        }

        # ä¿¡é ¼åº¦è¡¨ç¾
        self.confidence_expressions = self._get_confidence_expressions()

    def generate_comprehensive_explanation(self,
                                           prediction_result: Dict[str, Any],
                                           lab_info: Dict[str, Any],
                                           user_preferences: Dict[str, float],
                                           decision_steps: List[Dict] = None) -> DecisionExplanation:
        """åŒ…æ‹¬çš„èª¬æ˜ç”Ÿæˆ"""

        overall_score = prediction_result.get('overall_score', 0.0)
        confidence = prediction_result.get('confidence', 0.0)
        criterion_scores = prediction_result.get('criterion_scores', {})

        # ç¢ºä¿¡åº¦ãƒ¬ãƒ™ãƒ«æ±ºå®š
        confidence_level = self._determine_confidence_level(confidence)

        # èª¬æ˜ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆç”Ÿæˆ
        components = []

        # 1. å…¨ä½“è©•ä¾¡èª¬æ˜
        overall_component = self._generate_overall_assessment(
            overall_score, confidence, lab_info['name']
        )
        components.append(overall_component)

        # 2. åŸºæº–åˆ¥è©³ç´°èª¬æ˜
        criteria_components = self._generate_criteria_explanations(
            criterion_scores, user_preferences, lab_info
        )
        components.extend(criteria_components)

        # 3. æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹èª¬æ˜
        if decision_steps:
            process_component = self._generate_process_explanation(
                decision_steps)
            components.append(process_component)

        # 4. æ¯”è¼ƒãƒ»ä»£æ›¿æ¡ˆ
        comparison_component = self._generate_comparison_insights(
            criterion_scores, user_preferences
        )
        components.append(comparison_component)

        # æ¨è«–ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰
        reasoning_chain = self._build_reasoning_chain(
            components, criterion_scores)

        # ä»£æ›¿ã‚·ãƒŠãƒªã‚ª
        alternative_scenarios = self._generate_alternative_scenarios(
            user_preferences, criterion_scores, overall_score
        )

        # æ³¨æ„ç‚¹ãƒ»åˆ¶ç´„
        caveats = self._generate_caveats(confidence, criterion_scores)

        # æ¨å¥¨äº‹é …
        recommendations = self._generate_recommendations(
            overall_score, criterion_scores, lab_info
        )

        # å…¨ä½“çµè«–ç”Ÿæˆ
        overall_conclusion = self._generate_overall_conclusion(
            overall_score, confidence_level, lab_info['name']
        )

        return DecisionExplanation(
            overall_conclusion=overall_conclusion,
            confidence_level=confidence_level,
            components=components,
            reasoning_chain=reasoning_chain,
            alternative_scenarios=alternative_scenarios,
            caveats=caveats,
            recommendations=recommendations
        )

    def _generate_overall_assessment(self, score: float, confidence: float, lab_name: str) -> ExplanationComponent:
        """å…¨ä½“è©•ä¾¡èª¬æ˜ç”Ÿæˆ"""

        # ã‚¹ã‚³ã‚¢è©•ä¾¡
        if score >= 85:
            score_description = "éå¸¸ã«é«˜ã„é©åˆåº¦"
            score_emoji = "ğŸ¯"
        elif score >= 70:
            score_description = "é«˜ã„é©åˆåº¦"
            score_emoji = "âœ…"
        elif score >= 55:
            score_description = "è‰¯å¥½ãªé©åˆåº¦"
            score_emoji = "ğŸ‘"
        elif score >= 40:
            score_description = "ä¸­ç¨‹åº¦ã®é©åˆåº¦"
            score_emoji = "âš ï¸"
        else:
            score_description = "ä½ã„é©åˆåº¦"
            score_emoji = "âŒ"

        # ä¿¡é ¼åº¦è¡¨ç¾
        confidence_text = self.confidence_expressions[self._determine_confidence_level(
            confidence)]

        content = f"{score_emoji} **{lab_name}**ã¨ã®é©åˆåº¦ã¯{score:.1f}ç‚¹ã§ã€{score_description}ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚\n\n" \
            f"ã“ã®çµæœã¯{confidence_text}ã§ç®—å‡ºã•ã‚Œã¦ãŠã‚Šã€" \
            f"ãƒ•ã‚¡ã‚¸ã‚£è«–ç†ã«ã‚ˆã‚‹å¤šé¢çš„åˆ†æã«åŸºã¥ã„ã¦ã„ã¾ã™ã€‚"

        return ExplanationComponent(
            type="overall_assessment",
            content=content,
            confidence=confidence,
            importance=1.0,
            technical_details={
                'score': score,
                'confidence': confidence,
                'assessment_method': 'fuzzy_logic_multi_criteria'
            }
        )

    def _generate_criteria_explanations(self, criterion_scores: Dict[str, Any],
                                        user_preferences: Dict[str, float],
                                        lab_info: Dict[str, Any]) -> List[ExplanationComponent]:
        """åŸºæº–åˆ¥èª¬æ˜ç”Ÿæˆ"""

        components = []

        # åŸºæº–ã‚’é‡è¦åº¦é †ã«ã‚½ãƒ¼ãƒˆ
        sorted_criteria = sorted(
            criterion_scores.items(),
            key=lambda x: x[1].get('weighted_score', 0.0),
            reverse=True
        )

        for criterion, score_data in sorted_criteria:
            if criterion not in self.criteria_info:
                continue

            criterion_info = self.criteria_info[criterion]
            similarity = score_data.get('similarity', 0.0)
            user_val = score_data.get('user_preference', 0.0)
            lab_val = score_data.get('lab_feature', 0.0)
            weight = score_data.get('weight', 0.0)

            # é©åˆåº¦è©•ä¾¡
            if similarity >= 0.8:
                match_level = "éå¸¸ã«ã‚ˆã"
                match_emoji = "ğŸ¯"
            elif similarity >= 0.6:
                match_level = "ã‚ˆã"
                match_emoji = "âœ…"
            elif similarity >= 0.4:
                match_level = "ã‚ã‚‹ç¨‹åº¦"
                match_emoji = "ğŸ‘"
            else:
                match_level = "ã‚ã¾ã‚Š"
                match_emoji = "âš ï¸"

            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ»ç ”ç©¶å®¤å€¤ã®è¡¨ç¾
            user_label = self._get_scale_label(criterion, user_val)
            lab_label = self._get_scale_label(criterion, lab_val)

            # å·®ç•°åˆ†æ
            difference = abs(user_val - lab_val)
            if difference <= 1.0:
                difference_desc = "ã»ã¼ä¸€è‡´"
            elif difference <= 2.0:
                difference_desc = "è¿‘ã„å€¤"
            elif difference <= 3.0:
                difference_desc = "ã‚„ã‚„ç•°ãªã‚‹"
            else:
                difference_desc = "å¤§ããç•°ãªã‚‹"

            # èª¬æ˜æ–‡ç”Ÿæˆ
            content = f"{match_emoji} **{criterion_info['name_ja']}**\n\n" \
                f"ã‚ãªãŸã®å¸Œæœ›: {user_val:.1f} ({user_label}) | " \
                f"ç ”ç©¶å®¤ã®ç‰¹å¾´: {lab_val:.1f} ({lab_label})\n\n" \
                f"ã“ã®åŸºæº–ã§ã¯{match_level}ãƒãƒƒãƒã—ã¦ã„ã¾ã™ï¼ˆé¡ä¼¼åº¦: {similarity:.2f}ï¼‰ã€‚" \
                f"ä¸¡è€…ã®å€¤ã¯{difference_desc}ã§ã€{criterion_info['description_ja']}ã®è¦³ç‚¹ã‹ã‚‰" \
                f"{'é©åˆæ€§ãŒé«˜ã„' if similarity >= 0.6 else 'æ¤œè¨ãŒå¿…è¦'}ã¨ã„ãˆã¾ã™ã€‚"

            # é‡è¦åº¦ã«å¿œã˜ãŸè¿½åŠ èª¬æ˜
            if weight >= 0.25:  # é‡è¦ãªåŸºæº–
                content += f"\n\nğŸ’¡ ã“ã®åŸºæº–ã¯å…¨ä½“è©•ä¾¡ã«ãŠã„ã¦é‡è¦ãªè¦å› ï¼ˆé‡ã¿: {weight:.1%}ï¼‰ã¨ãªã£ã¦ã„ã¾ã™ã€‚"

            components.append(ExplanationComponent(
                type="criteria_analysis",
                content=content,
                confidence=similarity,
                importance=weight,
                technical_details={
                    'criterion': criterion,
                    'similarity': similarity,
                    'user_preference': user_val,
                    'lab_feature': lab_val,
                    'weight': weight,
                    'difference': difference
                }
            ))

        return components

    def _generate_process_explanation(self, decision_steps: List[Dict]) -> ExplanationComponent:
        """æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹èª¬æ˜ç”Ÿæˆ"""

        if not decision_steps:
            return ExplanationComponent(
                type="process_explanation",
                content="æ±ºå®šãƒ—ãƒ­ã‚»ã‚¹ã®è©³ç´°æƒ…å ±ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚",
                confidence=0.0,
                importance=0.3
            )

        # ä¸»è¦ãªæ±ºå®šã‚¹ãƒ†ãƒƒãƒ—æŠ½å‡º
        key_steps = [step for step in decision_steps if step.get(
            'confidence', 0) > 0.5]

        if not key_steps:
            key_steps = decision_steps[:3]  # ä¸Šä½3ã‚¹ãƒ†ãƒƒãƒ—

        process_description = "ğŸ§  **AIæ±ºå®šãƒ—ãƒ­ã‚»ã‚¹**\n\n"
        process_description += "ãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨ã«ã‚ˆã‚‹æ®µéšçš„åˆ†æ:\n\n"

        for i, step in enumerate(key_steps, 1):
            feature_name = step.get('feature_name', 'unknown')
            feature_value = step.get('feature_value', 0.0)
            chosen_branch = step.get('chosen_branch', 'unknown')
            confidence = step.get('confidence', 0.0)

            if feature_name in self.criteria_info:
                feature_display = self.criteria_info[feature_name]['name_ja']
            else:
                feature_display = feature_name

            process_description += f"{i}. {feature_display} = {feature_value:.1f} â†’ {chosen_branch} " \
                f"(ä¿¡é ¼åº¦: {confidence:.2f})\n"

        process_description += f"\nå„æ®µéšã§ã®ãƒ•ã‚¡ã‚¸ã‚£ãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—é–¢æ•°ã«ã‚ˆã‚Šã€" \
            f"ã‚ã„ã¾ã„ã•ã‚’è€ƒæ…®ã—ãŸæŸ”è»Ÿãªåˆ¤æ–­ã‚’å®Ÿç¾ã—ã¦ã„ã¾ã™ã€‚"

        return ExplanationComponent(
            type="process_explanation",
            content=process_description,
            confidence=np.mean([step.get('confidence', 0)
                               for step in key_steps]),
            importance=0.6,
            technical_details={
                'decision_steps': decision_steps,
                'key_steps_count': len(key_steps)
            }
        )

    def _generate_comparison_insights(self, criterion_scores: Dict[str, Any],
                                      user_preferences: Dict[str, float]) -> ExplanationComponent:
        """æ¯”è¼ƒãƒ»æ´å¯Ÿèª¬æ˜ç”Ÿæˆ"""

        # å¼·ã¿ãƒ»å¼±ã¿åˆ†æ
        strengths = []
        weaknesses = []

        for criterion, score_data in criterion_scores.items():
            similarity = score_data.get('similarity', 0.0)

            if criterion in self.criteria_info:
                criterion_name = self.criteria_info[criterion]['name_ja']

                if similarity >= 0.7:
                    strengths.append(criterion_name)
                elif similarity < 0.5:
                    weaknesses.append(criterion_name)

        content = "ğŸ“Š **é©åˆæ€§åˆ†æ**\n\n"

        if strengths:
            content += f"**âœ… ç‰¹ã«é©åˆã—ã¦ã„ã‚‹é ˜åŸŸ:** {', '.join(strengths)}\n\n"

        if weaknesses:
            content += f"**âš ï¸ æ³¨æ„ãŒå¿…è¦ãªé ˜åŸŸ:** {', '.join(weaknesses)}\n\n"

        # ãƒãƒ©ãƒ³ã‚¹åˆ†æ
        score_values = [score_data.get('similarity', 0.0)
                        for score_data in criterion_scores.values()]
        score_variance = np.var(score_values)

        if score_variance < 0.05:
            balance_desc = "å„åŸºæº–ã«ãŠã„ã¦éå¸¸ã«ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸé©åˆæ€§"
        elif score_variance < 0.1:
            balance_desc = "æ¦‚ã­ãƒãƒ©ãƒ³ã‚¹ã®å–ã‚ŒãŸé©åˆæ€§"
        else:
            balance_desc = "åŸºæº–é–“ã§ã°ã‚‰ã¤ãã®ã‚ã‚‹é©åˆæ€§"

        content += f"**âš–ï¸ ç·åˆãƒãƒ©ãƒ³ã‚¹:** {balance_desc}ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚"

        # æ”¹å–„ææ¡ˆ
        if weaknesses:
            content += f"\n\nğŸ’¡ {', '.join(weaknesses[:2])}ã«ã¤ã„ã¦ã¯ã€" \
                f"ç ”ç©¶å®¤è¦‹å­¦ã‚„æ•™æˆã¨ã®é¢è«‡ã§è©³ç´°ã‚’ç¢ºèªã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"

        return ExplanationComponent(
            type="comparison_insights",
            content=content,
            confidence=1.0 - score_variance,  # åˆ†æ•£ãŒå°ã•ã„ã»ã©ä¿¡é ¼åº¦é«˜
            importance=0.7,
            technical_details={
                'strengths': strengths,
                'weaknesses': weaknesses,
                'score_variance': score_variance
            }
        )

    def _build_reasoning_chain(self, components: List[ExplanationComponent],
                               criterion_scores: Dict[str, Any]) -> List[str]:
        """æ¨è«–ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰"""

        chain = []

        # å‰æ
        chain.append("ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å¸Œæœ›æ¡ä»¶ã¨ç ”ç©¶å®¤ã®ç‰¹å¾´ã‚’å¤šåŸºæº–ã§åˆ†æ")

        # ä¸»è¦åŸºæº–ã®æ¨è«–
        sorted_criteria = sorted(
            criterion_scores.items(),
            key=lambda x: x[1].get('weighted_score', 0.0),
            reverse=True
        )

        for criterion, score_data in sorted_criteria[:3]:  # ä¸Šä½3åŸºæº–
            if criterion in self.criteria_info:
                similarity = score_data.get('similarity', 0.0)
                criterion_name = self.criteria_info[criterion]['name_ja']

                if similarity >= 0.7:
                    chain.append(f"{criterion_name}ã§é«˜ã„é©åˆæ€§ã‚’ç¢ºèª")
                elif similarity >= 0.5:
                    chain.append(f"{criterion_name}ã§é©åº¦ãªé©åˆæ€§ã‚’ç¢ºèª")
                else:
                    chain.append(f"{criterion_name}ã§é©åˆæ€§ã®èª²é¡Œã‚’è­˜åˆ¥")

        # çµ±åˆåˆ¤æ–­
        chain.append("ãƒ•ã‚¡ã‚¸ã‚£è«–ç†ã«ã‚ˆã‚‹é‡ã¿ä»˜ãçµ±åˆã§ç·åˆé©åˆåº¦ã‚’ç®—å‡º")

        # çµè«–
        overall_score = np.mean([score_data.get('similarity', 0.0)
                                for score_data in criterion_scores.values()])
        if overall_score >= 0.7:
            chain.append("é«˜ã„é©åˆåº¦ã«ã‚ˆã‚Šæ¨å¥¨åˆ¤å®š")
        elif overall_score >= 0.5:
            chain.append("é©åº¦ãªé©åˆåº¦ã«ã‚ˆã‚Šæ¡ä»¶ä»˜ãæ¨å¥¨")
        else:
            chain.append("ä½ã„é©åˆåº¦ã«ã‚ˆã‚Šæ…é‡æ¤œè¨ã‚’æ¨å¥¨")

        return chain

    def _generate_alternative_scenarios(self, user_preferences: Dict[str, float],
                                        criterion_scores: Dict[str, Any],
                                        current_score: float) -> List[str]:
        """ä»£æ›¿ã‚·ãƒŠãƒªã‚ªç”Ÿæˆ"""

        scenarios = []

        # å¸Œæœ›èª¿æ•´ã‚·ãƒŠãƒªã‚ª
        for criterion, score_data in criterion_scores.items():
            similarity = score_data.get('similarity', 0.0)

            if similarity < 0.5 and criterion in self.criteria_info:
                criterion_name = self.criteria_info[criterion]['name_ja']
                user_val = score_data.get('user_preference', 0.0)
                lab_val = score_data.get('lab_feature', 0.0)

                if user_val > lab_val:
                    direction = "ä¸‹ã’ã‚‹"
                else:
                    direction = "ä¸Šã’ã‚‹"

                scenarios.append(
                    f"{criterion_name}ã®å¸Œæœ›ã‚’{direction}ã“ã¨ã§ã€"
                    f"é©åˆåº¦ãŒç´„{(0.7 - similarity) * 100:.0f}ç‚¹å‘ä¸Šã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
                )

        # é‡ã¿èª¿æ•´ã‚·ãƒŠãƒªã‚ª
        if len(scenarios) < 3:
            scenarios.append(
                f"åŸºæº–ã®é‡è¦åº¦ã‚’èª¿æ•´ã™ã‚‹ã“ã¨ã§ã€"
                f"æœ€å¤§{(100 - current_score) * 0.3:.0f}ç‚¹ç¨‹åº¦ã®é©åˆåº¦å‘ä¸ŠãŒæœŸå¾…ã§ãã¾ã™"
            )

        # ä»–ã®é¸æŠè‚¢ç¤ºå”†
        if current_score < 70:
            scenarios.append(
                "è¤‡æ•°ã®ç ”ç©¶å®¤ã‚’æ¯”è¼ƒæ¤œè¨ã—ã€"
                "ã‚ˆã‚Šé©åˆåº¦ã®é«˜ã„é¸æŠè‚¢ã‚’æ¢ã™ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™"
            )

        return scenarios[:3]  # æœ€å¤§3ã¤ã¾ã§

    def _generate_caveats(self, confidence: float, criterion_scores: Dict[str, Any]) -> List[str]:
        """æ³¨æ„ç‚¹ãƒ»åˆ¶ç´„ç”Ÿæˆ"""

        caveats = []

        # ä¿¡é ¼åº¦ã«åŸºã¥ãæ³¨æ„ç‚¹
        if confidence < 0.6:
            caveats.append(
                "ä¿¡é ¼åº¦ãŒä¸­ç¨‹åº¦ã®ãŸã‚ã€è¿½åŠ æƒ…å ±ã«ã‚ˆã‚‹æ¤œè¨¼ã‚’ãŠå‹§ã‚ã—ã¾ã™"
            )

        # ãƒ‡ãƒ¼ã‚¿åˆ¶ç´„
        caveats.append(
            "ã“ã®åˆ†æã¯ç¾åœ¨åˆ©ç”¨å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ãŠã‚Šã€"
            "å®Ÿéš›ã®ç ”ç©¶ç’°å¢ƒã¯å¤‰å‹•ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™"
        )

        # å€‹äººå·®
        caveats.append(
            "ç ”ç©¶å®¤é©åˆæ€§ã¯å€‹äººã®ä¾¡å€¤è¦³ã‚„ç›®æ¨™ã«ã‚ˆã‚Šå¤§ããå·¦å³ã•ã‚Œã‚‹ãŸã‚ã€"
            "æœ€çµ‚åˆ¤æ–­ã¯ç·åˆçš„ã«è¡Œã£ã¦ãã ã•ã„"
        )

        # æ™‚é–“çš„åˆ¶ç´„
        if any(score_data.get('similarity', 0.0) < 0.4 for score_data in criterion_scores.values()):
            caveats.append(
                "ä¸€éƒ¨åŸºæº–ã§é©åˆæ€§ãŒä½ã„ãŸã‚ã€"
                "å°†æ¥çš„ãªé©å¿œå¯èƒ½æ€§ã‚‚è€ƒæ…®ã—ã¦åˆ¤æ–­ã—ã¦ãã ã•ã„"
            )

        return caveats

    def _generate_recommendations(self, overall_score: float,
                                  criterion_scores: Dict[str, Any],
                                  lab_info: Dict[str, Any]) -> List[str]:
        """æ¨å¥¨äº‹é …ç”Ÿæˆ"""

        recommendations = []

        # ã‚¹ã‚³ã‚¢åˆ¥æ¨å¥¨
        if overall_score >= 80:
            recommendations.append(
                "é«˜ã„é©åˆåº¦ã‚’ç¤ºã—ã¦ã„ã‚‹ãŸã‚ã€ç©æ¥µçš„ã«æ¤œè¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™"
            )
            recommendations.append(
                "ç ”ç©¶å®¤è¦‹å­¦ã‚„æ•™æˆã¨ã®é¢è«‡ã§ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’åé›†ã—ã¾ã—ã‚‡ã†"
            )
        elif overall_score >= 60:
            recommendations.append(
                "è‰¯å¥½ãªé©åˆåº¦ã§ã™ãŒã€ä¸å®‰ãªç‚¹ã«ã¤ã„ã¦ã¯äº‹å‰ã«ç¢ºèªã—ã¾ã—ã‚‡ã†"
            )

            # ä½ã‚¹ã‚³ã‚¢åŸºæº–ã®ç‰¹å®š
            low_criteria = [
                self.criteria_info[criterion]['name_ja']
                for criterion, score_data in criterion_scores.items()
                if score_data.get('similarity', 0.0) < 0.5 and criterion in self.criteria_info
            ]

            if low_criteria:
                recommendations.append(
                    f"{', '.join(low_criteria[:2])}ã«ã¤ã„ã¦ç‰¹ã«è©³ã—ãç›¸è«‡ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™"
                )
        else:
            recommendations.append(
                "é©åˆåº¦ãŒä½ã‚ã®ãŸã‚ã€ä»–ã®é¸æŠè‚¢ã‚‚ä½µã›ã¦æ¤œè¨ã™ã‚‹ã“ã¨ã‚’ãŠå‹§ã‚ã—ã¾ã™"
            )
            recommendations.append(
                "ç¾åœ¨ã®å¸Œæœ›æ¡ä»¶ã‚’è¦‹ç›´ã—ã€æŸ”è»Ÿæ€§ã‚’æŒã£ã¦æ¤œè¨ã™ã‚‹ã“ã¨ã‚‚å¤§åˆ‡ã§ã™"
            )

        # ä¸€èˆ¬çš„æ¨å¥¨
        recommendations.append(
            "è¤‡æ•°ã®ç ”ç©¶å®¤ã‚’æ¯”è¼ƒã—ã€ç·åˆçš„ãªåˆ¤æ–­ã‚’è¡Œã†ã“ã¨ãŒé‡è¦ã§ã™"
        )

        return recommendations

    def _generate_overall_conclusion(self, score: float, confidence_level: CertaintyLevel,
                                     lab_name: str) -> str:
        """å…¨ä½“çµè«–ç”Ÿæˆ"""

        confidence_text = self.confidence_expressions[confidence_level]

        if score >= 85:
            conclusion = f"**{lab_name}**ã¯ã€ã‚ãªãŸã®å¸Œæœ›ã«éå¸¸ã«ã‚ˆãé©åˆã—ã¦ãŠã‚Šã€" \
                f"{confidence_text}ã§å¼·ãæ¨å¥¨ã§ãã‚‹é¸æŠè‚¢ã§ã™ã€‚"
        elif score >= 70:
            conclusion = f"**{lab_name}**ã¯ã€ã‚ãªãŸã®å¸Œæœ›ã«ã‚ˆãé©åˆã—ã¦ãŠã‚Šã€" \
                f"{confidence_text}ã§æ¨å¥¨ã§ãã‚‹é¸æŠè‚¢ã§ã™ã€‚"
        elif score >= 55:
            conclusion = f"**{lab_name}**ã¯ã€ã‚ãªãŸã®å¸Œæœ›ã«ã‚ã‚‹ç¨‹åº¦é©åˆã—ã¦ã„ã¾ã™ãŒã€" \
                f"ã„ãã¤ã‹ã®ç‚¹ã§æ…é‡ãªæ¤œè¨ãŒå¿…è¦ã§ã™ã€‚"
        elif score >= 40:
            conclusion = f"**{lab_name}**ã¯ã€ã‚ãªãŸã®å¸Œæœ›ã¨ã®é©åˆæ€§ã«èª²é¡ŒãŒã‚ã‚Šã€" \
                f"ä»–ã®é¸æŠè‚¢ã¨ã®æ¯”è¼ƒæ¤œè¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"
        else:
            conclusion = f"**{lab_name}**ã¯ã€ç¾åœ¨ã®å¸Œæœ›æ¡ä»¶ã¨ã®é©åˆæ€§ãŒä½ãã€" \
                f"æ¡ä»¶ã®è¦‹ç›´ã—ã¾ãŸã¯ä»–ã®é¸æŠè‚¢ã®æ¤œè¨ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚"

        return conclusion

    def _determine_confidence_level(self, confidence: float) -> CertaintyLevel:
        """ç¢ºä¿¡åº¦ãƒ¬ãƒ™ãƒ«æ±ºå®š"""

        if confidence >= 0.9:
            return CertaintyLevel.VERY_HIGH
        elif confidence >= 0.75:
            return CertaintyLevel.HIGH
        elif confidence >= 0.5:
            return CertaintyLevel.MEDIUM
        elif confidence >= 0.25:
            return CertaintyLevel.LOW
        else:
            return CertaintyLevel.VERY_LOW

    def _get_scale_label(self, criterion: str, value: float) -> str:
        """ã‚¹ã‚±ãƒ¼ãƒ«ãƒ©ãƒ™ãƒ«å–å¾—"""

        if criterion not in self.criteria_info:
            return f"{value:.1f}"

        scale_labels = self.criteria_info[criterion]['scale_labels_ja']

        # æœ€ã‚‚è¿‘ã„ãƒ©ãƒ™ãƒ«ã‚’é¸æŠ
        closest_key = min(scale_labels.keys(), key=lambda x: abs(x - value))

        if abs(closest_key - value) <= 1.5:
            return scale_labels[closest_key]
        else:
            # ä¸­é–“å€¤ã®å ´åˆ
            if value < 3:
                return "ä½ã‚"
            elif value > 7:
                return "é«˜ã‚"
            else:
                return "ä¸­ç¨‹åº¦"

    def _load_explanation_templates(self) -> Dict[str, str]:
        """èª¬æ˜ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆèª­ã¿è¾¼ã¿"""

        return {
            'overall_positive': "ğŸ¯ {lab_name}ã¨ã®é©åˆåº¦ã¯{score:.1f}ç‚¹ã§ã€{assessment}ã‚’ç¤ºã—ã¦ã„ã¾ã™ã€‚",
            'overall_negative': "âš ï¸ {lab_name}ã¨ã®é©åˆåº¦ã¯{score:.1f}ç‚¹ã§ã€{assessment}ã«ã¨ã©ã¾ã£ã¦ã„ã¾ã™ã€‚",
            'confidence_high': "ã“ã®çµæœã¯é«˜ã„ä¿¡é ¼åº¦ï¼ˆ{confidence:.1%}ï¼‰ã§ç®—å‡ºã•ã‚Œã¦ã„ã¾ã™ã€‚",
            'confidence_low': "ã“ã®çµæœã®ä¿¡é ¼åº¦ã¯{confidence:.1%}ã§ã‚ã‚Šã€è¿½åŠ æ¤œè¨¼ã‚’ãŠå‹§ã‚ã—ã¾ã™ã€‚",
            'criteria_match': "âœ… {criterion}ã§ã¯{match_level}ãƒãƒƒãƒã—ã¦ã„ã¾ã™ï¼ˆé¡ä¼¼åº¦: {similarity:.2f}ï¼‰ã€‚",
            'criteria_mismatch': "âš ï¸ {criterion}ã§ã¯é©åˆæ€§ã«èª²é¡ŒãŒã‚ã‚Šã¾ã™ï¼ˆé¡ä¼¼åº¦: {similarity:.2f}ï¼‰ã€‚"
        }

    def _get_confidence_expressions(self) -> Dict[CertaintyLevel, str]:
        """ä¿¡é ¼åº¦è¡¨ç¾å–å¾—"""

        return {
            CertaintyLevel.VERY_HIGH: "éå¸¸ã«é«˜ã„ä¿¡é ¼åº¦",
            CertaintyLevel.HIGH: "é«˜ã„ä¿¡é ¼åº¦",
            CertaintyLevel.MEDIUM: "ä¸­ç¨‹åº¦ã®ä¿¡é ¼åº¦",
            CertaintyLevel.LOW: "ä½ã„ä¿¡é ¼åº¦",
            CertaintyLevel.VERY_LOW: "éå¸¸ã«ä½ã„ä¿¡é ¼åº¦"
        }


class NaturalLanguageGenerator:
    """è‡ªç„¶è¨€èªç”Ÿæˆãƒ˜ãƒ«ãƒ‘ãƒ¼"""

    @staticmethod
    def format_explanation_for_ui(explanation: DecisionExplanation,
                                  format_type: str = "markdown") -> str:
        """UIå‘ã‘èª¬æ˜æ–‡ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""

        if format_type == "markdown":
            return NaturalLanguageGenerator._format_markdown(explanation)
        elif format_type == "html":
            return NaturalLanguageGenerator._format_html(explanation)
        else:
            return NaturalLanguageGenerator._format_plain_text(explanation)

    @staticmethod
    def _format_markdown(explanation: DecisionExplanation) -> str:
        """Markdownå½¢å¼ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""

        output = []

        # å…¨ä½“çµè«–
        output.append(f"## ğŸ¯ ç·åˆåˆ¤å®š\n\n{explanation.overall_conclusion}\n")

        # è©³ç´°åˆ†æ
        output.append("## ğŸ“Š è©³ç´°åˆ†æ\n")

        for component in explanation.components:
            if component.importance >= 0.7:  # é‡è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã®ã¿
                output.append(f"{component.content}\n")

        # æ¨è«–ãƒã‚§ãƒ¼ãƒ³
        if explanation.reasoning_chain:
            output.append("## ğŸ§  AIåˆ¤æ–­ãƒ—ãƒ­ã‚»ã‚¹\n")
            for i, step in enumerate(explanation.reasoning_chain, 1):
                output.append(f"{i}. {step}")
            output.append("")

        # æ¨å¥¨äº‹é …
        if explanation.recommendations:
            output.append("## ğŸ’¡ æ¨å¥¨äº‹é …\n")
            for rec in explanation.recommendations:
                output.append(f"- {rec}")
            output.append("")

        # æ³¨æ„ç‚¹
        if explanation.caveats:
            output.append("## âš ï¸ æ³¨æ„ç‚¹\n")
            for caveat in explanation.caveats:
                output.append(f"- {caveat}")

        return "\n".join(output)

    @staticmethod
    def _format_html(explanation: DecisionExplanation) -> str:
        """HTMLå½¢å¼ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""

        html_parts = []

        # å…¨ä½“çµè«–
        html_parts.append(f'<div class="overall-conclusion">')
        html_parts.append(f'<h2>ğŸ¯ ç·åˆåˆ¤å®š</h2>')
        html_parts.append(f'<p>{explanation.overall_conclusion}</p>')
        html_parts.append(f'</div>')

        # è©³ç´°åˆ†æ
        html_parts.append(f'<div class="detailed-analysis">')
        html_parts.append(f'<h2>ğŸ“Š è©³ç´°åˆ†æ</h2>')

        for component in explanation.components:
            if component.importance >= 0.7:
                html_parts.append(f'<div class="analysis-component">')
                html_parts.append(f'<p>{component.content}</p>')
                html_parts.append(f'</div>')

        html_parts.append(f'</div>')

        # æ¨å¥¨äº‹é …
        if explanation.recommendations:
            html_parts.append(f'<div class="recommendations">')
            html_parts.append(f'<h2>ğŸ’¡ æ¨å¥¨äº‹é …</h2>')
            html_parts.append(f'<ul>')
            for rec in explanation.recommendations:
                html_parts.append(f'<li>{rec}</li>')
            html_parts.append(f'</ul>')
            html_parts.append(f'</div>')

        return '\n'.join(html_parts)

    @staticmethod
    def _format_plain_text(explanation: DecisionExplanation) -> str:
        """ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""

        output = []

        # å…¨ä½“çµè«–
        output.append("=== ç·åˆåˆ¤å®š ===")
        output.append(explanation.overall_conclusion)
        output.append("")

        # é‡è¦ãªã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
        output.append("=== è©³ç´°åˆ†æ ===")
        for component in explanation.components:
            if component.importance >= 0.7:
                # Markdownãƒãƒ¼ã‚¯ã‚¢ãƒƒãƒ—ã‚’é™¤å»
                clean_content = re.sub(
                    r'\*\*([^*]+)\*\*', r'\1', component.content)
                clean_content = re.sub(r'[ğŸ¯âœ…ğŸ‘âš ï¸âŒğŸ§ ğŸ“ŠğŸ’¡âš–ï¸]', '', clean_content)
                output.append(clean_content.strip())
                output.append("")

        # æ¨å¥¨äº‹é …
        if explanation.recommendations:
            output.append("=== æ¨å¥¨äº‹é … ===")
            for i, rec in enumerate(explanation.recommendations, 1):
                output.append(f"{i}. {rec}")

        return "\n".join(output)


class ExplanationValidator:
    """èª¬æ˜å“è³ªæ¤œè¨¼"""

    @staticmethod
    def validate_explanation_quality(explanation: DecisionExplanation) -> Dict[str, Any]:
        """èª¬æ˜å“è³ªæ¤œè¨¼"""

        validation_results = {
            'overall_score': 0.0,
            'completeness': 0.0,
            'clarity': 0.0,
            'consistency': 0.0,
            'usefulness': 0.0,
            'issues': []
        }

        # å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
        completeness_score = ExplanationValidator._check_completeness(
            explanation)
        validation_results['completeness'] = completeness_score

        # æ˜ç¢ºæ€§ãƒã‚§ãƒƒã‚¯
        clarity_score = ExplanationValidator._check_clarity(explanation)
        validation_results['clarity'] = clarity_score

        # ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        consistency_score = ExplanationValidator._check_consistency(
            explanation)
        validation_results['consistency'] = consistency_score

        # æœ‰ç”¨æ€§ãƒã‚§ãƒƒã‚¯
        usefulness_score = ExplanationValidator._check_usefulness(explanation)
        validation_results['usefulness'] = usefulness_score

        # ç·åˆã‚¹ã‚³ã‚¢
        validation_results['overall_score'] = np.mean([
            completeness_score, clarity_score, consistency_score, usefulness_score
        ])

        return validation_results

    @staticmethod
    def _check_completeness(explanation: DecisionExplanation) -> float:
        """å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯"""

        required_elements = [
            explanation.overall_conclusion,
            explanation.components,
            explanation.recommendations
        ]

        present_elements = sum(1 for element in required_elements if element)
        completeness = present_elements / len(required_elements)

        return completeness

    @staticmethod
    def _check_clarity(explanation: DecisionExplanation) -> float:
        """æ˜ç¢ºæ€§ãƒã‚§ãƒƒã‚¯"""

        clarity_score = 1.0

        # çµè«–ã®é•·ã•ãƒã‚§ãƒƒã‚¯
        if len(explanation.overall_conclusion) < 50:
            clarity_score -= 0.2
        elif len(explanation.overall_conclusion) > 500:
            clarity_score -= 0.1

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆæ•°ãƒã‚§ãƒƒã‚¯
        if len(explanation.components) > 8:
            clarity_score -= 0.2
        elif len(explanation.components) < 2:
            clarity_score -= 0.3

        return max(0.0, clarity_score)

    @staticmethod
    def _check_consistency(explanation: DecisionExplanation) -> float:
        """ä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯"""

        # ç°¡æ˜“çš„ãªä¸€è²«æ€§ãƒã‚§ãƒƒã‚¯
        consistency_score = 1.0

        # ä¿¡é ¼åº¦ãƒ¬ãƒ™ãƒ«ã¨çµè«–ã®æ•´åˆæ€§
        if explanation.confidence_level in [CertaintyLevel.HIGH, CertaintyLevel.VERY_HIGH]:
            if "èª²é¡Œ" in explanation.overall_conclusion or "ä½ã„" in explanation.overall_conclusion:
                consistency_score -= 0.3

        return max(0.0, consistency_score)

    @staticmethod
    def _check_usefulness(explanation: DecisionExplanation) -> float:
        """æœ‰ç”¨æ€§ãƒã‚§ãƒƒã‚¯"""

        usefulness_score = 0.0

        # æ¨å¥¨äº‹é …ã®å­˜åœ¨
        if explanation.recommendations:
            usefulness_score += 0.4

        # ä»£æ›¿ã‚·ãƒŠãƒªã‚ªã®å­˜åœ¨
        if explanation.alternative_scenarios:
            usefulness_score += 0.3

        # æ³¨æ„ç‚¹ã®å­˜åœ¨
        if explanation.caveats:
            usefulness_score += 0.3

        return min(1.0, usefulness_score)
