# backend/test_genetic_integration.py
from train_genetic_model import GeneticFuzzyTreeTrainer
from explanation_engine import AdvancedExplanationEngine
from model_persistence import ModelPersistence
from evaluation_metrics import MultiObjectiveEvaluator
from optimization_tracker import OptimizationTracker
from advanced_nodes import (
    AdvancedFuzzyDecisionNode,
    AdvancedMembershipFunction,
    NodeSplitInfo
)
from genetic_fuzzy_tree import (
    GeneticFuzzyTreeOptimizer,
    GeneticParameters,
    GeneticIndividual
)
import unittest
import numpy as np
import pandas as pd
import tempfile
import shutil
import os
import sys
from pathlib import Path
import logging

# ãƒ†ã‚¹ãƒˆå¯¾è±¡ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
sys.path.append(os.path.dirname(os.path.abspath(__file__)))


# ãƒ†ã‚¹ãƒˆç”¨ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.WARNING)
logger = logging.getLogger(__name__)


class TestGeneticFuzzyTreeIntegration(unittest.TestCase):
    """éºä¼çš„ãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨çµ±åˆãƒ†ã‚¹ãƒˆ"""

    def setUp(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""

        # ä¹±æ•°ã‚·ãƒ¼ãƒ‰å›ºå®š
        np.random.seed(42)

        # ãƒ†ã‚¹ãƒˆç”¨ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        self.create_test_data()

        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        self.temp_dir = tempfile.mkdtemp()

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.genetic_params = GeneticParameters(
            population_size=10,  # ãƒ†ã‚¹ãƒˆç”¨ã«å°ã•ã
            generations=5,       # ãƒ†ã‚¹ãƒˆç”¨ã«çŸ­ã
            crossover_rate=0.8,
            mutation_rate=0.2,
            max_tree_depth=3     # ãƒ†ã‚¹ãƒˆç”¨ã«æµ…ã
        )

        self.optimizer = GeneticFuzzyTreeOptimizer(self.genetic_params)
        self.tracker = OptimizationTracker(
            tracking_db_path=os.path.join(self.temp_dir, "test_tracking.db")
        )
        self.evaluator = MultiObjectiveEvaluator()
        self.persistence = ModelPersistence(
            models_directory=os.path.join(self.temp_dir, "models"),
            metadata_db_path=os.path.join(self.temp_dir, "metadata.db")
        )
        self.explanation_engine = AdvancedExplanationEngine()

    def tearDown(self):
        """ãƒ†ã‚¹ãƒˆã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        # ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå‰Šé™¤
        shutil.rmtree(self.temp_dir, ignore_errors=True)

    def create_test_data(self):
        """ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ä½œæˆ"""

        n_samples = 50

        # 5ã¤ã®ç‰¹å¾´é‡ï¼ˆç ”ç©¶å®¤é¸æŠã‚·ãƒŠãƒªã‚ªï¼‰
        self.feature_names = [
            'research_intensity',
            'advisor_style',
            'team_work',
            'workload',
            'theory_practice'
        ]

        # ãƒ©ãƒ³ãƒ€ãƒ ãªç‰¹å¾´é‡ç”Ÿæˆï¼ˆ1-10ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
        data = {}
        for feature in self.feature_names:
            data[feature] = np.random.uniform(1, 10, n_samples)

        self.training_data = pd.DataFrame(data)

        # ç›®æ¨™å¤‰æ•°ï¼ˆè¤‡é›‘ãªéç·šå½¢é–¢ä¿‚ï¼‰
        self.target_values = (
            0.3 * (data['research_intensity'] / 10) +
            0.2 * (1 - np.abs(data['advisor_style'] - 6) / 5) +
            0.2 * (data['team_work'] / 10) +
            0.15 * (1 - np.abs(data['workload'] - 7) / 4) +
            0.15 * (data['theory_practice'] / 10) +
            np.random.normal(0, 0.05, n_samples)  # ãƒã‚¤ã‚º
        )

        # 0-1ç¯„å›²ã«æ­£è¦åŒ–
        self.target_values = np.clip(self.target_values, 0, 1)

        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿åˆ†å‰²
        split_idx = int(n_samples * 0.8)
        self.train_data = self.training_data.iloc[:split_idx]
        self.train_targets = self.target_values[:split_idx]
        self.val_data = self.training_data.iloc[split_idx:]
        self.val_targets = self.target_values[split_idx:]

    def test_membership_function_creation(self):
        """ãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—é–¢æ•°ä½œæˆãƒ†ã‚¹ãƒˆ"""

        # ä¸‰è§’ãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—é–¢æ•°
        mf = AdvancedMembershipFunction(
            name="medium",
            function_type="triangular",
            parameters=[2.0, 5.0, 8.0],
            weight=1.0
        )

        # å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆ
        self.assertEqual(mf.membership(2.0), 0.0)
        self.assertEqual(mf.membership(5.0), 1.0)
        self.assertEqual(mf.membership(8.0), 0.0)
        self.assertAlmostEqual(mf.membership(3.5), 0.5, places=5)

        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³ãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—é–¢æ•°
        mf_gaussian = AdvancedMembershipFunction(
            name="gaussian",
            function_type="gaussian",
            parameters=[5.0, 1.0],  # mu=5, sigma=1
            weight=1.0
        )

        self.assertAlmostEqual(mf_gaussian.membership(5.0), 1.0, places=5)
        self.assertGreater(mf_gaussian.membership(4.0), 0.5)
        self.assertLess(mf_gaussian.membership(3.0), 0.5)

    def test_decision_node_creation(self):
        """æ±ºå®šãƒãƒ¼ãƒ‰ä½œæˆãƒ†ã‚¹ãƒˆ"""

        # ãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—é–¢æ•°ä½œæˆ
        mf_low = AdvancedMembershipFunction("low", "triangular", [1, 3, 5])
        mf_high = AdvancedMembershipFunction("high", "triangular", [5, 7, 9])

        # åˆ†å‰²æƒ…å ±ä½œæˆ
        split_info = NodeSplitInfo(
            feature_index=0,
            feature_name="research_intensity",
            split_type="fuzzy_threshold",
            membership_functions={"low": mf_low, "high": mf_high},
            information_gain=0.5,
            split_quality=0.8
        )

        # ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰ä½œæˆ
        leaf_low = AdvancedFuzzyDecisionNode(
            node_id="leaf_low",
            depth=1,
            leaf_value=0.3
        )

        leaf_high = AdvancedFuzzyDecisionNode(
            node_id="leaf_high",
            depth=1,
            leaf_value=0.7
        )

        # ãƒ«ãƒ¼ãƒˆãƒãƒ¼ãƒ‰ä½œæˆ
        root = AdvancedFuzzyDecisionNode(
            node_id="root",
            depth=0,
            split_info=split_info,
            children={"low": leaf_low, "high": leaf_high}
        )

        # äºˆæ¸¬ãƒ†ã‚¹ãƒˆ
        prediction = root.predict([2.0, 0, 0, 0, 0], self.feature_names)
        self.assertIsInstance(prediction, float)
        self.assertGreaterEqual(prediction, 0.0)
        self.assertLessEqual(prediction, 1.0)

        # èª¬æ˜ä»˜ãäºˆæ¸¬ãƒ†ã‚¹ãƒˆ
        prediction_with_explanation = root.predict_with_explanation(
            [7.0, 0, 0, 0, 0], self.feature_names)
        self.assertIsInstance(prediction_with_explanation, tuple)
        self.assertEqual(len(prediction_with_explanation), 2)

    def test_genetic_individual_creation(self):
        """éºä¼çš„å€‹ä½“ä½œæˆãƒ†ã‚¹ãƒˆ"""

        individual = GeneticIndividual()
        self.assertIsNotNone(individual.individual_id)
        self.assertEqual(individual.generation, 0)

        # éºä¼å­åˆæœŸåŒ–
        individual.initialize_random_genome(
            feature_count=len(self.feature_names),
            max_depth=3
        )

        self.assertGreater(len(individual.genome), 0)
        self.assertIsInstance(individual.genome, list)

        # æ±ºå®šæœ¨ãƒ‡ã‚³ãƒ¼ãƒ‰
        tree = individual.decode_genome_to_tree(
            self.feature_names,
            self.train_data,
            self.train_targets
        )

        self.assertIsInstance(tree, AdvancedFuzzyDecisionNode)

    def test_genetic_optimization(self):
        """éºä¼çš„æœ€é©åŒ–ãƒ†ã‚¹ãƒˆ"""

        # æœ€é©åŒ–å®Ÿè¡Œ
        best_individual = self.optimizer.optimize(
            training_data=self.train_data,
            target_values=self.train_targets,
            validation_data=self.val_data,
            validation_targets=self.val_targets,
            feature_names=self.feature_names
        )

        # çµæœæ¤œè¨¼
        self.assertIsInstance(best_individual, GeneticIndividual)
        self.assertIsNotNone(best_individual.tree)
        self.assertGreater(best_individual.fitness_components.overall, 0.0)
        self.assertLessEqual(best_individual.fitness_components.overall, 1.0)

        # äºˆæ¸¬å®Ÿè¡Œ
        sample_input = self.train_data.iloc[0].values.tolist()
        prediction = best_individual.tree.predict(
            sample_input, self.feature_names)

        self.assertIsInstance(prediction, float)
        self.assertGreaterEqual(prediction, 0.0)
        self.assertLessEqual(prediction, 1.0)

    def test_optimization_tracking(self):
        """æœ€é©åŒ–è¿½è·¡ãƒ†ã‚¹ãƒˆ"""

        self.tracker.start_optimization_tracking()

        # ãƒ€ãƒŸãƒ¼å€‹ä½“ä½œæˆ
        individuals = []
        for i in range(5):
            individual = GeneticIndividual()
            individual.fitness_components.overall = np.random.uniform(0.3, 0.9)
            individual.fitness_components.accuracy = np.random.uniform(
                0.4, 0.8)
            individual.fitness_components.simplicity = np.random.uniform(
                0.5, 0.9)
            individuals.append(individual)

        # ä¸–ä»£è¨˜éŒ²
        stats = self.tracker.record_generation(
            generation=0,
            population=individuals
        )

        self.assertIsNotNone(stats)
        self.assertEqual(stats.generation, 0)
        self.assertEqual(stats.population_size, 5)
        self.assertGreater(stats.best_fitness, 0.0)

        self.tracker.finish_optimization_tracking()

        # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        report = self.tracker.generate_optimization_report()
        self.assertIn('optimization_summary', report)
        self.assertIn('final_population_stats', report)

    def test_model_persistence(self):
        """ãƒ¢ãƒ‡ãƒ«æ°¸ç¶šåŒ–ãƒ†ã‚¹ãƒˆ"""

        # ãƒ†ã‚¹ãƒˆç”¨å€‹ä½“ä½œæˆ
        individual = GeneticIndividual()
        individual.initialize_random_genome(len(self.feature_names), 3)
        individual.decode_genome_to_tree(
            self.feature_names, self.train_data, self.train_targets)
        individual.fitness_components.overall = 0.75

        # ãƒ€ãƒŸãƒ¼ã‚ªãƒ—ãƒ†ã‚£ãƒã‚¤ã‚¶ãƒ¼
        class DummyOptimizer:
            def __init__(self):
                self.parameters = self.genetic_params
                self.convergence_generation = None
                self.generation_stats = []

            def get_optimization_summary(self):
                return {
                    'total_generations': 5,
                    'best_fitness': individual.fitness_components.overall
                }

        dummy_optimizer = DummyOptimizer()

        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        model_id = self.persistence.save_model(
            genetic_individual=individual,
            optimizer=dummy_optimizer,
            feature_names=self.feature_names,
            training_sample_count=len(self.train_data),
            validation_sample_count=len(self.val_data),
            tags=['test_model'],
            description="Test model for integration testing"
        )

        self.assertIsNotNone(model_id)

        # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
        loaded_individual, model_data = self.persistence.load_model(model_id)

        self.assertIsInstance(loaded_individual, GeneticIndividual)
        self.assertEqual(loaded_individual.individual_id,
                         individual.individual_id)
        self.assertAlmostEqual(
            loaded_individual.fitness_components.overall,
            individual.fitness_components.overall,
            places=6
        )

        # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§
        models = self.persistence.list_models()
        self.assertGreater(len(models), 0)
        self.assertEqual(models[0]['model_id'], model_id)

        # ãƒ¢ãƒ‡ãƒ«å‰Šé™¤
        success = self.persistence.delete_model(model_id)
        self.assertTrue(success)

    def test_multi_objective_evaluation(self):
        """å¤šç›®çš„è©•ä¾¡ãƒ†ã‚¹ãƒˆ"""

        # ãƒ†ã‚¹ãƒˆç”¨å€‹ä½“ä½œæˆ
        individual = GeneticIndividual()
        individual.initialize_random_genome(len(self.feature_names), 3)
        tree = individual.decode_genome_to_tree(
            self.feature_names, self.train_data, self.train_targets)
        individual.tree = tree

        # è©•ä¾¡å®Ÿè¡Œ
        fitness_components = self.evaluator.evaluate_individual(
            individual=individual,
            training_data=self.train_data,
            target_values=self.train_targets,
            validation_data=self.val_data,
            validation_targets=self.val_targets,
            feature_names=self.feature_names
        )

        # çµæœæ¤œè¨¼
        self.assertIsNotNone(fitness_components)
        self.assertGreaterEqual(fitness_components.accuracy, 0.0)
        self.assertLessEqual(fitness_components.accuracy, 1.0)
        self.assertGreaterEqual(fitness_components.simplicity, 0.0)
        self.assertLessEqual(fitness_components.simplicity, 1.0)
        self.assertGreaterEqual(fitness_components.interpretability, 0.0)
        self.assertLessEqual(fitness_components.interpretability, 1.0)
        self.assertGreaterEqual(fitness_components.overall, 0.0)
        self.assertLessEqual(fitness_components.overall, 1.0)

    def test_explanation_engine(self):
        """èª¬æ˜ã‚¨ãƒ³ã‚¸ãƒ³ãƒ†ã‚¹ãƒˆ"""

        # ãƒ†ã‚¹ãƒˆç”¨æ±ºå®šæœ¨ä½œæˆ
        individual = GeneticIndividual()
        individual.initialize_random_genome(len(self.feature_names), 3)
        tree = individual.decode_genome_to_tree(
            self.feature_names, self.train_data, self.train_targets)

        # ã‚µãƒ³ãƒ—ãƒ«å…¥åŠ›
        sample_input = self.train_data.iloc[0].values.tolist()

        # èª¬æ˜ä»˜ãäºˆæ¸¬
        prediction, explanation = tree.predict_with_explanation(
            sample_input, self.feature_names)

        # åŒ…æ‹¬çš„èª¬æ˜ç”Ÿæˆ
        comprehensive_explanation = self.explanation_engine.generate_comprehensive_explanation(
            prediction=prediction,
            explanation=explanation,
            feature_vector=sample_input,
            feature_names=self.feature_names,
            decision_tree=tree
        )

        # çµæœæ¤œè¨¼
        self.assertIsInstance(comprehensive_explanation, dict)
        self.assertIn('prediction_value', comprehensive_explanation)
        self.assertIn('confidence', comprehensive_explanation)
        self.assertIn('feature_importance', comprehensive_explanation)
        self.assertIn('narrative_explanation', comprehensive_explanation)
        self.assertIn('reliability_assessment', comprehensive_explanation)

        # äºˆæ¸¬å€¤ã®å¦¥å½“æ€§
        self.assertIsInstance(
            comprehensive_explanation['prediction_value'], float)
        self.assertGreaterEqual(
            comprehensive_explanation['prediction_value'], 0.0)
        self.assertLessEqual(
            comprehensive_explanation['prediction_value'], 1.0)

    def test_full_training_pipeline(self):
        """å®Œå…¨å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ãƒ†ã‚¹ãƒˆ"""

        # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼è¨­å®š
        config = {
            'genetic_parameters': {
                'population_size': 8,
                'generations': 3,
                'crossover_rate': 0.8,
                'mutation_rate': 0.2,
                'max_tree_depth': 3
            },
            'data_parameters': {
                'validation_split': 0.2,
                'random_state': 42
            },
            'output_parameters': {
                'save_model': True,
                'save_tracking': False,  # ãƒ†ã‚¹ãƒˆã§ã¯ç„¡åŠ¹åŒ–
                'generate_report': False,  # ãƒ†ã‚¹ãƒˆã§ã¯ç„¡åŠ¹åŒ–
                'create_visualizations': False,  # ãƒ†ã‚¹ãƒˆã§ã¯ç„¡åŠ¹åŒ–
                'model_output_dir': os.path.join(self.temp_dir, 'models')
            }
        }

        # ãƒˆãƒ¬ãƒ¼ãƒŠãƒ¼åˆæœŸåŒ–
        trainer = GeneticFuzzyTreeTrainer(config)

        # ãƒ‡ãƒ¼ã‚¿æº–å‚™ï¼ˆç›´æ¥æŒ‡å®šï¼‰
        trainer.prepare_data(
            training_data=self.training_data,
            target_values=self.target_values,
            feature_names=self.feature_names
        )

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        trainer.setup_components()

        # å­¦ç¿’å®Ÿè¡Œ
        best_individual = trainer.train()

        # çµæœæ¤œè¨¼
        self.assertIsInstance(best_individual, GeneticIndividual)
        self.assertIsNotNone(best_individual.tree)
        self.assertGreater(best_individual.fitness_components.overall, 0.0)

        # è©•ä¾¡å®Ÿè¡Œ
        if trainer.validation_data is not None:
            evaluation_results = trainer.evaluate_model()
            self.assertIsInstance(evaluation_results, dict)
            self.assertIn('mae', evaluation_results)
            self.assertIn('rmse', evaluation_results)
            self.assertGreater(evaluation_results['test_samples'], 0)

    def test_serialization_deserialization(self):
        """ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ»ãƒ‡ã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¼ãƒ¼ã‚·ãƒ§ãƒ³ãƒ†ã‚¹ãƒˆ"""

        from model_persistence import ModelSerializer

        # ãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—é–¢æ•°ãƒ†ã‚¹ãƒˆ
        mf_original = AdvancedMembershipFunction(
            name="test_mf",
            function_type="triangular",
            parameters=[1.0, 5.0, 9.0],
            weight=0.8
        )

        mf_serialized = ModelSerializer.serialize_membership_function(
            mf_original)
        mf_deserialized = ModelSerializer.deserialize_membership_function(
            mf_serialized)

        self.assertEqual(mf_original.name, mf_deserialized.name)
        self.assertEqual(mf_original.function_type,
                         mf_deserialized.function_type)
        self.assertEqual(mf_original.parameters, mf_deserialized.parameters)
        self.assertEqual(mf_original.weight, mf_deserialized.weight)

        # æ±ºå®šãƒãƒ¼ãƒ‰ãƒ†ã‚¹ãƒˆ
        node_original = AdvancedFuzzyDecisionNode(
            node_id="test_node",
            depth=0,
            leaf_value=0.7
        )

        node_serialized = ModelSerializer.serialize_decision_node(
            node_original)
        node_deserialized = ModelSerializer.deserialize_decision_node(
            node_serialized)

        self.assertEqual(node_original.node_id, node_deserialized.node_id)
        self.assertEqual(node_original.depth, node_deserialized.depth)
        self.assertEqual(node_original.is_leaf, node_deserialized.is_leaf)
        self.assertEqual(node_original.leaf_value,
                         node_deserialized.leaf_value)

    def test_error_handling(self):
        """ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""

        # ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã§ã®æœ€é©åŒ–
        empty_data = pd.DataFrame()
        empty_targets = np.array([])

        with self.assertRaises((ValueError, IndexError)):
            self.optimizer.optimize(
                training_data=empty_data,
                target_values=empty_targets,
                feature_names=[]
            )

        # å­˜åœ¨ã—ãªã„ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿
        with self.assertRaises((ValueError, FileNotFoundError)):
            self.persistence.load_model("non_existent_model_id")

        # ä¸æ­£ãªãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—é–¢æ•°ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        invalid_mf = AdvancedMembershipFunction(
            name="invalid",
            function_type="triangular",
            parameters=[5.0, 3.0, 1.0],  # ä¸æ­£ãªé †åº
            weight=1.0
        )

        # ã‚¨ãƒ©ãƒ¼ã¯ç™ºç”Ÿã•ã›ãšã«é©åˆ‡ã«å‡¦ç†ã•ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
        result = invalid_mf.membership(4.0)
        self.assertIsInstance(result, float)
        self.assertGreaterEqual(result, 0.0)
        self.assertLessEqual(result, 1.0)


class TestPerformanceBenchmarks(unittest.TestCase):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ™ãƒ³ãƒãƒãƒ¼ã‚¯ãƒ†ã‚¹ãƒˆ"""

    def setUp(self):
        """ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""
        np.random.seed(42)

        # ä¸­è¦æ¨¡ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
        n_samples = 200
        n_features = 5

        self.feature_names = [f'feature_{i}' for i in range(n_features)]

        data = {}
        for i, feature in enumerate(self.feature_names):
            data[feature] = np.random.uniform(1, 10, n_samples)

        self.training_data = pd.DataFrame(data)
        self.target_values = np.random.uniform(0, 1, n_samples)

        # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ¸¬å®šç”¨ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
        self.genetic_params = GeneticParameters(
            population_size=20,
            generations=10,
            crossover_rate=0.8,
            mutation_rate=0.2,
            max_tree_depth=4
        )

    def test_optimization_speed(self):
        """æœ€é©åŒ–é€Ÿåº¦ãƒ†ã‚¹ãƒˆ"""

        import time

        optimizer = GeneticFuzzyTreeOptimizer(self.genetic_params)

        start_time = time.time()

        best_individual = optimizer.optimize(
            training_data=self.training_data,
            target_values=self.target_values,
            feature_names=self.feature_names
        )

        end_time = time.time()
        execution_time = end_time - start_time

        # å®Ÿè¡Œæ™‚é–“ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯ï¼ˆç’°å¢ƒä¾å­˜ï¼‰
        self.assertLess(execution_time, 300)  # 5åˆ†ä»¥å†…
        self.assertIsNotNone(best_individual)

        print(f"\næœ€é©åŒ–å®Ÿè¡Œæ™‚é–“: {execution_time:.2f}ç§’")
        print(f"æœ€è‰¯é©å¿œåº¦: {best_individual.fitness_components.overall:.4f}")

    def test_prediction_speed(self):
        """äºˆæ¸¬é€Ÿåº¦ãƒ†ã‚¹ãƒˆ"""

        import time

        # ç°¡å˜ãªæ±ºå®šæœ¨ä½œæˆ
        individual = GeneticIndividual()
        individual.initialize_random_genome(len(self.feature_names), 3)
        tree = individual.decode_genome_to_tree(
            self.feature_names,
            self.training_data,
            self.target_values
        )

        # å¤§é‡äºˆæ¸¬ã®ã‚¿ã‚¤ãƒŸãƒ³ã‚°æ¸¬å®š
        n_predictions = 1000
        test_samples = []

        for _ in range(n_predictions):
            sample = np.random.uniform(1, 10, len(self.feature_names)).tolist()
            test_samples.append(sample)

        start_time = time.time()

        predictions = []
        for sample in test_samples:
            prediction = tree.predict(sample, self.feature_names)
            predictions.append(prediction)

        end_time = time.time()
        prediction_time = end_time - start_time
        avg_time_per_prediction = prediction_time / n_predictions

        # äºˆæ¸¬é€Ÿåº¦ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        self.assertLess(avg_time_per_prediction, 0.01)  # 10msä»¥å†…/äºˆæ¸¬
        self.assertEqual(len(predictions), n_predictions)

        print(f"\näºˆæ¸¬ç·æ™‚é–“: {prediction_time:.4f}ç§’")
        print(f"å¹³å‡äºˆæ¸¬æ™‚é–“: {avg_time_per_prediction*1000:.2f}ms/äºˆæ¸¬")

    def test_memory_usage(self):
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ãƒ†ã‚¹ãƒˆ"""

        import psutil
        import os

        process = psutil.Process(os.getpid())
        initial_memory = process.memory_info().rss / 1024 / 1024  # MB

        # è¤‡æ•°ãƒ¢ãƒ‡ãƒ«ã®ä½œæˆã¨ä¿å­˜
        models = []
        for i in range(10):
            individual = GeneticIndividual()
            individual.initialize_random_genome(len(self.feature_names), 4)
            tree = individual.decode_genome_to_tree(
                self.feature_names,
                self.training_data,
                self.target_values
            )
            models.append(individual)

        final_memory = process.memory_info().rss / 1024 / 1024  # MB
        memory_increase = final_memory - initial_memory

        # ãƒ¡ãƒ¢ãƒªå¢—åŠ ã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
        self.assertLess(memory_increase, 100)  # 100MBä»¥å†…

        print(f"\nåˆæœŸãƒ¡ãƒ¢ãƒª: {initial_memory:.1f}MB")
        print(f"æœ€çµ‚ãƒ¡ãƒ¢ãƒª: {final_memory:.1f}MB")
        print(f"ãƒ¡ãƒ¢ãƒªå¢—åŠ : {memory_increase:.1f}MB")


def run_integration_tests():
    """çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""

    print("ğŸ§ª éºä¼çš„ãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨çµ±åˆãƒ†ã‚¹ãƒˆé–‹å§‹")

    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆä½œæˆ
    test_suite = unittest.TestSuite()

    # åŸºæœ¬çµ±åˆãƒ†ã‚¹ãƒˆ
    test_suite.addTest(unittest.makeSuite(TestGeneticFuzzyTreeIntegration))

    # ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ†ã‚¹ãƒˆ
    test_suite.addTest(unittest.makeSuite(TestPerformanceBenchmarks))

    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(test_suite)

    # çµæœã‚µãƒãƒªãƒ¼
    print(f"\nğŸ“Š ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼:")
    print(f"   å®Ÿè¡Œãƒ†ã‚¹ãƒˆæ•°: {result.testsRun}")
    print(
        f"   æˆåŠŸ: {result.testsRun - len(result.failures) - len(result.errors)}")
    print(f"   å¤±æ•—: {len(result.failures)}")
    print(f"   ã‚¨ãƒ©ãƒ¼: {len(result.errors)}")

    if result.failures:
        print(f"\nâŒ å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆ:")
        for test, traceback in result.failures:
            print(f"   - {test}")

    if result.errors:
        print(f"\nğŸ’¥ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸãƒ†ã‚¹ãƒˆ:")
        for test, traceback in result.errors:
            print(f"   - {test}")

    success = len(result.failures) == 0 and len(result.errors) == 0

    if success:
        print(f"\nğŸ‰ å…¨ãƒ†ã‚¹ãƒˆæˆåŠŸï¼")
    else:
        print(f"\nâš ï¸ ä¸€éƒ¨ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸã€‚")

    return success


if __name__ == "__main__":
    success = run_integration_tests()
    exit(0 if success else 1)
