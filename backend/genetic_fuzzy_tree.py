# backend/genetic_fuzzy_tree.py - å®Œå…¨ä¿®æ­£ç‰ˆ
"""
ğŸ§¬ Fixed Genetic Fuzzy Decision Tree System
ä¿®æ­£ç‰ˆéºä¼çš„ãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨ã‚·ã‚¹ãƒ†ãƒ  - record_individual å‘¼ã³å‡ºã—ä¿®æ­£æ¸ˆã¿
"""

import random
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Any, Optional, Union
from dataclasses import dataclass, field
import copy
import math
import uuid
import time
import warnings
warnings.filterwarnings('ignore')

# ä¾å­˜é–¢ä¿‚ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆï¼ˆã‚¨ãƒ©ãƒ¼å‡¦ç†ä»˜ãï¼‰
try:
    from explanation_engine import FuzzyExplanationEngine, DecisionExplanation
except ImportError:
    print("âš ï¸ explanation_engine not found, using mock")

    class FuzzyExplanationEngine:
        def generate_comprehensive_explanation(self, *args, **kwargs):
            return "Basic explanation generated"

    class DecisionExplanation:
        def __init__(self, overall_conclusion, confidence_level=None):
            self.overall_conclusion = overall_conclusion

try:
    from optimization_tracker import OptimizationTracker, GenerationStats
except ImportError:
    print("âš ï¸ optimization_tracker not found, using mock")

    class OptimizationTracker:
        def __init__(self, run_id):
            self.run_id = run_id

        def start_optimization(self, config): pass
        def end_optimization(self): pass
        def record_individual(self, *args, **kwargs): pass
        def record_generation(self, *args): pass

try:
    from evaluation_metrics import MultiObjectiveEvaluator, MetricResult
except ImportError:
    print("âš ï¸ evaluation_metrics not found, using mock")

    class MultiObjectiveEvaluator:
        def evaluate_individual(self, *args, **kwargs):
            return {
                'accuracy': type('obj', (object,), {'normalized_value': 0.8})(),
                'simplicity': type('obj', (object,), {'normalized_value': 0.7})(),
                'interpretability': type('obj', (object,), {'normalized_value': 0.6})(),
                'generalization': type('obj', (object,), {'normalized_value': 0.75})(),
                'validity': type('obj', (object,), {'normalized_value': 0.9})()
            }

try:
    from advanced_nodes import (
        AdvancedFuzzyDecisionNode, MembershipFunction, MembershipType,
        FitnessComponents, TreeVisualizationHelper
    )
except ImportError:
    print("âš ï¸ advanced_nodes not found, using simple implementations")

    from enum import Enum

    class MembershipType(Enum):
        TRIANGULAR = "triangular"
        GAUSSIAN = "gaussian"
        TRAPEZOIDAL = "trapezoidal"

    class MembershipFunction:
        def __init__(self, name, mf_type, parameters, weight=1.0):
            self.name = name
            self.type = mf_type
            self.parameters = parameters
            self.weight = weight

        def evaluate(self, x):
            if self.type == MembershipType.TRIANGULAR:
                a, b, c = self.parameters
                if x <= a or x >= c:
                    return 0.0
                elif a < x <= b:
                    return (x - a) / (b - a)
                else:  # b < x < c
                    return (c - x) / (c - b)
            elif self.type == MembershipType.GAUSSIAN:
                center, sigma = self.parameters
                return np.exp(-0.5 * ((x - center) / sigma) ** 2)
            else:
                return 0.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

    class AdvancedFuzzyDecisionNode:
        def __init__(self, node_id=None, feature_name=None, leaf_value=None):
            self.node_id = node_id or str(uuid.uuid4())[:8]
            self.feature_name = feature_name
            self.leaf_value = leaf_value
            self.is_leaf = leaf_value is not None
            self.membership_functions = {}
            self.children = {}
            self.depth = 0

        def add_membership_function(self, label, mf):
            self.membership_functions[label] = mf

        def add_child(self, label, child):
            self.children[label] = child

        def predict(self, features):
            if self.is_leaf:
                return self.leaf_value

            feature_value = features.get(self.feature_name, 5.0)

            # ãƒ•ã‚¡ã‚¸ã‚£è©•ä¾¡
            max_membership = 0.0
            best_label = None

            for label, mf in self.membership_functions.items():
                membership = mf.evaluate(feature_value)
                if membership > max_membership:
                    max_membership = membership
                    best_label = label

            # å­ãƒãƒ¼ãƒ‰ã§äºˆæ¸¬
            if best_label and best_label in self.children:
                return self.children[best_label].predict(features)
            else:
                return 0.5  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤

        def predict_with_explanation(self, features, feature_names):
            prediction = self.predict(features)
            explanation = {
                'confidence': 0.8,
                'decision_steps': [],
                'rationale': f'Prediction: {prediction:.3f}'
            }
            return prediction, explanation

        def calculate_complexity(self):
            if self.is_leaf:
                return 1
            total = 1 + len(self.membership_functions)
            for child in self.children.values():
                total += child.calculate_complexity()
            return total

        def calculate_depth(self):
            if self.is_leaf:
                return 1
            max_depth = 0
            for child in self.children.values():
                max_depth = max(max_depth, child.calculate_depth())
            return max_depth + 1

        def get_tree_structure(self):
            if self.is_leaf:
                return {'type': 'leaf', 'value': self.leaf_value}
            return {
                'type': 'internal',
                'feature': self.feature_name,
                'children': len(self.children),
                'membership_functions': len(self.membership_functions)
            }

    class FitnessComponents:
        def __init__(self, accuracy=0.0, simplicity=0.0, interpretability=0.0,
                     generalization=0.0, validity=0.0):
            self.accuracy = accuracy
            self.simplicity = simplicity
            self.interpretability = interpretability
            self.generalization = generalization
            self.validity = validity
            self.overall = self.compute_overall()

        def compute_overall(self):
            weights = [0.3, 0.2, 0.2, 0.15, 0.15]
            components = [self.accuracy, self.simplicity, self.interpretability,
                          self.generalization, self.validity]
            return sum(w * c for w, c in zip(weights, components))

        def to_dict(self):
            return {
                'accuracy': self.accuracy,
                'simplicity': self.simplicity,
                'interpretability': self.interpretability,
                'generalization': self.generalization,
                'validity': self.validity,
                'overall': self.overall
            }

        @property
        def __dict__(self):
            return self.to_dict()

    class TreeVisualizationHelper:
        @staticmethod
        def generate_tree_summary(tree):
            return f"Tree: depth={tree.calculate_depth()}, complexity={tree.calculate_complexity()}"


@dataclass
class GeneticParameters:
    """éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿"""
    population_size: int = 50
    generations: int = 30
    mutation_rate: float = 0.15
    crossover_rate: float = 0.8
    elite_size: int = 5
    tournament_size: int = 3
    max_depth: int = 6
    min_membership_functions: int = 2
    max_membership_functions: int = 4

    def __post_init__(self):
        # ã‚¨ãƒªãƒ¼ãƒˆã‚µã‚¤ã‚ºã®èª¿æ•´
        if self.elite_size >= self.population_size:
            self.elite_size = max(1, self.population_size // 10)


class Individual:
    """éºä¼çš„å€‹ä½“"""

    def __init__(self, individual_id: str = None, generation: int = 0):
        self.individual_id = individual_id or str(uuid.uuid4())[:8]
        self.generation = generation
        self.tree: Optional[AdvancedFuzzyDecisionNode] = None
        self.genome: Dict[str, Any] = {}
        self.fitness_value: float = 0.0
        self.fitness_components: Optional[FitnessComponents] = None
        self.complexity_score: int = 0
        self.parents: List[str] = []


class GeneticFuzzyTreeOptimizer:
    """éºä¼çš„ãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨æœ€é©åŒ–å™¨ - ä¿®æ­£ç‰ˆ"""

    def __init__(self, parameters: GeneticParameters = None, random_seed: int = None):
        self.parameters = parameters or GeneticParameters()
        self.random_seed = random_seed

        # ä¹±æ•°ã‚·ãƒ¼ãƒ‰è¨­å®š
        if random_seed is not None:
            random.seed(random_seed)
            np.random.seed(random_seed)

        # è©•ä¾¡å™¨
        self.evaluator = MultiObjectiveEvaluator()

        # ãƒˆãƒ©ãƒƒã‚«ãƒ¼
        self.tracker: Optional[OptimizationTracker] = None

        # èª¬æ˜ã‚¨ãƒ³ã‚¸ãƒ³
        self.explanation_engine = FuzzyExplanationEngine()

        # çµ±è¨ˆæƒ…å ±
        self.evolution_stats = {
            'best_fitness_history': [],
            'avg_fitness_history': [],
            'diversity_history': [],
            'evaluation_times': []
        }

        # ç‰¹å¾´åï¼ˆç ”ç©¶å®¤é¸æŠåŸºæº–ï¼‰
        self.feature_names = [
            'research_intensity', 'advisor_style', 'team_work',
            'workload', 'theory_practice'
        ]

        # ãƒ‡ãƒ¼ã‚¿ä¿å­˜ç”¨
        self.training_data: Optional[pd.DataFrame] = None
        self.test_data: Optional[pd.DataFrame] = None
        self.target_column: str = 'compatibility'

        print("ğŸ§¬ GeneticFuzzyTreeOptimizer initialized")

    def optimize(self, training_data: pd.DataFrame,
                 test_data: pd.DataFrame = None,
                 target_column: str = 'compatibility',
                 run_id: str = None) -> Dict[str, Any]:
        """éºä¼çš„æœ€é©åŒ–å®Ÿè¡Œ"""

        # ãƒˆãƒ©ãƒƒã‚«ãƒ¼åˆæœŸåŒ–
        self.tracker = OptimizationTracker(run_id)

        # è¨­å®šä¿å­˜
        config = {
            'parameters': self.parameters.__dict__,
            'feature_names': self.feature_names,
            'training_samples': len(training_data),
            'test_samples': len(test_data) if test_data is not None else 0,
            'target_column': target_column,
            'random_seed': self.random_seed
        }

        self.tracker.start_optimization(config)

        print(f"ğŸš€ Starting genetic optimization...")
        print(f"ğŸ“Š Training samples: {len(training_data)}")
        print(f"ğŸ¯ Target: {target_column}")
        print(f"ğŸ‘¥ Population: {self.parameters.population_size}")
        print(f"ğŸ”„ Generations: {self.parameters.generations}")

        try:
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒãªã„å ´åˆã¯è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã‚’åˆ†å‰²
            if test_data is None:
                test_data = training_data.sample(
                    frac=0.2, random_state=self.random_seed)
                training_data = training_data.drop(test_data.index)

            # ãƒ‡ãƒ¼ã‚¿ä¿å­˜
            self.training_data = training_data
            self.test_data = test_data
            self.target_column = target_column

            # åˆæœŸå€‹ä½“ç¾¤ç”Ÿæˆ
            population = self._create_initial_population()

            # é€²åŒ–å®Ÿè¡Œ
            result = self._evolve_population(population)

            # æœ€çµ‚åŒ–
            self.tracker.end_optimization()

            return result

        except Exception as e:
            print(f"âŒ Optimization failed: {e}")
            if self.tracker:
                self.tracker.end_optimization()
            raise

    def _create_initial_population(self) -> List[Individual]:
        """åˆæœŸå€‹ä½“ç¾¤ç”Ÿæˆ"""
        population = []

        for i in range(self.parameters.population_size):
            individual = self._create_individual()
            individual.individual_id = f"gen0_ind{i}"
            population.append(individual)

        return population

    def _evolve_population(self, population: List[Individual]) -> Dict[str, Any]:
        """å€‹ä½“ç¾¤é€²åŒ– - ä¿®æ­£ç‰ˆ"""

        best_individual = None

        # ä¸–ä»£ãƒ«ãƒ¼ãƒ—
        for generation in range(self.parameters.generations):
            generation_start_time = time.time()

            print(
                f"\nğŸ”„ Generation {generation + 1}/{self.parameters.generations}")

            # å€‹ä½“è©•ä¾¡
            evaluation_results = []

            for individual in population:
                evaluation_start = time.time()

                # é©å¿œåº¦è©•ä¾¡
                fitness_value = self._evaluate_individual_fitness(individual)
                individual.fitness_value = fitness_value

                evaluation_time = time.time() - evaluation_start

                # è©•ä¾¡çµæœè¨˜éŒ²
                evaluation_result = {
                    'individual_id': individual.individual_id,
                    'overall_fitness': fitness_value,
                    'fitness_components': individual.fitness_components.__dict__ if individual.fitness_components else {},
                    'evaluation_time': evaluation_time,
                    'model_complexity': individual.complexity_score
                }
                evaluation_results.append(evaluation_result)

                # âœ… ä¿®æ­£æ¸ˆã¿å€‹ä½“è¨˜éŒ² - æ­£ã—ã„å¼•æ•°é †åº
                self.tracker.record_individual(
                    individual=individual,
                    individual_id=individual.individual_id,
                    generation=generation,
                    fitness_components=evaluation_result.get(
                        'fitness_components', {}),
                    overall_fitness=evaluation_result.get(
                        'overall_fitness', 0.0),
                    notes=f"Generation {generation} evaluation"
                )

            # æœ€è‰¯å€‹ä½“æ›´æ–°
            population.sort(key=lambda x: x.fitness_value, reverse=True)
            current_best = population[0]

            if best_individual is None or current_best.fitness_value > best_individual.fitness_value:
                best_individual = copy.deepcopy(current_best)

            # çµ±è¨ˆè¨ˆç®—
            fitness_values = [ind.fitness_value for ind in population]
            best_fitness = max(fitness_values)
            avg_fitness = np.mean(fitness_values)

            # å¤šæ§˜æ€§è¨ˆç®—
            diversity_score = self._calculate_population_diversity(population)

            # ä¸–ä»£è¨˜éŒ²
            generation_metrics = {
                'mutation_success_rate': 0.7,
                'crossover_success_rate': 0.8
            }

            self.tracker.record_generation(
                generation, population, evaluation_results, generation_metrics
            )

            # é€²åŒ–çµ±è¨ˆæ›´æ–°
            self.evolution_stats['best_fitness_history'].append(best_fitness)
            self.evolution_stats['avg_fitness_history'].append(avg_fitness)
            self.evolution_stats['diversity_history'].append(diversity_score)
            self.evolution_stats['evaluation_times'].append(
                time.time() - generation_start_time)

            print(
                f"ğŸ“Š Best: {best_fitness:.4f}, Avg: {avg_fitness:.4f}, Diversity: {diversity_score:.3f}")

            # åæŸãƒã‚§ãƒƒã‚¯
            if self._check_convergence(generation):
                print(f"ğŸ¯ Convergence detected at generation {generation + 1}")
                break

            # æœ€çµ‚ä¸–ä»£ã§ãªã„å ´åˆã¯æ¬¡ä¸–ä»£ç”Ÿæˆ
            if generation < self.parameters.generations - 1:
                population = self._create_next_generation(population)

        # æœ€çµ‚çµæœã¾ã¨ã‚
        result = self._compile_final_result(best_individual, population)

        print(f"ğŸ Optimization completed!")
        print(f"ğŸ¯ Best fitness: {result['best_fitness']:.4f}")
        print(f"ğŸ“Š Final population diversity: {result['final_diversity']:.3f}")

        return result

    def _create_individual(self) -> Individual:
        """å€‹ä½“ç”Ÿæˆ"""

        individual = Individual(
            individual_id=str(uuid.uuid4())[:8],
            generation=0
        )

        # ãƒ©ãƒ³ãƒ€ãƒ ãªãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨ç”Ÿæˆ
        individual.tree = self._generate_random_fuzzy_tree()

        # ã‚²ãƒãƒ æƒ…å ±ä½œæˆ
        individual.genome = self._tree_to_genome(individual.tree)

        # è¤‡é›‘åº¦è¨ˆç®—
        individual.complexity_score = individual.tree.calculate_complexity()

        return individual

    def _generate_random_fuzzy_tree(self, depth: int = 0, max_depth: int = None) -> AdvancedFuzzyDecisionNode:
        """ãƒ©ãƒ³ãƒ€ãƒ ãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨ç”Ÿæˆ"""

        if max_depth is None:
            max_depth = self.parameters.max_depth

        # ãƒªãƒ¼ãƒ•ãƒãƒ¼ãƒ‰æ¡ä»¶
        if (depth >= max_depth or
            random.random() < 0.3 or
                depth > 0 and random.random() < 0.1 * depth):

            # ãƒªãƒ¼ãƒ•å€¤ã¯ãƒ©ãƒ³ãƒ€ãƒ ï¼ˆ0-1ï¼‰
            leaf_value = random.uniform(0.0, 1.0)
            return AdvancedFuzzyDecisionNode(leaf_value=leaf_value)

        # å†…éƒ¨ãƒãƒ¼ãƒ‰ç”Ÿæˆ
        node = AdvancedFuzzyDecisionNode(
            feature_name=random.choice(self.feature_names)
        )

        # ãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—é–¢æ•°ç”Ÿæˆ
        num_mfs = random.randint(
            self.parameters.min_membership_functions,
            self.parameters.max_membership_functions
        )

        mf_labels = ['low', 'medium', 'high', 'very_high'][:num_mfs]

        for i, label in enumerate(mf_labels):
            mf = self._generate_random_membership_function(label, i, num_mfs)
            node.add_membership_function(label, mf)

            # å­ãƒãƒ¼ãƒ‰ç”Ÿæˆ
            child = self._generate_random_fuzzy_tree(depth + 1, max_depth)
            node.add_child(label, child)

        return node

    def _generate_random_membership_function(self, label: str, index: int, total_mfs: int) -> MembershipFunction:
        """ãƒ©ãƒ³ãƒ€ãƒ ãƒ¡ãƒ³ãƒãƒ¼ã‚·ãƒƒãƒ—é–¢æ•°ç”Ÿæˆ"""

        # ã‚¿ã‚¤ãƒ—é¸æŠ
        mf_types = [MembershipType.TRIANGULAR,
                    MembershipType.GAUSSIAN, MembershipType.TRAPEZOIDAL]
        mf_type = random.choice(mf_types)

        # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆ0-10ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
        if mf_type == MembershipType.TRIANGULAR:
            # ä¸‰è§’å½¢: [a, b, c] where a < b < c
            center = (index + 0.5) * 10.0 / total_mfs
            spread = 10.0 / total_mfs * 0.8
            a = max(0, center - spread)
            b = center
            c = min(10, center + spread)
            parameters = [a, b, c]

        elif mf_type == MembershipType.GAUSSIAN:
            # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³: [center, sigma]
            center = (index + 0.5) * 10.0 / total_mfs
            sigma = 10.0 / total_mfs * 0.5
            parameters = [center, sigma]

        else:  # TRAPEZOIDAL
            # å°å½¢: [a, b, c, d]
            center = (index + 0.5) * 10.0 / total_mfs
            spread = 10.0 / total_mfs * 0.6
            a = max(0, center - spread)
            b = max(0, center - spread * 0.5)
            c = min(10, center + spread * 0.5)
            d = min(10, center + spread)
            parameters = [a, b, c, d]

        return MembershipFunction(label, mf_type, parameters)

    def _evaluate_individual_fitness(self, individual: Individual) -> float:
        """å€‹ä½“é©å¿œåº¦è©•ä¾¡"""

        try:
            if individual.tree is None:
                return 0.0

            # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
            predictions = []
            targets = []

            for _, row in self.training_data.iterrows():
                features = {
                    'research_intensity': row.get('research_intensity', 5.0),
                    'advisor_style': row.get('advisor_style', 5.0),
                    'team_work': row.get('team_work', 5.0),
                    'workload': row.get('workload', 5.0),
                    'theory_practice': row.get('theory_practice', 5.0)
                }

                prediction = individual.tree.predict(features)
                target = row.get(self.target_column, 0.5)

                predictions.append(prediction)
                targets.append(target)

            predictions = np.array(predictions)
            targets = np.array(targets)

            # å¤šç›®çš„è©•ä¾¡
            evaluation_results = self.evaluator.evaluate_individual(
                individual, predictions, targets
            )

            # é©å¿œåº¦æˆåˆ†è¨ˆç®—
            accuracy = evaluation_results['accuracy'].normalized_value
            simplicity = evaluation_results['simplicity'].normalized_value
            interpretability = evaluation_results['interpretability'].normalized_value
            generalization = evaluation_results['generalization'].normalized_value
            validity = evaluation_results['validity'].normalized_value

            # ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹æˆåˆ†ä¿å­˜
            individual.fitness_components = FitnessComponents(
                accuracy=accuracy,
                simplicity=simplicity,
                interpretability=interpretability,
                generalization=generalization,
                validity=validity
            )

            # ç·åˆé©å¿œåº¦
            overall_fitness = individual.fitness_components.compute_overall()

            return overall_fitness

        except Exception as e:
            print(f"âš ï¸ Fitness evaluation error: {e}")
            return 0.0

    def _create_next_generation(self, population: List[Individual]) -> List[Individual]:
        """æ¬¡ä¸–ä»£ç”Ÿæˆ"""

        next_generation = []

        # ã‚¨ãƒªãƒ¼ãƒˆä¿å­˜
        elite_count = min(self.parameters.elite_size, len(population))
        for i in range(elite_count):
            elite = copy.deepcopy(population[i])
            elite.generation += 1
            next_generation.append(elite)

        # æ®‹ã‚Šã‚’äº¤å‰ãƒ»çªç„¶å¤‰ç•°ã§ç”Ÿæˆ
        while len(next_generation) < self.parameters.population_size:
            # è¦ªé¸æŠï¼ˆãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆé¸æŠï¼‰
            parent1 = self._tournament_selection(population)
            parent2 = self._tournament_selection(population)

            # äº¤å‰
            if random.random() < self.parameters.crossover_rate:
                child1, child2 = self._crossover(parent1, parent2)
            else:
                child1, child2 = copy.deepcopy(parent1), copy.deepcopy(parent2)

            # çªç„¶å¤‰ç•°
            if random.random() < self.parameters.mutation_rate:
                child1 = self._mutate(child1)
            if random.random() < self.parameters.mutation_rate:
                child2 = self._mutate(child2)

            # è©•ä¾¡
            child1.fitness_value = self._evaluate_individual_fitness(child1)
            child2.fitness_value = self._evaluate_individual_fitness(child2)

            next_generation.extend([child1, child2])

        return next_generation[:self.parameters.population_size]

    def _tournament_selection(self, population: List[Individual]) -> Individual:
        """ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆé¸æŠ"""
        tournament_size = min(self.parameters.tournament_size, len(population))
        tournament = random.sample(population, tournament_size)
        return max(tournament, key=lambda x: x.fitness_value)

    def _crossover(self, parent1: Individual, parent2: Individual) -> Tuple[Individual, Individual]:
        """äº¤å‰æ“ä½œ"""

        try:
            # æ–°å€‹ä½“ä½œæˆ
            child1 = Individual(
                individual_id=str(uuid.uuid4())[:8],
                generation=parent1.generation + 1
            )

            child2 = Individual(
                individual_id=str(uuid.uuid4())[:8],
                generation=parent2.generation + 1
            )

            # ç°¡æ˜“äº¤å‰ï¼šè¦ªã®æœ¨ã‚’ãƒ©ãƒ³ãƒ€ãƒ é¸æŠ
            child1.tree = copy.deepcopy(
                random.choice([parent1.tree, parent2.tree]))
            child2.tree = copy.deepcopy(
                random.choice([parent1.tree, parent2.tree]))

            # ã‚²ãƒãƒ æ›´æ–°
            child1.genome = self._tree_to_genome(child1.tree)
            child2.genome = self._tree_to_genome(child2.tree)

            # è¤‡é›‘åº¦æ›´æ–°
            child1.complexity_score = child1.tree.calculate_complexity()
            child2.complexity_score = child2.tree.calculate_complexity()

            return child1, child2

        except Exception as e:
            print(f"âš ï¸ Crossover error: {e}")
            return parent1, parent2

    def _mutate(self, individual: Individual) -> Individual:
        """çªç„¶å¤‰ç•°"""

        try:
            # æ–°å€‹ä½“ä½œæˆ
            mutant = copy.deepcopy(individual)
            mutant.individual_id = str(uuid.uuid4())[:8]

            # ç°¡æ˜“çªç„¶å¤‰ç•°ï¼šæ–°ã—ã„æœ¨ã‚’ç”Ÿæˆ
            if random.random() < 0.5:
                mutant.tree = self._generate_random_fuzzy_tree()

            # ã‚²ãƒãƒ æ›´æ–°
            mutant.genome = self._tree_to_genome(mutant.tree)
            mutant.complexity_score = mutant.tree.calculate_complexity()

            return mutant

        except Exception as e:
            print(f"âš ï¸ Mutation error: {e}")
            return individual

    def _collect_nodes(self, tree: AdvancedFuzzyDecisionNode) -> List[AdvancedFuzzyDecisionNode]:
        """ãƒãƒ¼ãƒ‰åé›†"""

        nodes = [tree]

        if not tree.is_leaf:
            for child in tree.children.values():
                nodes.extend(self._collect_nodes(child))

        return nodes

    def _tree_to_genome(self, tree: AdvancedFuzzyDecisionNode) -> Dict[str, Any]:
        """æœ¨ã‚’ã‚²ãƒãƒ è¡¨ç¾ã«å¤‰æ›"""

        genome = {
            'tree_structure': tree.get_tree_structure(),
            'complexity': tree.calculate_complexity(),
            'depth': tree.calculate_depth(),
            'feature_usage': {}
        }

        # ç‰¹å¾´ä½¿ç”¨çµ±è¨ˆ
        nodes = self._collect_nodes(tree)
        for node in nodes:
            if not node.is_leaf and node.feature_name:
                feature = node.feature_name
                genome['feature_usage'][feature] = genome['feature_usage'].get(
                    feature, 0) + 1

        return genome

    def _calculate_population_diversity(self, population: List[Individual]) -> float:
        """å€‹ä½“ç¾¤å¤šæ§˜æ€§è¨ˆç®—"""

        if len(population) < 2:
            return 0.0

        # è¤‡é›‘åº¦ã®å¤šæ§˜æ€§
        complexities = [ind.complexity_score for ind in population]
        complexity_diversity = np.std(
            complexities) / max(1, np.mean(complexities))

        # é©å¿œåº¦ã®å¤šæ§˜æ€§
        fitness_values = [ind.fitness_value for ind in population]
        fitness_diversity = np.std(fitness_values) / \
            max(0.001, np.mean(fitness_values))

        return (complexity_diversity + fitness_diversity) / 2.0

    def _check_convergence(self, generation: int) -> bool:
        """åæŸãƒã‚§ãƒƒã‚¯"""

        # æœ€ä½ä¸–ä»£æ•°
        if generation < 5:
            return False

        # é©å¿œåº¦å±¥æ­´ã§ã®åæŸãƒã‚§ãƒƒã‚¯
        recent_best = self.evolution_stats['best_fitness_history'][-5:]

        if len(recent_best) >= 5:
            variance = np.var(recent_best)
            if variance < 0.001:  # åˆ†æ•£ãŒå°ã•ã„
                return True

        # å¤šæ§˜æ€§ã«ã‚ˆã‚‹åæŸãƒã‚§ãƒƒã‚¯
        recent_diversity = self.evolution_stats['diversity_history'][-3:]

        if len(recent_diversity) >= 3:
            avg_diversity = np.mean(recent_diversity)
            if avg_diversity < 0.05:  # å¤šæ§˜æ€§ãŒä½ã„
                return True

        return False

    def _compile_final_result(self, best_individual: Individual,
                              final_population: List[Individual]) -> Dict[str, Any]:
        """æœ€çµ‚çµæœã‚³ãƒ³ãƒ‘ã‚¤ãƒ«"""

        result = {
            'best_individual': best_individual,
            'best_fitness': best_individual.fitness_value if best_individual else 0.0,
            'best_fitness_components': best_individual.fitness_components.__dict__ if best_individual and best_individual.fitness_components else {},
            'final_population_size': len(final_population),
            'final_diversity': self._calculate_population_diversity(final_population),
            'evolution_stats': self.evolution_stats,
            'optimization_config': self.parameters.__dict__,
            'feature_names': self.feature_names,
            'convergence_analysis': self._analyze_convergence()
        }

        # æœ€è‰¯å€‹ä½“ã®è©³ç´°åˆ†æ
        if best_individual and best_individual.tree:
            result['best_tree_analysis'] = {
                'complexity': best_individual.tree.calculate_complexity(),
                'depth': best_individual.tree.calculate_depth(),
                'structure_summary': TreeVisualizationHelper.generate_tree_summary(best_individual.tree),
                'feature_importance': self._analyze_feature_importance(best_individual.tree)
            }

        return result

    def _analyze_convergence(self) -> Dict[str, Any]:
        """åæŸåˆ†æ"""

        if len(self.evolution_stats['best_fitness_history']) < 3:
            return {'convergence_detected': False, 'stagnation_generations': 0}

        fitness_history = self.evolution_stats['best_fitness_history']

        # åœæ»ä¸–ä»£æ•°è¨ˆç®—
        stagnation_count = 0
        threshold = 0.001

        for i in range(1, len(fitness_history)):
            if abs(fitness_history[i] - fitness_history[i-1]) < threshold:
                stagnation_count += 1
            else:
                stagnation_count = 0

        convergence_detected = stagnation_count >= 5

        return {
            'convergence_detected': convergence_detected,
            'stagnation_generations': stagnation_count,
            'final_improvement': fitness_history[-1] - fitness_history[0] if len(fitness_history) > 1 else 0.0
        }

    def _analyze_feature_importance(self, tree: AdvancedFuzzyDecisionNode) -> Dict[str, float]:
        """ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ"""

        feature_usage = {}

        def analyze_node(node: AdvancedFuzzyDecisionNode, depth: int = 0):
            """å†å¸°çš„ã«ãƒãƒ¼ãƒ‰ã‚’åˆ†æ"""
            if not node.is_leaf and node.feature_name:
                feature = node.feature_name
                # æ·±åº¦ã«åŸºã¥ãé‡ã¿ä»˜ã‘ï¼ˆæ·±ã„æ–¹ãŒé‡è¦åº¦ä½ã„ï¼‰
                weight = 1.0 / (depth + 1)
                feature_usage[feature] = feature_usage.get(
                    feature, 0.0) + weight

            # å­ãƒãƒ¼ãƒ‰ã‚’å†å¸°çš„ã«å‡¦ç†
            if not node.is_leaf:
                for child in node.children.values():
                    analyze_node(child, depth + 1)

        # ãƒ«ãƒ¼ãƒˆã‹ã‚‰åˆ†æé–‹å§‹
        analyze_node(tree, 0)

        # æ­£è¦åŒ–
        total_usage = sum(feature_usage.values())
        if total_usage > 0:
            for feature in feature_usage:
                feature_usage[feature] /= total_usage

        return feature_usage

    def predict_with_explanation(self, individual: Individual, user_prefs: Dict, lab_features: Dict) -> Tuple[float, str]:
        """èª¬æ˜ä»˜ãäºˆæ¸¬"""

        if not individual or not individual.tree:
            return 0.5, "No valid tree available"

        # ç‰¹å¾´é‡ãƒ™ã‚¯ãƒˆãƒ«ä½œæˆ
        features = {}
        for criterion in self.feature_names:
            user_val = user_prefs.get(criterion, 5.0)
            lab_val = lab_features.get(criterion, 5.0)
            # é¡ä¼¼åº¦è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            similarity = 1.0 - abs(user_val - lab_val) / 10.0
            features[criterion] = max(
                0.0, min(1.0, similarity)) * 10.0  # 0-10ã‚¹ã‚±ãƒ¼ãƒ«

        # äºˆæ¸¬å®Ÿè¡Œ
        try:
            prediction, explanation_data = individual.tree.predict_with_explanation(
                features, self.feature_names)

            # èª¬æ˜æ–‡ç”Ÿæˆ
            explanation = f"éºä¼çš„ãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨ã«ã‚ˆã‚‹äºˆæ¸¬: {prediction:.1%}\n"
            explanation += f"é©å¿œåº¦: {individual.fitness_value:.3f}\n"
            explanation += f"æœ¨ã®è¤‡é›‘åº¦: {individual.tree.calculate_complexity()}\n"
            explanation += f"æ±ºå®šçµŒè·¯ã®ä¿¡é ¼åº¦: {explanation_data.get('confidence', 0.8):.1%}"

            return prediction, explanation

        except Exception as e:
            return 0.5, f"Prediction error: {e}"


# ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨é–¢æ•°
def run_genetic_optimization_demo():
    """éºä¼çš„æœ€é©åŒ–ãƒ‡ãƒ¢å®Ÿè¡Œ"""
    print("ğŸ§¬ Genetic Fuzzy Tree Optimization Demo")
    print("=" * 50)

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    n_samples = 500

    data = []
    for i in range(n_samples):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼è¨­å®š
        user_research = np.random.uniform(1, 10)
        user_advisor = np.random.uniform(1, 10)
        user_team = np.random.uniform(1, 10)
        user_workload = np.random.uniform(1, 10)
        user_theory = np.random.uniform(1, 10)

        # ç ”ç©¶å®¤ç‰¹å¾´
        lab_research = np.random.uniform(1, 10)
        lab_advisor = np.random.uniform(1, 10)
        lab_team = np.random.uniform(1, 10)
        lab_workload = np.random.uniform(1, 10)
        lab_theory = np.random.uniform(1, 10)

        # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³é¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹é©åˆåº¦è¨ˆç®—
        weights = [0.25, 0.20, 0.20, 0.15, 0.20]
        sigma = 2.0

        similarities = []
        criteria_pairs = [
            (user_research, lab_research),
            (user_advisor, lab_advisor),
            (user_team, lab_team),
            (user_workload, lab_workload),
            (user_theory, lab_theory)
        ]

        for (user_val, lab_val) in criteria_pairs:
            similarity = np.exp(-((user_val - lab_val)
                                ** 2) / (2 * sigma ** 2))
            similarities.append(similarity)

        compatibility = sum(w * s for w, s in zip(weights, similarities))
        compatibility += np.random.normal(0, 0.05)
        compatibility = max(0.1, min(0.9, compatibility))

        sample = {
            'research_intensity': user_research,
            'advisor_style': user_advisor,
            'team_work': user_team,
            'workload': user_workload,
            'theory_practice': user_theory,
            'compatibility': compatibility
        }
        data.append(sample)

    df = pd.DataFrame(data)
    print(f"ğŸ“Š Generated {len(df)} training samples")
    print(
        f"ğŸ“ˆ Compatibility stats: mean={df['compatibility'].mean():.3f}, std={df['compatibility'].std():.3f}")

    # æœ€é©åŒ–å®Ÿè¡Œ
    parameters = GeneticParameters(
        population_size=20,
        generations=15,
        mutation_rate=0.15,
        crossover_rate=0.8
    )

    optimizer = GeneticFuzzyTreeOptimizer(parameters, random_seed=42)
    result = optimizer.optimize(df)

    print(f"\nâœ… Optimization completed!")
    print(f"ğŸ¯ Best fitness: {result['best_fitness']:.4f}")
    print(
        f"ğŸ“ˆ Generations completed: {len(result['evolution_stats']['best_fitness_history'])}")

    # ãƒ†ã‚¹ãƒˆäºˆæ¸¬
    if result['best_individual']:
        print(f"\nğŸ¯ Test Predictions:")

        test_cases = [
            {
                'name': 'ç†è«–é‡è¦–å­¦ç”Ÿ',
                'user_prefs': {'research_intensity': 9, 'advisor_style': 4, 'team_work': 5, 'workload': 8, 'theory_practice': 3},
                'lab_features': {'research_intensity': 8.5, 'advisor_style': 4, 'team_work': 5, 'workload': 7.5, 'theory_practice': 3}
            },
            {
                'name': 'å®Ÿè·µé‡è¦–å­¦ç”Ÿ',
                'user_prefs': {'research_intensity': 7, 'advisor_style': 8, 'team_work': 9, 'workload': 6, 'theory_practice': 9},
                'lab_features': {'research_intensity': 7.2, 'advisor_style': 7.8, 'team_work': 8.7, 'workload': 6.3, 'theory_practice': 8.5}
            }
        ]

        for case in test_cases:
            prediction, explanation = optimizer.predict_with_explanation(
                result['best_individual'],
                case['user_prefs'],
                case['lab_features']
            )
            print(f"   {case['name']}: {prediction*100:.1f}%")

    # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    model_path = f"models/genetic_model_{timestamp}.pkl"

    try:
        import pickle
        import os
        os.makedirs("models", exist_ok=True)

        with open(model_path, 'wb') as f:
            pickle.dump(result, f)
        print(f"ğŸ’¾ Model saved successfully: {model_path}")
    except Exception as e:
        print(f"âš ï¸ Model save failed: {e}")

    return result


# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
def create_genetic_optimizer(population_size: int = 50,
                             generations: int = 30,
                             mutation_rate: float = 0.15,
                             crossover_rate: float = 0.8,
                             random_seed: int = None) -> GeneticFuzzyTreeOptimizer:
    """éºä¼çš„æœ€é©åŒ–å™¨ä½œæˆ"""

    parameters = GeneticParameters(
        population_size=population_size,
        generations=generations,
        mutation_rate=mutation_rate,
        crossover_rate=crossover_rate
    )

    return GeneticFuzzyTreeOptimizer(parameters, random_seed)


def evaluate_individual_performance(individual: Individual,
                                    test_data: pd.DataFrame,
                                    target_column: str = 'compatibility') -> Dict[str, float]:
    """å€‹ä½“æ€§èƒ½è©•ä¾¡"""

    if not individual or not individual.tree:
        return {'error': 'Invalid individual or tree'}

    predictions = []
    targets = []

    for _, row in test_data.iterrows():
        features = {
            'research_intensity': row.get('research_intensity', 5.0),
            'advisor_style': row.get('advisor_style', 5.0),
            'team_work': row.get('team_work', 5.0),
            'workload': row.get('workload', 5.0),
            'theory_practice': row.get('theory_practice', 5.0)
        }

        prediction = individual.tree.predict(features)
        target = row.get(target_column, 0.5)

        predictions.append(prediction)
        targets.append(target)

    predictions = np.array(predictions)
    targets = np.array(targets)

    # æ€§èƒ½æŒ‡æ¨™è¨ˆç®—
    mse = np.mean((predictions - targets) ** 2)
    mae = np.mean(np.abs(predictions - targets))

    # ç›¸é–¢ä¿‚æ•°
    correlation = np.corrcoef(predictions, targets)[
        0, 1] if len(predictions) > 1 else 0.0

    return {
        'mse': float(mse),
        'mae': float(mae),
        'rmse': float(np.sqrt(mse)),
        'correlation': float(correlation) if not np.isnan(correlation) else 0.0,
        'complexity': individual.tree.calculate_complexity(),
        'depth': individual.tree.calculate_depth(),
        'fitness': individual.fitness_value
    }


def save_genetic_model(result: Dict[str, Any], filepath: str):
    """éºä¼çš„ãƒ¢ãƒ‡ãƒ«ä¿å­˜"""

    try:
        import pickle
        import os

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

        # ãƒ¢ãƒ‡ãƒ«ãƒ‡ãƒ¼ã‚¿æº–å‚™
        model_data = {
            'best_individual': result['best_individual'],
            'optimization_results': {
                'best_fitness': result['best_fitness'],
                'final_diversity': result['final_diversity'],
                'evolution_stats': result['evolution_stats'],
                'convergence_analysis': result['convergence_analysis']
            },
            'metadata': {
                'saved_at': time.strftime("%Y-%m-%d %H:%M:%S"),
                'feature_names': result['feature_names'],
                'optimization_config': result['optimization_config']
            }
        }

        # ä¿å­˜
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)

        print(f"ğŸ’¾ Genetic model saved: {filepath}")
        return True

    except Exception as e:
        print(f"âŒ Failed to save model: {e}")
        return False


def load_genetic_model(filepath: str) -> Dict[str, Any]:
    """éºä¼çš„ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿"""

    try:
        import pickle

        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)

        print(f"âœ… Genetic model loaded: {filepath}")
        return model_data

    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        return {}


# ãƒ†ã‚¹ãƒˆå®Ÿè¡Œ
if __name__ == '__main__':
    try:
        result = run_genetic_optimization_demo()
        print("ğŸ‰ Demo completed successfully!")
    except Exception as e:
        print(f"âŒ Demo failed: {e}")
        import traceback
        traceback.print_exc()
