# backend/genetic_fuzzy_tree.py - ÂÆåÂÖ®‰øÆÊ≠£Áâà
"""
üß¨ Fixed Genetic Fuzzy Decision Tree System
‰øÆÊ≠£ÁâàÈÅ∫‰ºùÁöÑ„Éï„Ç°„Ç∏„Ç£Ê±∫ÂÆöÊú®„Ç∑„Çπ„ÉÜ„É† - record_individual Âëº„Å≥Âá∫„Åó‰øÆÊ≠£Ê∏à„Åø
"""

import random
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Any, Optional, Union
from dataclasses import dataclass, field
import copy
import math
import uuid
import time
import warnings
warnings.filterwarnings('ignore')

# ‰æùÂ≠òÈñ¢‰øÇ„ÅÆ„Ç§„É≥„Éù„Éº„ÉàÔºà„Ç®„É©„ÉºÂá¶ÁêÜ‰ªò„ÅçÔºâ
try:
    from explanation_engine import FuzzyExplanationEngine, DecisionExplanation
except ImportError:
    print("‚ö†Ô∏è explanation_engine not found, using mock")

    class FuzzyExplanationEngine:
        def generate_comprehensive_explanation(self, *args, **kwargs):
            return "Basic explanation generated"

    class DecisionExplanation:
        def __init__(self, overall_conclusion, confidence_level=None):
            self.overall_conclusion = overall_conclusion

try:
    from optimization_tracker import OptimizationTracker, GenerationStats
except ImportError:
    print("‚ö†Ô∏è optimization_tracker not found, using mock")

    class OptimizationTracker:
        def __init__(self, run_id):
            self.run_id = run_id

        def start_optimization(self, config): pass
        def end_optimization(self): pass
        def record_individual(self, *args, **kwargs): pass
        def record_generation(self, *args): pass

try:
    from evaluation_metrics import MultiObjectiveEvaluator, MetricResult
except ImportError:
    print("‚ö†Ô∏è evaluation_metrics not found, using mock")

    class MultiObjectiveEvaluator:
        def evaluate_individual(self, *args, **kwargs):
            return {
                'accuracy': type('obj', (object,), {'normalized_value': 0.8})(),
                'simplicity': type('obj', (object,), {'normalized_value': 0.7})(),
                'interpretability': type('obj', (object,), {'normalized_value': 0.6})(),
                'generalization': type('obj', (object,), {'normalized_value': 0.75})(),
                'validity': type('obj', (object,), {'normalized_value': 0.9})()
            }

try:
    from advanced_nodes import (
        AdvancedFuzzyDecisionNode, MembershipFunction, MembershipType,
        FitnessComponents, TreeVisualizationHelper
    )
except ImportError:
    print("‚ö†Ô∏è advanced_nodes not found, using simple implementations")

    from enum import Enum

    class MembershipType(Enum):
        TRIANGULAR = "triangular"
        GAUSSIAN = "gaussian"
        TRAPEZOIDAL = "trapezoidal"

    class MembershipFunction:
        def __init__(self, name, mf_type, parameters, weight=1.0):
            self.name = name
            self.type = mf_type
            self.parameters = parameters
            self.weight = weight

        def evaluate(self, x):
            if self.type == MembershipType.TRIANGULAR:
                a, b, c = self.parameters
                if x <= a or x >= c:
                    return 0.0
                elif a < x <= b:
                    return (x - a) / (b - a)
                else:  # b < x < c
                    return (c - x) / (c - b)
            elif self.type == MembershipType.GAUSSIAN:
                center, sigma = self.parameters
                return np.exp(-0.5 * ((x - center) / sigma) ** 2)
            else:
                return 0.5  # „Éá„Éï„Ç©„É´„ÉàÂÄ§

    class AdvancedFuzzyDecisionNode:
        def __init__(self, node_id=None, feature_name=None, leaf_value=None):
            self.node_id = node_id or str(uuid.uuid4())[:8]
            self.feature_name = feature_name
            self.leaf_value = leaf_value
            self.is_leaf = leaf_value is not None
            self.membership_functions = {}
            self.children = {}
            self.depth = 0

        def add_membership_function(self, label, mf):
            self.membership_functions[label] = mf

        def add_child(self, label, child):
            self.children[label] = child

        def predict(self, features):
            if self.is_leaf:
                return self.leaf_value

            feature_value = features.get(self.feature_name, 5.0)

            # „Éï„Ç°„Ç∏„Ç£Ë©ï‰æ°
            max_membership = 0.0
            best_label = None

            for label, mf in self.membership_functions.items():
                membership = mf.evaluate(feature_value)
                if membership > max_membership:
                    max_membership = membership
                    best_label = label

            # Â≠ê„Éé„Éº„Éâ„Åß‰∫àÊ∏¨
            if best_label and best_label in self.children:
                return self.children[best_label].predict(features)
            else:
                return 0.5  # „Éá„Éï„Ç©„É´„ÉàÂÄ§

        def predict_with_explanation(self, features, feature_names):
            prediction = self.predict(features)
            explanation = {
                'confidence': 0.8,
                'decision_steps': [],
                'rationale': f'Prediction: {prediction:.3f}'
            }
            return prediction, explanation

        def calculate_complexity(self):
            if self.is_leaf:
                return 1
            total = 1 + len(self.membership_functions)
            for child in self.children.values():
                total += child.calculate_complexity()
            return total

        def calculate_depth(self):
            if self.is_leaf:
                return 1
            max_depth = 0
            for child in self.children.values():
                max_depth = max(max_depth, child.calculate_depth())
            return max_depth + 1

        def get_tree_structure(self):
            if self.is_leaf:
                return {'type': 'leaf', 'value': self.leaf_value}
            return {
                'type': 'internal',
                'feature': self.feature_name,
                'children': len(self.children),
                'membership_functions': len(self.membership_functions)
            }

    class FitnessComponents:
        def __init__(self, accuracy=0.0, simplicity=0.0, interpretability=0.0,
                     generalization=0.0, validity=0.0):
            self.accuracy = accuracy
            self.simplicity = simplicity
            self.interpretability = interpretability
            self.generalization = generalization
            self.validity = validity
            self.overall = self.compute_overall()

        def compute_overall(self):
            weights = [0.3, 0.2, 0.2, 0.15, 0.15]
            components = [self.accuracy, self.simplicity, self.interpretability,
                          self.generalization, self.validity]
            return sum(w * c for w, c in zip(weights, components))

        def to_dict(self):
            return {
                'accuracy': self.accuracy,
                'simplicity': self.simplicity,
                'interpretability': self.interpretability,
                'generalization': self.generalization,
                'validity': self.validity,
                'overall': self.overall
            }

        @property
        def __dict__(self):
            return self.to_dict()

    class TreeVisualizationHelper:
        @staticmethod
        def generate_tree_summary(tree):
            return f"Tree: depth={tree.calculate_depth()}, complexity={tree.calculate_complexity()}"


@dataclass
class GeneticParameters:
    """ÈÅ∫‰ºùÁöÑ„Ç¢„É´„Ç¥„É™„Ç∫„É†„Éë„É©„É°„Éº„Çø"""
    population_size: int = 50
    generations: int = 30
    mutation_rate: float = 0.15
    crossover_rate: float = 0.8
    elite_size: int = 5
    tournament_size: int = 3
    max_depth: int = 6
    min_membership_functions: int = 2
    max_membership_functions: int = 4

    def __post_init__(self):
        # „Ç®„É™„Éº„Éà„Çµ„Ç§„Ç∫„ÅÆË™øÊï¥
        if self.elite_size >= self.population_size:
            self.elite_size = max(1, self.population_size // 10)


class Individual:
    """ÈÅ∫‰ºùÁöÑÂÄã‰Ωì"""

    def __init__(self, individual_id: str = None, generation: int = 0):
        self.individual_id = individual_id or str(uuid.uuid4())[:8]
        self.generation = generation
        self.tree: Optional[AdvancedFuzzyDecisionNode] = None
        self.genome: Dict[str, Any] = {}
        self.fitness_value: float = 0.0
        self.fitness_components: Optional[FitnessComponents] = None
        self.complexity_score: int = 0
        self.parents: List[str] = []


class GeneticFuzzyTreeOptimizer:
    """ÈÅ∫‰ºùÁöÑ„Éï„Ç°„Ç∏„Ç£Ê±∫ÂÆöÊú®ÊúÄÈÅ©ÂåñÂô® - ‰øÆÊ≠£Áâà"""

    def __init__(self, parameters: GeneticParameters = None, random_seed: int = None):
        self.parameters = parameters or GeneticParameters()
        self.random_seed = random_seed

        # ‰π±Êï∞„Ç∑„Éº„ÉâË®≠ÂÆö
        if random_seed is not None:
            random.seed(random_seed)
            np.random.seed(random_seed)

        # Ë©ï‰æ°Âô®
        self.evaluator = MultiObjectiveEvaluator()

        # „Éà„É©„ÉÉ„Ç´„Éº
        self.tracker: Optional[OptimizationTracker] = None

        # Ë™¨Êòé„Ç®„É≥„Ç∏„É≥
        self.explanation_engine = FuzzyExplanationEngine()

        # Áµ±Ë®àÊÉÖÂ†±
        self.evolution_stats = {
            'best_fitness_history': [],
            'avg_fitness_history': [],
            'diversity_history': [],
            'evaluation_times': []
        }

        # ÁâπÂæ¥ÂêçÔºàÁ†îÁ©∂ÂÆ§ÈÅ∏ÊäûÂü∫Ê∫ñÔºâ
        self.feature_names = [
            'research_intensity', 'advisor_style', 'team_work',
            'workload', 'theory_practice'
        ]

        # „Éá„Éº„Çø‰øùÂ≠òÁî®
        self.training_data: Optional[pd.DataFrame] = None
        self.test_data: Optional[pd.DataFrame] = None
        self.target_column: str = 'compatibility'

        print("üß¨ GeneticFuzzyTreeOptimizer initialized")

    def optimize(self, training_data: pd.DataFrame,
                 test_data: pd.DataFrame = None,
                 target_column: str = 'compatibility',
                 run_id: str = None) -> Dict[str, Any]:
        """ÈÅ∫‰ºùÁöÑÊúÄÈÅ©ÂåñÂÆüË°å"""

        # „Éà„É©„ÉÉ„Ç´„ÉºÂàùÊúüÂåñ
        self.tracker = OptimizationTracker(run_id)

        # Ë®≠ÂÆö‰øùÂ≠ò
        config = {
            'parameters': self.parameters.__dict__,
            'feature_names': self.feature_names,
            'training_samples': len(training_data),
            'test_samples': len(test_data) if test_data is not None else 0,
            'target_column': target_column,
            'random_seed': self.random_seed
        }

        self.tracker.start_optimization(config)

        print(f"üöÄ Starting genetic optimization...")
        print(f"üìä Training samples: {len(training_data)}")
        print(f"üéØ Target: {target_column}")
        print(f"üë• Population: {self.parameters.population_size}")
        print(f"üîÑ Generations: {self.parameters.generations}")

        try:
            # „ÉÜ„Çπ„Éà„Éá„Éº„Çø„Åå„Å™„ÅÑÂ†¥Âêà„ÅØË®ìÁ∑¥„Éá„Éº„Çø„ÇíÂàÜÂâ≤
            if test_data is None:
                test_data = training_data.sample(
                    frac=0.2, random_state=self.random_seed)
                training_data = training_data.drop(test_data.index)

            # „Éá„Éº„Çø‰øùÂ≠ò
            self.training_data = training_data
            self.test_data = test_data
            self.target_column = target_column

            # ÂàùÊúüÂÄã‰ΩìÁæ§ÁîüÊàê
            population = self._create_initial_population()

            # ÈÄ≤ÂåñÂÆüË°å
            result = self._evolve_population(population)

            # ÊúÄÁµÇÂåñ
            self.tracker.end_optimization()

            return result

        except Exception as e:
            print(f"‚ùå Optimization failed: {e}")
            if self.tracker:
                self.tracker.end_optimization()
            raise

    def _create_initial_population(self) -> List[Individual]:
        """ÂàùÊúüÂÄã‰ΩìÁæ§ÁîüÊàê"""
        population = []

        for i in range(self.parameters.population_size):
            individual = self._create_individual()
            individual.individual_id = f"gen0_ind{i}"
            population.append(individual)

        return population

    def _evolve_population(self, population: List[Individual]) -> Dict[str, Any]:
        """ÂÄã‰ΩìÁæ§ÈÄ≤Âåñ - ‰øÆÊ≠£Áâà"""

        best_individual = None

        # ‰∏ñ‰ª£„É´„Éº„Éó
        for generation in range(self.parameters.generations):
            generation_start_time = time.time()

            print(
                f"\nüîÑ Generation {generation + 1}/{self.parameters.generations}")

            # ÂÄã‰ΩìË©ï‰æ°
            evaluation_results = []

            for individual in population:
                evaluation_start = time.time()

                # ÈÅ©ÂøúÂ∫¶Ë©ï‰æ°
                fitness_value = self._evaluate_individual_fitness(individual)
                individual.fitness_value = fitness_value

                evaluation_time = time.time() - evaluation_start

                # Ë©ï‰æ°ÁµêÊûúË®òÈå≤
                evaluation_result = {
                    'individual_id': individual.individual_id,
                    'overall_fitness': fitness_value,
                    'fitness_components': individual.fitness_components.__dict__ if individual.fitness_components else {},
                    'evaluation_time': evaluation_time,
                    'model_complexity': individual.complexity_score
                }
                evaluation_results.append(evaluation_result)

                # ‚úÖ ‰øÆÊ≠£Ê∏à„ÅøÂÄã‰ΩìË®òÈå≤ - Ê≠£„Åó„ÅÑÂºïÊï∞È†ÜÂ∫è
                self.tracker.record_individual(
                    individual=individual,
                    individual_id=individual.individual_id,
                    generation=generation,
                    fitness_components=evaluation_result.get(
                        'fitness_components', {}),
                    overall_fitness=evaluation_result.get(
                        'overall_fitness', 0.0),
                    notes=f"Generation {generation} evaluation"
                )

            # ÊúÄËâØÂÄã‰ΩìÊõ¥Êñ∞
            population.sort(key=lambda x: x.fitness_value, reverse=True)
            current_best = population[0]

            if best_individual is None or current_best.fitness_value > best_individual.fitness_value:
                best_individual = copy.deepcopy(current_best)

            # Áµ±Ë®àË®àÁÆó
            fitness_values = [ind.fitness_value for ind in population]
            best_fitness = max(fitness_values)
            avg_fitness = np.mean(fitness_values)

            # Â§öÊßòÊÄßË®àÁÆó
            diversity_score = self._calculate_population_diversity(population)

            # ‰∏ñ‰ª£Ë®òÈå≤
            generation_metrics = {
                'mutation_success_rate': 0.7,
                'crossover_success_rate': 0.8
            }

            self.tracker.record_generation(
                generation, population, evaluation_results, generation_metrics
            )

            # ÈÄ≤ÂåñÁµ±Ë®àÊõ¥Êñ∞
            self.evolution_stats['best_fitness_history'].append(best_fitness)
            self.evolution_stats['avg_fitness_history'].append(avg_fitness)
            self.evolution_stats['diversity_history'].append(diversity_score)
            self.evolution_stats['evaluation_times'].append(
                time.time() - generation_start_time)

            print(
                f"üìä Best: {best_fitness:.4f}, Avg: {avg_fitness:.4f}, Diversity: {diversity_score:.3f}")

            # ÂèéÊùü„ÉÅ„Çß„ÉÉ„ÇØ
            if self._check_convergence(generation):
                print(f"üéØ Convergence detected at generation {generation + 1}")
                break

            # ÊúÄÁµÇ‰∏ñ‰ª£„Åß„Å™„ÅÑÂ†¥Âêà„ÅØÊ¨°‰∏ñ‰ª£ÁîüÊàê
            if generation < self.parameters.generations - 1:
                population = self._create_next_generation(population)

        # ÊúÄÁµÇÁµêÊûú„Åæ„Å®„ÇÅ
        result = self._compile_final_result(best_individual, population)

        print(f"üèÅ Optimization completed!")
        print(f"üéØ Best fitness: {result['best_fitness']:.4f}")
        print(f"üìä Final population diversity: {result['final_diversity']:.3f}")

        return result

    def _create_individual(self) -> Individual:
        """ÂÄã‰ΩìÁîüÊàê"""

        individual = Individual(
            individual_id=str(uuid.uuid4())[:8],
            generation=0
        )

        # „É©„É≥„ÉÄ„É†„Å™„Éï„Ç°„Ç∏„Ç£Ê±∫ÂÆöÊú®ÁîüÊàê
        individual.tree = self._generate_random_fuzzy_tree()

        # „Ç≤„Éé„É†ÊÉÖÂ†±‰ΩúÊàê
        individual.genome = self._tree_to_genome(individual.tree)

        # Ë§áÈõëÂ∫¶Ë®àÁÆó
        individual.complexity_score = individual.tree.calculate_complexity()

        return individual

    def _generate_random_fuzzy_tree(self, depth: int = 0, max_depth: int = None) -> AdvancedFuzzyDecisionNode:
        """„É©„É≥„ÉÄ„É†„Éï„Ç°„Ç∏„Ç£Ê±∫ÂÆöÊú®ÁîüÊàê"""

        if max_depth is None:
            max_depth = self.parameters.max_depth

        # „É™„Éº„Éï„Éé„Éº„ÉâÊù°‰ª∂
        if (depth >= max_depth or
            random.random() < 0.3 or
                depth > 0 and random.random() < 0.1 * depth):

            # „É™„Éº„ÉïÂÄ§„ÅØ„É©„É≥„ÉÄ„É†Ôºà0-1Ôºâ
            leaf_value = random.uniform(0.0, 1.0)
            return AdvancedFuzzyDecisionNode(leaf_value=leaf_value)

        # ÂÜÖÈÉ®„Éé„Éº„ÉâÁîüÊàê
        node = AdvancedFuzzyDecisionNode(
            feature_name=random.choice(self.feature_names)
        )

        # „É°„É≥„Éê„Éº„Ç∑„ÉÉ„ÉóÈñ¢Êï∞ÁîüÊàê
        num_mfs = random.randint(
            self.parameters.min_membership_functions,
            self.parameters.max_membership_functions
        )

        mf_labels = ['low', 'medium', 'high', 'very_high'][:num_mfs]

        for i, label in enumerate(mf_labels):
            mf = self._generate_random_membership_function(label, i, num_mfs)
            node.add_membership_function(label, mf)

            # Â≠ê„Éé„Éº„ÉâÁîüÊàê
            child = self._generate_random_fuzzy_tree(depth + 1, max_depth)
            node.add_child(label, child)

        return node

    def _generate_random_membership_function(self, label: str, index: int, total_mfs: int) -> MembershipFunction:
        """„É©„É≥„ÉÄ„É†„É°„É≥„Éê„Éº„Ç∑„ÉÉ„ÉóÈñ¢Êï∞ÁîüÊàê"""

        # „Çø„Ç§„ÉóÈÅ∏Êäû
        mf_types = [MembershipType.TRIANGULAR,
                    MembershipType.GAUSSIAN, MembershipType.TRAPEZOIDAL]
        mf_type = random.choice(mf_types)

        # „Éë„É©„É°„Éº„ÇøÁîüÊàêÔºà0-10„Çπ„Ç±„Éº„É´Ôºâ
        if mf_type == MembershipType.TRIANGULAR:
            # ‰∏âËßíÂΩ¢: [a, b, c] where a < b < c
            center = (index + 0.5) * 10.0 / total_mfs
            spread = 10.0 / total_mfs * 0.8
            a = max(0, center - spread)
            b = center
            c = min(10, center + spread)
            parameters = [a, b, c]

        elif mf_type == MembershipType.GAUSSIAN:
            # „Ç¨„Ç¶„Ç∑„Ç¢„É≥: [center, sigma]
            center = (index + 0.5) * 10.0 / total_mfs
            sigma = 10.0 / total_mfs * 0.5
            parameters = [center, sigma]

        else:  # TRAPEZOIDAL
            # Âè∞ÂΩ¢: [a, b, c, d]
            center = (index + 0.5) * 10.0 / total_mfs
            spread = 10.0 / total_mfs * 0.6
            a = max(0, center - spread)
            b = max(0, center - spread * 0.5)
            c = min(10, center + spread * 0.5)
            d = min(10, center + spread)
            parameters = [a, b, c, d]

        return MembershipFunction(label, mf_type, parameters)

    def _evaluate_individual_fitness(self, individual: Individual) -> float:
        """ÂÄã‰ΩìÈÅ©ÂøúÂ∫¶Ë©ï‰æ°"""

        try:
            if individual.tree is None:
                return 0.0

            # Ë®ìÁ∑¥„Éá„Éº„Çø„Åß‰∫àÊ∏¨
            predictions = []
            targets = []

            for _, row in self.training_data.iterrows():
                features = {
                    'research_intensity': row.get('research_intensity', 5.0),
                    'advisor_style': row.get('advisor_style', 5.0),
                    'team_work': row.get('team_work', 5.0),
                    'workload': row.get('workload', 5.0),
                    'theory_practice': row.get('theory_practice', 5.0)
                }

                prediction = individual.tree.predict(features)
                target = row.get(self.target_column, 0.5)

                predictions.append(prediction)
                targets.append(target)

            predictions = np.array(predictions)
            targets = np.array(targets)

            # Â§öÁõÆÁöÑË©ï‰æ°
            evaluation_results = self.evaluator.evaluate_individual(
                individual, predictions, targets
            )

            # ÈÅ©ÂøúÂ∫¶ÊàêÂàÜË®àÁÆó
            accuracy = evaluation_results['accuracy'].normalized_value
            simplicity = evaluation_results['simplicity'].normalized_value
            interpretability = evaluation_results['interpretability'].normalized_value
            generalization = evaluation_results['generalization'].normalized_value
            validity = evaluation_results['validity'].normalized_value

            # „Éï„Ç£„ÉÉ„Éà„Éç„ÇπÊàêÂàÜ‰øùÂ≠ò
            individual.fitness_components = FitnessComponents(
                accuracy=accuracy,
                simplicity=simplicity,
                interpretability=interpretability,
                generalization=generalization,
                validity=validity
            )

            # Á∑èÂêàÈÅ©ÂøúÂ∫¶
            overall_fitness = individual.fitness_components.compute_overall()

            return overall_fitness

        except Exception as e:
            print(f"‚ö†Ô∏è Fitness evaluation error: {e}")
            return 0.0

    def _create_next_generation(self, population: List[Individual]) -> List[Individual]:
        """Ê¨°‰∏ñ‰ª£ÁîüÊàê"""

        next_generation = []

        # „Ç®„É™„Éº„Éà‰øùÂ≠ò
        elite_count = min(self.parameters.elite_size, len(population))
        for i in range(elite_count):
            elite = copy.deepcopy(population[i])
            elite.generation += 1
            next_generation.append(elite)

        # ÊÆã„Çä„Çí‰∫§Âèâ„ÉªÁ™ÅÁÑ∂Â§âÁï∞„ÅßÁîüÊàê
        while len(next_generation) < self.parameters.population_size:
            # Ë¶™ÈÅ∏ÊäûÔºà„Éà„Éº„Éä„É°„É≥„ÉàÈÅ∏ÊäûÔºâ
            parent1 = self._tournament_selection(population)
            parent2 = self._tournament_selection(population)

            # ‰∫§Âèâ
            if random.random() < self.parameters.crossover_rate:
                child1, child2 = self._crossover(parent1, parent2)
            else:
                child1, child2 = copy.deepcopy(parent1), copy.deepcopy(parent2)

            # Á™ÅÁÑ∂Â§âÁï∞
            if random.random() < self.parameters.mutation_rate:
                child1 = self._mutate(child1)
            if random.random() < self.parameters.mutation_rate:
                child2 = self._mutate(child2)

            # Ë©ï‰æ°
            child1.fitness_value = self._evaluate_individual_fitness(child1)
            child2.fitness_value = self._evaluate_individual_fitness(child2)

            next_generation.extend([child1, child2])

        return next_generation[:self.parameters.population_size]

    def _tournament_selection(self, population: List[Individual]) -> Individual:
        """„Éà„Éº„Éä„É°„É≥„ÉàÈÅ∏Êäû"""
        tournament_size = min(self.parameters.tournament_size, len(population))
        tournament = random.sample(population, tournament_size)
        return max(tournament, key=lambda x: x.fitness_value)

    def _crossover(self, parent1: Individual, parent2: Individual) -> Tuple[Individual, Individual]:
        """‰∫§ÂèâÊìç‰Ωú"""

        try:
            # Êñ∞ÂÄã‰Ωì‰ΩúÊàê
            child1 = Individual(
                individual_id=str(uuid.uuid4())[:8],
                generation=parent1.generation + 1
            )

            child2 = Individual(
                individual_id=str(uuid.uuid4())[:8],
                generation=parent2.generation + 1
            )

            # Á∞°Êòì‰∫§ÂèâÔºöË¶™„ÅÆÊú®„Çí„É©„É≥„ÉÄ„É†ÈÅ∏Êäû
            child1.tree = copy.deepcopy(
                random.choice([parent1.tree, parent2.tree]))
            child2.tree = copy.deepcopy(
                random.choice([parent1.tree, parent2.tree]))

            # „Ç≤„Éé„É†Êõ¥Êñ∞
            child1.genome = self._tree_to_genome(child1.tree)
            child2.genome = self._tree_to_genome(child2.tree)

            # Ë§áÈõëÂ∫¶Êõ¥Êñ∞
            child1.complexity_score = child1.tree.calculate_complexity()
            child2.complexity_score = child2.tree.calculate_complexity()

            return child1, child2

        except Exception as e:
            print(f"‚ö†Ô∏è Crossover error: {e}")
            return parent1, parent2

    def _mutate(self, individual: Individual) -> Individual:
        """Á™ÅÁÑ∂Â§âÁï∞"""

        try:
            # Êñ∞ÂÄã‰Ωì‰ΩúÊàê
            mutant = copy.deepcopy(individual)
            mutant.individual_id = str(uuid.uuid4())[:8]

            # Á∞°ÊòìÁ™ÅÁÑ∂Â§âÁï∞ÔºöÊñ∞„Åó„ÅÑÊú®„ÇíÁîüÊàê
            if random.random() < 0.5:
                mutant.tree = self._generate_random_fuzzy_tree()

            # „Ç≤„Éé„É†Êõ¥Êñ∞
            mutant.genome = self._tree_to_genome(mutant.tree)
            mutant.complexity_score = mutant.tree.calculate_complexity()

            return mutant

        except Exception as e:
            print(f"‚ö†Ô∏è Mutation error: {e}")
            return individual

    def _collect_nodes(self, tree: AdvancedFuzzyDecisionNode) -> List[AdvancedFuzzyDecisionNode]:
        """„Éé„Éº„ÉâÂèéÈõÜ"""

        nodes = [tree]

        if not tree.is_leaf:
            for child in tree.children.values():
                nodes.extend(self._collect_nodes(child))

        return nodes

    def _tree_to_genome(self, tree: AdvancedFuzzyDecisionNode) -> Dict[str, Any]:
        """Êú®„Çí„Ç≤„Éé„É†Ë°®Áèæ„Å´Â§âÊèõ"""

        genome = {
            'tree_structure': tree.get_tree_structure(),
            'complexity': tree.calculate_complexity(),
            'depth': tree.calculate_depth(),
            'feature_usage': {}
        }

        # ÁâπÂæ¥‰ΩøÁî®Áµ±Ë®à
        nodes = self._collect_nodes(tree)
        for node in nodes:
            if not node.is_leaf and node.feature_name:
                feature = node.feature_name
                genome['feature_usage'][feature] = genome['feature_usage'].get(
                    feature, 0) + 1

        return genome

    def _calculate_population_diversity(self, population: List[Individual]) -> float:
        """ÂÄã‰ΩìÁæ§Â§öÊßòÊÄßË®àÁÆó"""

        if len(population) < 2:
            return 0.0

        # Ë§áÈõëÂ∫¶„ÅÆÂ§öÊßòÊÄß
        complexities = [ind.complexity_score for ind in population]
        complexity_diversity = np.std(
            complexities) / max(1, np.mean(complexities))

        # ÈÅ©ÂøúÂ∫¶„ÅÆÂ§öÊßòÊÄß
        fitness_values = [ind.fitness_value for ind in population]
        fitness_diversity = np.std(fitness_values) / \
            max(0.001, np.mean(fitness_values))

        return (complexity_diversity + fitness_diversity) / 2.0

    def _check_convergence(self, generation: int) -> bool:
        """ÂèéÊùü„ÉÅ„Çß„ÉÉ„ÇØ"""

        # ÊúÄ‰Ωé‰∏ñ‰ª£Êï∞
        if generation < 5:
            return False

        # ÈÅ©ÂøúÂ∫¶Â±•Ê≠¥„Åß„ÅÆÂèéÊùü„ÉÅ„Çß„ÉÉ„ÇØ
        recent_best = self.evolution_stats['best_fitness_history'][-5:]

        if len(recent_best) >= 5:
            variance = np.var(recent_best)
            if variance < 0.001:  # ÂàÜÊï£„ÅåÂ∞è„Åï„ÅÑ
                return True

        # Â§öÊßòÊÄß„Å´„Çà„ÇãÂèéÊùü„ÉÅ„Çß„ÉÉ„ÇØ
        recent_diversity = self.evolution_stats['diversity_history'][-3:]

        if len(recent_diversity) >= 3:
            avg_diversity = np.mean(recent_diversity)
            if avg_diversity < 0.05:  # Â§öÊßòÊÄß„Åå‰Ωé„ÅÑ
                return True

        return False

    def _compile_final_result(self, best_individual: Individual,
                              final_population: List[Individual]) -> Dict[str, Any]:
        """ÊúÄÁµÇÁµêÊûú„Ç≥„É≥„Éë„Ç§„É´"""

        result = {
            'best_individual': best_individual,
            'best_fitness': best_individual.fitness_value if best_individual else 0.0,
            'best_fitness_components': best_individual.fitness_components.__dict__ if best_individual and best_individual.fitness_components else {},
            'final_population_size': len(final_population),
            'final_diversity': self._calculate_population_diversity(final_population),
            'evolution_stats': self.evolution_stats,
            'optimization_config': self.parameters.__dict__,
            'feature_names': self.feature_names,
            'convergence_analysis': self._analyze_convergence()
        }

        # ÊúÄËâØÂÄã‰Ωì„ÅÆË©≥Á¥∞ÂàÜÊûê
        if best_individual and best_individual.tree:
            result['best_tree_analysis'] = {
                'complexity': best_individual.tree.calculate_complexity(),
                'depth': best_individual.tree.calculate_depth(),
                'structure_summary': TreeVisualizationHelper.generate_tree_summary(best_individual.tree),
                'feature_importance': self._analyze_feature_importance(best_individual.tree)
            }

        return result

    def _analyze_convergence(self) -> Dict[str, Any]:
        """ÂèéÊùüÂàÜÊûê"""

        if len(self.evolution_stats['best_fitness_history']) < 3:
            return {'convergence_detected': False, 'stagnation_generations': 0}

        fitness_history = self.evolution_stats['best_fitness_history']

        # ÂÅúÊªû‰∏ñ‰ª£Êï∞Ë®àÁÆó
        stagnation_count = 0
        threshold = 0.001

        for i in range(1, len(fitness_history)):
            if abs(fitness_history[i] - fitness_history[i-1]) < threshold:
                stagnation_count += 1
            else:
                stagnation_count = 0

        convergence_detected = stagnation_count >= 5

        return {
            'convergence_detected': convergence_detected,
            'stagnation_generations': stagnation_count,
            'final_improvement': fitness_history[-1] - fitness_history[0] if len(fitness_history) > 1 else 0.0
        }

    def _analyze_feature_importance(self, tree: AdvancedFuzzyDecisionNode) -> Dict[str, float]:
        """ÁâπÂæ¥ÈáèÈáçË¶ÅÂ∫¶ÂàÜÊûê"""

        feature_usage = {}

        def analyze_node(node: AdvancedFuzzyDecisionNode, depth: int = 0):
            """ÂÜçÂ∏∞ÁöÑ„Å´„Éé„Éº„Éâ„ÇíÂàÜÊûê"""
            if not node.is_leaf and node.feature_name:
                feature = node.feature_name
                # Ê∑±Â∫¶„Å´Âü∫„Å•„ÅèÈáç„Åø‰ªò„ÅëÔºàÊ∑±„ÅÑÊñπ„ÅåÈáçË¶ÅÂ∫¶‰Ωé„ÅÑÔºâ
                weight = 1.0 / (depth + 1)
                feature_usage[feature] = feature_usage.get(
                    feature, 0.0) + weight

            # Â≠ê„Éé„Éº„Éâ„ÇíÂÜçÂ∏∞ÁöÑ„Å´Âá¶ÁêÜ
            if not node.is_leaf:
                for child in node.children.values():
                    analyze_node(child, depth + 1)

        # „É´„Éº„Éà„Åã„ÇâÂàÜÊûêÈñãÂßã
        analyze_node(tree, 0)

        # Ê≠£Ë¶èÂåñ
        total_usage = sum(feature_usage.values())
        if total_usage > 0:
            for feature in feature_usage:
                feature_usage[feature] /= total_usage

        return feature_usage

    def predict_with_explanation(self, individual: Individual, user_prefs: Dict, lab_features: Dict) -> Tuple[float, str]:
        """Ë™¨Êòé‰ªò„Åç‰∫àÊ∏¨"""

        if not individual or not individual.tree:
            return 0.5, "No valid tree available"

        # ÁâπÂæ¥Èáè„Éô„ÇØ„Éà„É´‰ΩúÊàê
        features = {}
        for criterion in self.feature_names:
            user_val = user_prefs.get(criterion, 5.0)
            lab_val = lab_features.get(criterion, 5.0)
            # È°û‰ººÂ∫¶Ë®àÁÆóÔºàÁ∞°ÊòìÁâàÔºâ
            similarity = 1.0 - abs(user_val - lab_val) / 10.0
            features[criterion] = max(
                0.0, min(1.0, similarity)) * 10.0  # 0-10„Çπ„Ç±„Éº„É´

        # ‰∫àÊ∏¨ÂÆüË°å
        try:
            prediction, explanation_data = individual.tree.predict_with_explanation(
                features, self.feature_names)

            # Ë™¨ÊòéÊñáÁîüÊàê
            explanation = f"ÈÅ∫‰ºùÁöÑ„Éï„Ç°„Ç∏„Ç£Ê±∫ÂÆöÊú®„Å´„Çà„Çã‰∫àÊ∏¨: {prediction:.1%}\n"
            explanation += f"ÈÅ©ÂøúÂ∫¶: {individual.fitness_value:.3f}\n"
            explanation += f"Êú®„ÅÆË§áÈõëÂ∫¶: {individual.tree.calculate_complexity()}\n"
            explanation += f"Ê±∫ÂÆöÁµåË∑Ø„ÅÆ‰ø°È†ºÂ∫¶: {explanation_data.get('confidence', 0.8):.1%}"

            return prediction, explanation

        except Exception as e:
            return 0.5, f"Prediction error: {e}"


# „Éá„É¢„É≥„Çπ„Éà„É¨„Éº„Ç∑„Éß„É≥Áî®Èñ¢Êï∞
def run_genetic_optimization_demo():
    """ÈÅ∫‰ºùÁöÑÊúÄÈÅ©Âåñ„Éá„É¢ÂÆüË°å"""
    print("üß¨ Genetic Fuzzy Tree Optimization Demo")
    print("=" * 50)

    # „ÉÜ„Çπ„Éà„Éá„Éº„ÇøÁîüÊàê
    np.random.seed(42)
    n_samples = 500

    data = []
    for i in range(n_samples):
        # „É¶„Éº„Ç∂„ÉºË®≠ÂÆö
        user_research = np.random.uniform(1, 10)
        user_advisor = np.random.uniform(1, 10)
        user_team = np.random.uniform(1, 10)
        user_workload = np.random.uniform(1, 10)
        user_theory = np.random.uniform(1, 10)

        # Á†îÁ©∂ÂÆ§ÁâπÂæ¥
        lab_research = np.random.uniform(1, 10)
        lab_advisor = np.random.uniform(1, 10)
        lab_team = np.random.uniform(1, 10)
        lab_workload = np.random.uniform(1, 10)
        lab_theory = np.random.uniform(1, 10)

        # „Ç¨„Ç¶„Ç∑„Ç¢„É≥È°û‰ººÂ∫¶„Éô„Éº„ÇπÈÅ©ÂêàÂ∫¶Ë®àÁÆó
        weights = [0.25, 0.20, 0.20, 0.15, 0.20]
        sigma = 2.0

        similarities = []
        criteria_pairs = [
            (user_research, lab_research),
            (user_advisor, lab_advisor),
            (user_team, lab_team),
            (user_workload, lab_workload),
            (user_theory, lab_theory)
        ]

        for (user_val, lab_val) in criteria_pairs:
            similarity = np.exp(-((user_val - lab_val)
                                ** 2) / (2 * sigma ** 2))
            similarities.append(similarity)

        compatibility = sum(w * s for w, s in zip(weights, similarities))
        compatibility += np.random.normal(0, 0.05)
        compatibility = max(0.1, min(0.9, compatibility))

        sample = {
            'research_intensity': user_research,
            'advisor_style': user_advisor,
            'team_work': user_team,
            'workload': user_workload,
            'theory_practice': user_theory,
            'compatibility': compatibility
        }
        data.append(sample)

    df = pd.DataFrame(data)
    print(f"üìä Generated {len(df)} training samples")
    print(
        f"üìà Compatibility stats: mean={df['compatibility'].mean():.3f}, std={df['compatibility'].std():.3f}")

    # ÊúÄÈÅ©ÂåñÂÆüË°å
    parameters = GeneticParameters(
        population_size=20,
        generations=15,
        mutation_rate=0.15,
        crossover_rate=0.8
    )

    optimizer = GeneticFuzzyTreeOptimizer(parameters, random_seed=42)
    result = optimizer.optimize(df)

    print(f"\n‚úÖ Optimization completed!")
    print(f"üéØ Best fitness: {result['best_fitness']:.4f}")
    print(
        f"üìà Generations completed: {len(result['evolution_stats']['best_fitness_history'])}")

    # „ÉÜ„Çπ„Éà‰∫àÊ∏¨
    if result['best_individual']:
        print(f"\nüéØ Test Predictions:")

        test_cases = [
            {
                'name': 'ÁêÜË´ñÈáçË¶ñÂ≠¶Áîü',
                'user_prefs': {'research_intensity': 9, 'advisor_style': 4, 'team_work': 5, 'workload': 8, 'theory_practice': 3},
                'lab_features': {'research_intensity': 8.5, 'advisor_style': 4, 'team_work': 5, 'workload': 7.5, 'theory_practice': 3}
            },
            {
                'name': 'ÂÆüË∑µÈáçË¶ñÂ≠¶Áîü',
                'user_prefs': {'research_intensity': 7, 'advisor_style': 8, 'team_work': 9, 'workload': 6, 'theory_practice': 9},
                'lab_features': {'research_intensity': 7.2, 'advisor_style': 7.8, 'team_work': 8.7, 'workload': 6.3, 'theory_practice': 8.5}
            }
        ]

        for case in test_cases:
            prediction, explanation = optimizer.predict_with_explanation(
                result['best_individual'],
                case['user_prefs'],
                case['lab_features']
            )
            print(f"   {case['name']}: {prediction*100:.1f}%")

    # „É¢„Éá„É´‰øùÂ≠ò
    timestamp = time.strftime("%Y%m%d_%H%M%S")
    model_path = f"models/genetic_model_{timestamp}.pkl"

    try:
        import pickle
        import os
        os.makedirs("models", exist_ok=True)

        with open(model_path, 'wb') as f:
            pickle.dump(result, f)
        print(f"üíæ Model saved successfully: {model_path}")
    except Exception as e:
        print(f"‚ö†Ô∏è Model save failed: {e}")

    return result


# „É¶„Éº„ÉÜ„Ç£„É™„ÉÜ„Ç£Èñ¢Êï∞
def create_genetic_optimizer(population_size: int = 50,
                             generations: int = 30,
                             mutation_rate: float = 0.15,
                             crossover_rate: float = 0.8,
                             random_seed: int = None) -> GeneticFuzzyTreeOptimizer:
    """ÈÅ∫‰ºùÁöÑÊúÄÈÅ©ÂåñÂô®‰ΩúÊàê"""

    parameters = GeneticParameters(
        population_size=population_size,
        generations=generations,
        mutation_rate=mutation_rate,
        crossover_rate=crossover_rate
    )

    return GeneticFuzzyTreeOptimizer(parameters, random_seed)


def evaluate_individual_performance(individual: Individual,
                                    test_data: pd.DataFrame,
                                    target_column: str = 'compatibility') -> Dict[str, float]:
    """ÂÄã‰ΩìÊÄßËÉΩË©ï‰æ°"""

    if not individual or not individual.tree:
        return {'error': 'Invalid individual or tree'}

    predictions = []
    targets = []

    for _, row in test_data.iterrows():
        features = {
            'research_intensity': row.get('research_intensity', 5.0),
            'advisor_style': row.get('advisor_style', 5.0),
            'team_work': row.get('team_work', 5.0),
            'workload': row.get('workload', 5.0),
            'theory_practice': row.get('theory_practice', 5.0)
        }

        prediction = individual.tree.predict(features)
        target = row.get(target_column, 0.5)

        predictions.append(prediction)
        targets.append(target)

    predictions = np.array(predictions)
    targets = np.array(targets)

    # ÊÄßËÉΩÊåáÊ®ôË®àÁÆó
    mse = np.mean((predictions - targets) ** 2)
    mae = np.mean(np.abs(predictions - targets))

    # Áõ∏Èñ¢‰øÇÊï∞
    correlation = np.corrcoef(predictions, targets)[
        0, 1] if len(predictions) > 1 else 0.0

    return {
        'mse': float(mse),
        'mae': float(mae),
        'rmse': float(np.sqrt(mse)),
        'correlation': float(correlation) if not np.isnan(correlation) else 0.0,
        'complexity': individual.tree.calculate_complexity(),
        'depth': individual.tree.calculate_depth(),
        'fitness': individual.fitness_value
    }


def save_genetic_model(result: Dict[str, Any], filepath: str):
    """ÈÅ∫‰ºùÁöÑ„É¢„Éá„É´‰øùÂ≠ò"""

    try:
        import pickle
        import os

        # „Éá„Ç£„É¨„ÇØ„Éà„É™‰ΩúÊàê
        os.makedirs(os.path.dirname(filepath), exist_ok=True)

        # „É¢„Éá„É´„Éá„Éº„ÇøÊ∫ñÂÇô
        model_data = {
            'best_individual': result['best_individual'],
            'optimization_results': {
                'best_fitness': result['best_fitness'],
                'final_diversity': result['final_diversity'],
                'evolution_stats': result['evolution_stats'],
                'convergence_analysis': result['convergence_analysis']
            },
            'metadata': {
                'saved_at': time.strftime("%Y-%m-%d %H:%M:%S"),
                'feature_names': result['feature_names'],
                'optimization_config': result['optimization_config']
            }
        }

        # ‰øùÂ≠ò
        with open(filepath, 'wb') as f:
            pickle.dump(model_data, f)

        print(f"üíæ Genetic model saved: {filepath}")
        return True

    except Exception as e:
        print(f"‚ùå Failed to save model: {e}")
        return False


def load_genetic_model(filepath: str) -> Dict[str, Any]:
    """ÈÅ∫‰ºùÁöÑ„É¢„Éá„É´Ë™≠„ÅøËæº„Åø"""

    try:
        import pickle

        with open(filepath, 'rb') as f:
            model_data = pickle.load(f)

        print(f"‚úÖ Genetic model loaded: {filepath}")
        return model_data

    except Exception as e:
        print(f"‚ùå Failed to load model: {e}")
        return {}


# „ÉÜ„Çπ„ÉàÂÆüË°å
if __name__ == '__main__':
    try:
        result = run_genetic_optimization_demo()
        print("üéâ Demo completed successfully!")
    except Exception as e:
        print(f"‚ùå Demo failed: {e}")
        import traceback
        traceback.print_exc()
