# backend/advanced_genetic_fuzzy_tree.py
"""
ğŸ§¬ Advanced Genetic Fuzzy Decision Tree System
é«˜åº¦ãªéºä¼çš„ãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨ã‚·ã‚¹ãƒ†ãƒ 

ä½¿ç”¨æ–¹æ³•:
    python advanced_genetic_fuzzy_tree.py --mode train
    python advanced_genetic_fuzzy_tree.py --mode evaluate --model_id genetic_model_20241201_143022
    python advanced_genetic_fuzzy_tree.py --mode compare
"""

from models import db, Lab, Evaluation, create_app
from explanation_engine import FuzzyExplanationEngine, NaturalLanguageGenerator
from optimization_tracker import OptimizationTracker, OptimizationReporter
from model_persistence import (
    AdvancedModelPersistence, ModelVersionManager, ModelComparisonTool
)
from genetic_fuzzy_tree import (
    GeneticFuzzyTreeOptimizer, GeneticParameters, Individual
)
import argparse
import sys
import os
import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹è¿½åŠ 
sys.path.append(os.path.dirname(os.path.abspath(__file__)))


def create_synthetic_training_data(n_samples: int = 1000) -> pd.DataFrame:
    """åˆæˆè¨“ç·´ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ"""

    print(f"ğŸ² Generating {n_samples} synthetic training samples...")

    np.random.seed(42)

    # åŸºæº–ãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    data = []

    for i in range(n_samples):
        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å¸Œæœ›ï¼ˆ1-10ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
        user_research_intensity = np.random.uniform(1, 10)
        user_advisor_style = np.random.uniform(1, 10)
        user_team_work = np.random.uniform(1, 10)
        user_workload = np.random.uniform(1, 10)
        user_theory_practice = np.random.uniform(1, 10)

        # ç ”ç©¶å®¤ç‰¹å¾´ï¼ˆ1-10ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
        lab_research_intensity = np.random.uniform(1, 10)
        lab_advisor_style = np.random.uniform(1, 10)
        lab_team_work = np.random.uniform(1, 10)
        lab_workload = np.random.uniform(1, 10)
        lab_theory_practice = np.random.uniform(1, 10)

        # é©åˆåº¦è¨ˆç®—ï¼ˆã‚¬ã‚¦ã‚·ã‚¢ãƒ³é¡ä¼¼åº¦ãƒ™ãƒ¼ã‚¹ï¼‰
        weights = [0.25, 0.20, 0.20, 0.15, 0.20]

        similarities = []
        criteria_pairs = [
            (user_research_intensity, lab_research_intensity),
            (user_advisor_style, lab_advisor_style),
            (user_team_work, lab_team_work),
            (user_workload, lab_workload),
            (user_theory_practice, lab_theory_practice)
        ]

        for user_val, lab_val in criteria_pairs:
            diff = abs(user_val - lab_val)
            similarity = np.exp(-0.5 * (diff / 2.0) ** 2)  # ã‚¬ã‚¦ã‚·ã‚¢ãƒ³é¡ä¼¼åº¦
            similarities.append(similarity)

        # é‡ã¿ä»˜ãé©åˆåº¦
        compatibility = sum(w * s for w, s in zip(weights, similarities))

        # ãƒã‚¤ã‚ºè¿½åŠ 
        compatibility += np.random.normal(0, 0.05)
        compatibility = max(0.0, min(1.0, compatibility))

        # å€‹äººå·®ãƒ»ä¸»è¦³æ€§ãƒ¢ãƒ‡ãƒªãƒ³ã‚°
        personality_factor = np.random.normal(1.0, 0.1)
        compatibility *= personality_factor
        compatibility = max(0.0, min(1.0, compatibility))

        sample = {
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å¸Œæœ›
            'user_research_intensity': user_research_intensity,
            'user_advisor_style': user_advisor_style,
            'user_team_work': user_team_work,
            'user_workload': user_workload,
            'user_theory_practice': user_theory_practice,

            # ç ”ç©¶å®¤ç‰¹å¾´
            'lab_research_intensity': lab_research_intensity,
            'lab_advisor_style': lab_advisor_style,
            'lab_team_work': lab_team_work,
            'lab_workload': lab_workload,
            'lab_theory_practice': lab_theory_practice,

            # å…¥åŠ›ç‰¹å¾´ï¼ˆå·®åˆ†ãƒ™ãƒ¼ã‚¹ï¼‰
            'research_intensity': user_research_intensity,
            'advisor_style': user_advisor_style,
            'team_work': user_team_work,
            'workload': user_workload,
            'theory_practice': user_theory_practice,

            # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ
            'compatibility': compatibility
        }

        data.append(sample)

    df = pd.DataFrame(data)

    print(f"âœ… Generated {len(df)} samples")
    print(
        f"ğŸ“Š Compatibility stats: mean={df['compatibility'].mean():.3f}, std={df['compatibility'].std():.3f}")

    return df


def load_real_data_from_database() -> pd.DataFrame:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰å®Ÿãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""

    print("ğŸ—„ï¸ Loading real data from database...")

    try:
        # Flaskã‚¢ãƒ—ãƒªä½œæˆ
        app = create_app()

        with app.app_context():
            # è©•ä¾¡ãƒ‡ãƒ¼ã‚¿å–å¾—
            evaluations = Evaluation.query.all()

            if not evaluations:
                print("âš ï¸ No evaluation data found in database")
                return None

            # ãƒ‡ãƒ¼ã‚¿å¤‰æ›
            data = []
            for eval_record in evaluations:
                # è©•ä¾¡çµæœå–å¾—
                results = eval_record.get_results()
                if not results:
                    continue

                # å„ç ”ç©¶å®¤ã¨ã®é©åˆåº¦
                for result in results:
                    lab_info = result.get('lab', {})
                    compatibility_info = result.get('compatibility', {})

                    sample = {
                        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å¸Œæœ›
                        'research_intensity': eval_record.research_intensity,
                        'advisor_style': eval_record.advisor_style,
                        'team_work': eval_record.team_work,
                        'workload': eval_record.workload,
                        'theory_practice': eval_record.theory_practice,

                        # é©åˆåº¦
                        'compatibility': compatibility_info.get('overall_score', 50.0) / 100.0,

                        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
                        'lab_id': lab_info.get('id'),
                        'evaluation_id': eval_record.id
                    }

                    data.append(sample)

            df = pd.DataFrame(data)

            print(f"ğŸ“Š Loaded {len(df)} real data samples")
            print(
                f"ğŸ“ˆ Compatibility distribution: {df['compatibility'].describe()}")

            return df

    except Exception as e:
        print(f"âŒ Failed to load real data: {e}")
        return None


def train_genetic_model(args):
    """éºä¼çš„ãƒ¢ãƒ‡ãƒ«è¨“ç·´"""

    print("ğŸ§¬ Starting Genetic Fuzzy Tree Training...")
    print("=" * 60)

    # ãƒ‡ãƒ¼ã‚¿æº–å‚™
    if args.use_real_data:
        training_data = load_real_data_from_database()
        if training_data is None or len(training_data) < 50:
            print("âš ï¸ Insufficient real data, using synthetic data")
            training_data = create_synthetic_training_data(
                args.training_samples)
    else:
        training_data = create_synthetic_training_data(args.training_samples)

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿åˆ†å‰²
    test_size = int(len(training_data) * 0.2)
    test_data = training_data.sample(n=test_size, random_state=42)
    training_data = training_data.drop(test_data.index)

    print(f"ğŸ“Š Training samples: {len(training_data)}")
    print(f"ğŸ§ª Test samples: {len(test_data)}")

    # ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿è¨­å®š
    parameters = GeneticParameters(
        population_size=args.population_size,
        generations=args.generations,
        mutation_rate=args.mutation_rate,
        crossover_rate=args.crossover_rate,
        max_depth=args.max_depth,
        tournament_size=args.tournament_size
    )

    print("\nğŸ”§ Optimization Parameters:")
    print(f"   Population Size: {parameters.population_size}")
    print(f"   Generations: {parameters.generations}")
    print(f"   Mutation Rate: {parameters.mutation_rate:.2f}")
    print(f"   Crossover Rate: {parameters.crossover_rate:.2f}")
    print(f"   Max Depth: {parameters.max_depth}")

    # æœ€é©åŒ–å™¨åˆæœŸåŒ–
    optimizer = GeneticFuzzyTreeOptimizer(
        parameters=parameters,
        random_seed=args.random_seed
    )

    # æœ€é©åŒ–å®Ÿè¡Œ
    run_id = f"genetic_optimization_{datetime.now().strftime('%Y%m%d_%H%M%S')}"

    print(f"\nğŸš€ Starting optimization (Run ID: {run_id})...")

    try:
        result = optimizer.optimize(
            training_data=training_data,
            test_data=test_data,
            target_column='compatibility',
            run_id=run_id
        )

        print("\nğŸ‰ Optimization completed successfully!")

        # çµæœä¿å­˜
        persistence = AdvancedModelPersistence()
        model_id = persistence.save_genetic_optimization_result(
            result,
            description=f"Genetic Fuzzy Tree trained on {len(training_data)} samples"
        )

        # çµæœãƒ¬ãƒãƒ¼ãƒˆ
        print("\nğŸ“Š Final Results:")
        print(f"   Best Fitness: {result['best_fitness']:.4f}")
        print(f"   Final Diversity: {result['final_diversity']:.3f}")
        print(
            f"   Convergence: {result['convergence_analysis']['convergence_detected']}")
        print(f"   Model ID: {model_id}")

        # è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        if args.generate_report:
            print("\nğŸ“‹ Generating detailed report...")
            reporter = OptimizationReporter()
            html_report = reporter.generate_html_report(optimizer.tracker)
            print(f"ğŸ“„ HTML Report: {html_report}")

        return model_id

    except Exception as e:
        print(f"\nâŒ Optimization failed: {e}")
        raise


def evaluate_model(args):
    """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡"""

    print(f"ğŸ§ª Evaluating model: {args.model_id}")
    print("=" * 50)

    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    persistence = AdvancedModelPersistence()

    try:
        individual, optimization_result = persistence.load_genetic_model(
            args.model_id)

        print(f"âœ… Model loaded successfully")
        print(
            f"ğŸ¯ Model Fitness: {individual.fitness_components.overall if individual.fitness_components else 'N/A'}")
        print(f"ğŸ§® Model Complexity: {individual.complexity_score}")

    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        return

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿æº–å‚™
    if args.use_real_data:
        test_data = load_real_data_from_database()
        if test_data is None:
            test_data = create_synthetic_training_data(200)
    else:
        test_data = create_synthetic_training_data(200)

    print(f"ğŸ“Š Test samples: {len(test_data)}")

    # äºˆæ¸¬å®Ÿè¡Œ
    print("\nğŸ” Running predictions...")

    predictions = []
    explanations = []

    # èª¬æ˜ã‚¨ãƒ³ã‚¸ãƒ³åˆæœŸåŒ–
    explanation_engine = FuzzyExplanationEngine()

    for i, (_, row) in enumerate(test_data.head(10).iterrows()):  # æœ€åˆã®10ã‚µãƒ³ãƒ—ãƒ«ã§è©•ä¾¡
        # å…¥åŠ›æº–å‚™
        user_preferences = {
            'research_intensity': row['research_intensity'],
            'advisor_style': row['advisor_style'],
            'team_work': row['team_work'],
            'workload': row['workload'],
            'theory_practice': row['theory_practice']
        }

        # äºˆæ¸¬å®Ÿè¡Œ
        try:
            if individual.tree:
                prediction = individual.tree.predict(user_preferences)

                # è©³ç´°èª¬æ˜ä»˜ãäºˆæ¸¬
                detailed_prediction, explanation_details = individual.tree.predict_with_explanation(
                    user_preferences, list(user_preferences.keys())
                )

                predictions.append({
                    'sample_id': i,
                    'actual': row['compatibility'],
                    'predicted': prediction,
                    'detailed_predicted': detailed_prediction,
                    'error': abs(row['compatibility'] - prediction),
                    'user_preferences': user_preferences
                })

                # åŒ…æ‹¬çš„èª¬æ˜ç”Ÿæˆ
                prediction_result = {
                    'overall_score': prediction * 100,
                    'confidence': explanation_details.get('confidence', 0.5) * 100,
                    'criterion_scores': {}
                }

                lab_info = {'name': f'Test Lab {i+1}'}

                comprehensive_explanation = explanation_engine.generate_comprehensive_explanation(
                    prediction_result, lab_info, user_preferences
                )

                explanations.append({
                    'sample_id': i,
                    'explanation': comprehensive_explanation,
                    'formatted_explanation': NaturalLanguageGenerator.format_explanation_for_ui(
                        comprehensive_explanation, 'markdown'
                    )
                })

            else:
                print(f"âš ï¸ No tree available for sample {i}")

        except Exception as e:
            print(f"âš ï¸ Prediction failed for sample {i}: {e}")

    # è©•ä¾¡æŒ‡æ¨™è¨ˆç®—
    if predictions:
        predictions_df = pd.DataFrame(predictions)

        mae = predictions_df['error'].mean()
        rmse = np.sqrt((predictions_df['error'] ** 2).mean())
        max_error = predictions_df['error'].max()

        print(f"\nğŸ“ˆ Prediction Performance:")
        print(f"   MAE (Mean Absolute Error): {mae:.4f}")
        print(f"   RMSE (Root Mean Squared Error): {rmse:.4f}")
        print(f"   Max Error: {max_error:.4f}")
        print(f"   Samples Evaluated: {len(predictions)}")

        # ã‚µãƒ³ãƒ—ãƒ«äºˆæ¸¬è¡¨ç¤º
        print(f"\nğŸ” Sample Predictions:")
        for pred in predictions[:5]:
            print(
                f"   Sample {pred['sample_id']}: Actual={pred['actual']:.3f}, Predicted={pred['predicted']:.3f}, Error={pred['error']:.3f}")

    # èª¬æ˜ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
    if explanations and args.show_explanations:
        print(f"\nğŸ’¡ Sample Explanation (Sample 0):")
        print("=" * 50)
        print(explanations[0]['formatted_explanation'])


def compare_models(args):
    """ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ"""

    print("ğŸ” Comparing models...")
    print("=" * 40)

    persistence = AdvancedModelPersistence()

    # ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—
    models = persistence.list_models('genetic_fuzzy_tree')

    if len(models) < 2:
        print("âš ï¸ Need at least 2 models for comparison")
        return

    print(f"ğŸ“Š Found {len(models)} genetic fuzzy tree models")

    # æ¯”è¼ƒè¡¨ä½œæˆ
    comparison_df = ModelComparisonTool.compare_models(models)

    print("\nğŸ“‹ Model Comparison:")
    print(comparison_df.to_string())

    # æ€§èƒ½ãƒ©ãƒ³ã‚­ãƒ³ã‚°
    ranking = ModelComparisonTool.generate_performance_ranking(
        models, 'best_fitness')

    print(f"\nğŸ† Performance Ranking (by best_fitness):")
    for i, model in enumerate(ranking[:5], 1):
        print(f"   {i}. {model['model_id']}: {model['ranking_value']:.4f}")

    # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«æ¤œç´¢
    criteria = {
        'best_fitness': 0.6,
        'model_complexity': -0.2,  # è¤‡é›‘åº¦ã¯ä½ã„æ–¹ãŒè‰¯ã„
        'tree_depth': -0.1
    }

    best_model = ModelComparisonTool.find_best_model_by_criteria(
        models, criteria)

    if best_model:
        print(f"\nğŸ¯ Best Model (composite criteria): {best_model['model_id']}")
        print(f"   Composite Score: {best_model['composite_score']:.4f}")
        print(f"   Fitness: {best_model['best_fitness']:.4f}")
        print(f"   Complexity: {best_model['model_complexity']}")


def demonstrate_prediction(args):
    """äºˆæ¸¬ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³"""

    print("ğŸ­ Prediction Demonstration")
    print("=" * 40)

    # ãƒ¢ãƒ‡ãƒ«èª­ã¿è¾¼ã¿
    persistence = AdvancedModelPersistence()

    if args.model_id:
        model_id = args.model_id
    else:
        # æœ€è‰¯ãƒ¢ãƒ‡ãƒ«è‡ªå‹•é¸æŠ
        models = persistence.list_models('genetic_fuzzy_tree')
        if not models:
            print("âŒ No genetic fuzzy tree models found")
            return

        best_model = max(models, key=lambda x: x.get('best_fitness', 0.0))
        model_id = best_model['model_id']
        print(f"ğŸ¤– Using best available model: {model_id}")

    try:
        individual, _ = persistence.load_genetic_model(model_id)
        print(f"âœ… Model loaded: {model_id}")

    except Exception as e:
        print(f"âŒ Failed to load model: {e}")
        return

    # ãƒ‡ãƒ¢ç”¨ã‚µãƒ³ãƒ—ãƒ«
    demo_samples = [
        {
            'name': 'ç†è«–ç ”ç©¶å¸Œæœ›ã®å­¦ç”Ÿ',
            'preferences': {
                'research_intensity': 9.0,
                'advisor_style': 3.0,  # å³æ ¼ãªæŒ‡å°ã‚’å¸Œæœ›
                'team_work': 4.0,     # å€‹äººç ”ç©¶ã‚’å¥½ã‚€
                'workload': 8.0,      # é«˜è² è·OK
                'theory_practice': 2.0  # ç†è«–é‡è¦–
            }
        },
        {
            'name': 'å®Ÿè·µé‡è¦–ã®å­¦ç”Ÿ',
            'preferences': {
                'research_intensity': 7.0,
                'advisor_style': 8.0,  # è‡ªç”±ãªæŒ‡å°ã‚’å¸Œæœ›
                'team_work': 8.5,     # ãƒãƒ¼ãƒ ç ”ç©¶ã‚’å¥½ã‚€
                'workload': 6.0,      # ä¸­ç¨‹åº¦ã®è² è·
                'theory_practice': 9.0  # å®Ÿè·µé‡è¦–
            }
        },
        {
            'name': 'ãƒãƒ©ãƒ³ã‚¹é‡è¦–ã®å­¦ç”Ÿ',
            'preferences': {
                'research_intensity': 6.5,
                'advisor_style': 5.5,
                'team_work': 6.0,
                'workload': 5.5,
                'theory_practice': 5.0
            }
        }
    ]

    # èª¬æ˜ã‚¨ãƒ³ã‚¸ãƒ³
    explanation_engine = FuzzyExplanationEngine()

    print(
        f"\nğŸ­ Demonstrating predictions for {len(demo_samples)} sample profiles:")

    for sample in demo_samples:
        print(f"\nğŸ‘¤ {sample['name']}:")
        print("   Preferences:", {k: f"{v:.1f}" for k,
              v in sample['preferences'].items()})

        try:
            # äºˆæ¸¬å®Ÿè¡Œ
            prediction = individual.tree.predict(sample['preferences'])

            # è©³ç´°äºˆæ¸¬
            detailed_prediction, explanation_details = individual.tree.predict_with_explanation(
                sample['preferences'], list(sample['preferences'].keys())
            )

            print(
                f"   ğŸ¯ Predicted Compatibility: {prediction:.3f} ({prediction*100:.1f}%)")
            print(f"   ğŸ” Detailed Prediction: {detailed_prediction:.3f}")
            print(
                f"   ğŸ“Š Confidence: {explanation_details.get('confidence', 0.5)*100:.1f}%")

            # ç°¡æ˜“èª¬æ˜ç”Ÿæˆ
            if prediction >= 0.8:
                assessment = "éå¸¸ã«é©åˆåº¦ãŒé«˜ã„"
            elif prediction >= 0.6:
                assessment = "é©åˆåº¦ãŒé«˜ã„"
            elif prediction >= 0.4:
                assessment = "é©åˆåº¦ã¯ä¸­ç¨‹åº¦"
            else:
                assessment = "é©åˆåº¦ã¯ä½ã„"

            print(f"   ğŸ’¡ Assessment: {assessment}")

        except Exception as e:
            print(f"   âŒ Prediction failed: {e}")


def cleanup_models(args):
    """ãƒ¢ãƒ‡ãƒ«æ¸…ç†"""

    print("ğŸ§¹ Cleaning up old models...")

    persistence = AdvancedModelPersistence()

    deleted_count = persistence.cleanup_old_models(
        keep_latest=args.keep_latest,
        min_fitness=args.min_fitness
    )

    print(f"âœ… Cleaned up {deleted_count} models")

    # çµ±è¨ˆè¡¨ç¤º
    stats = persistence.get_storage_statistics()
    print(f"\nğŸ“Š Storage Statistics:")
    print(f"   Total Models: {stats['total_models']}")
    print(f"   Total Size: {stats['total_size_bytes'] / (1024*1024):.1f} MB")
    print(f"   Average Fitness: {stats['average_fitness']:.4f}")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""

    parser = argparse.ArgumentParser(
        description="Advanced Genetic Fuzzy Decision Tree System",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # æ–°ã—ã„ãƒ¢ãƒ‡ãƒ«ã‚’è¨“ç·´
  python advanced_genetic_fuzzy_tree.py --mode train --generations 30 --population_size 50
  
  # ãƒ¢ãƒ‡ãƒ«ã‚’è©•ä¾¡
  python advanced_genetic_fuzzy_tree.py --mode evaluate --model_id genetic_model_20241201_143022
  
  # ãƒ¢ãƒ‡ãƒ«æ¯”è¼ƒ
  python advanced_genetic_fuzzy_tree.py --mode compare
  
  # äºˆæ¸¬ãƒ‡ãƒ¢
  python advanced_genetic_fuzzy_tree.py --mode demo --model_id genetic_model_20241201_143022
  
  # ãƒ¢ãƒ‡ãƒ«æ¸…ç†
  python advanced_genetic_fuzzy_tree.py --mode cleanup --keep_latest 5
        """
    )

    parser.add_argument('--mode', required=True,
                        choices=['train', 'evaluate',
                                 'compare', 'demo', 'cleanup'],
                        help='å‹•ä½œãƒ¢ãƒ¼ãƒ‰')

    # å…±é€šãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    parser.add_argument('--model_id', type=str, help='ãƒ¢ãƒ‡ãƒ«ID')
    parser.add_argument('--use_real_data', action='store_true',
                        help='å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šåˆæˆãƒ‡ãƒ¼ã‚¿ï¼‰')
    parser.add_argument('--random_seed', type=int, default=42, help='ä¹±æ•°ã‚·ãƒ¼ãƒ‰')

    # è¨“ç·´ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    parser.add_argument('--training_samples', type=int, default=1000,
                        help='è¨“ç·´ã‚µãƒ³ãƒ—ãƒ«æ•°ï¼ˆåˆæˆãƒ‡ãƒ¼ã‚¿ä½¿ç”¨æ™‚ï¼‰')
    parser.add_argument('--population_size', type=int,
                        default=50, help='å€‹ä½“ç¾¤ã‚µã‚¤ã‚º')
    parser.add_argument('--generations', type=int, default=30, help='ä¸–ä»£æ•°')
    parser.add_argument('--mutation_rate', type=float,
                        default=0.15, help='çªç„¶å¤‰ç•°ç‡')
    parser.add_argument('--crossover_rate', type=float,
                        default=0.8, help='äº¤å‰ç‡')
    parser.add_argument('--max_depth', type=int, default=6, help='æœ€å¤§æœ¨æ·±åº¦')
    parser.add_argument('--tournament_size', type=int,
                        default=3, help='ãƒˆãƒ¼ãƒŠãƒ¡ãƒ³ãƒˆã‚µã‚¤ã‚º')
    parser.add_argument('--generate_report', action='store_true',
                        help='è©³ç´°ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ')

    # è©•ä¾¡ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    parser.add_argument('--show_explanations', action='store_true',
                        help='èª¬æ˜æ–‡ã‚’è¡¨ç¤º')

    # æ¸…ç†ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    parser.add_argument('--keep_latest', type=int, default=10,
                        help='ä¿æŒã™ã‚‹æœ€æ–°ãƒ¢ãƒ‡ãƒ«æ•°')
    parser.add_argument('--min_fitness', type=float, default=0.5,
                        help='ä¿æŒã™ã‚‹æœ€ä½é©å¿œåº¦')

    args = parser.parse_args()

    # ãƒ˜ãƒƒãƒ€ãƒ¼è¡¨ç¤º
    print("ğŸ§¬ Advanced Genetic Fuzzy Decision Tree System")
    print("=" * 60)
    print(f"Mode: {args.mode}")
    print(f"Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 60)

    try:
        if args.mode == 'train':
            model_id = train_genetic_model(args)
            print(f"\nğŸ‰ Training completed! Model ID: {model_id}")

        elif args.mode == 'evaluate':
            if not args.model_id:
                print("âŒ Model ID required for evaluation mode")
                return
            evaluate_model(args)

        elif args.mode == 'compare':
            compare_models(args)

        elif args.mode == 'demo':
            demonstrate_prediction(args)

        elif args.mode == 'cleanup':
            cleanup_models(args)

    except KeyboardInterrupt:
        print("\n\nâš ï¸ Operation interrupted by user")
    except Exception as e:
        print(f"\nâŒ Operation failed: {e}")
        import traceback
        traceback.print_exc()


if __name__ == '__main__':
    main()
