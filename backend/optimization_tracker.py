# backend/optimization_tracker.py
import json
import time
import pickle
import os
import numpy as np
from datetime import datetime
from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass, field, asdict
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict, deque
import threading
import queue


@dataclass
class GenerationStats:
    """ä¸–ä»£çµ±è¨ˆ"""
    generation: int
    timestamp: datetime

    # é©å¿œåº¦çµ±è¨ˆ
    best_fitness: float = 0.0
    worst_fitness: float = 0.0
    avg_fitness: float = 0.0
    median_fitness: float = 0.0
    std_fitness: float = 0.0

    # å¤šç›®çš„çµ±è¨ˆ
    best_accuracy: float = 0.0
    best_simplicity: float = 0.0
    best_interpretability: float = 0.0
    best_generalization: float = 0.0
    best_validity: float = 0.0

    avg_accuracy: float = 0.0
    avg_simplicity: float = 0.0
    avg_interpretability: float = 0.0
    avg_generalization: float = 0.0
    avg_validity: float = 0.0

    # å¤šæ§˜æ€§çµ±è¨ˆ
    diversity_score: float = 0.0
    unique_individuals: int = 0

    # é€²åŒ–çµ±è¨ˆ
    mutation_success_rate: float = 0.0
    crossover_success_rate: float = 0.0

    # æ€§èƒ½çµ±è¨ˆ
    evaluation_time: float = 0.0
    memory_usage: float = 0.0


@dataclass
class IndividualRecord:
    """å€‹ä½“è¨˜éŒ²"""
    individual_id: str
    generation: int
    timestamp: datetime

    # éºä¼å­æƒ…å ±
    genome: Dict[str, Any] = field(default_factory=dict)

    # é©å¿œåº¦æƒ…å ±
    fitness_components: Dict[str, float] = field(default_factory=dict)
    overall_fitness: float = 0.0

    # ç³»è­œæƒ…å ±
    parents: List[str] = field(default_factory=list)
    children: List[str] = field(default_factory=list)

    # æ€§èƒ½æƒ…å ±
    prediction_accuracy: float = 0.0
    model_complexity: int = 0
    evaluation_time: float = 0.0

    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
    notes: str = ""
    tags: List[str] = field(default_factory=list)


class OptimizationTracker:
    """æœ€é©åŒ–ãƒ—ãƒ­ã‚»ã‚¹è¿½è·¡ã‚·ã‚¹ãƒ†ãƒ """

    def __init__(self, run_id: str = None, save_dir: str = "optimization_logs"):
        self.run_id = run_id or f"run_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        self.save_dir = save_dir

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs(save_dir, exist_ok=True)

        # ãƒ‡ãƒ¼ã‚¿æ§‹é€ 
        self.generation_stats: List[GenerationStats] = []
        self.individual_records: Dict[str, IndividualRecord] = {}
        self.best_individuals_history: List[str] = []

        # å®Ÿè¡Œæƒ…å ±
        self.start_time: Optional[datetime] = None
        self.end_time: Optional[datetime] = None
        self.current_generation: int = 0
        self.is_running: bool = False

        # è¨­å®šæƒ…å ±
        self.config: Dict[str, Any] = {}

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
        self.monitoring_queue: queue.Queue = queue.Queue()
        self.monitoring_thread: Optional[threading.Thread] = None
        self.enable_realtime_monitoring: bool = True

        # ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£è¿½è·¡
        self.pareto_front_history: List[List[str]] = []

        print(f"ğŸ¯ OptimizationTracker initialized: {self.run_id}")

    def start_optimization(self, config: Dict[str, Any]):
        """æœ€é©åŒ–é–‹å§‹"""
        self.start_time = datetime.now()
        self.is_running = True
        self.config = config.copy()
        self.current_generation = 0

        # è¨­å®šä¿å­˜
        self._save_config()

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–é–‹å§‹
        if self.enable_realtime_monitoring:
            self._start_monitoring_thread()

        print(f"ğŸš€ Optimization started at {self.start_time}")
        print(f"ğŸ“ Logs saved to: {self.save_dir}")

    def end_optimization(self):
        """æœ€é©åŒ–çµ‚äº†"""
        self.end_time = datetime.now()
        self.is_running = False

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–åœæ­¢
        if self.monitoring_thread and self.monitoring_thread.is_alive():
            self.monitoring_queue.put(('STOP', None))
            self.monitoring_thread.join(timeout=5.0)

        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self._generate_final_report()

        duration = self.end_time - self.start_time if self.start_time else None
        print(f"ğŸ Optimization completed at {self.end_time}")
        if duration:
            print(f"â±ï¸ Total duration: {duration}")

    def record_generation(self, generation: int, population: List[Any],
                          evaluation_results: List[Dict[str, Any]],
                          generation_metrics: Dict[str, Any] = None):
        """ä¸–ä»£è¨˜éŒ²"""

        start_time = time.time()

        # é©å¿œåº¦æŠ½å‡º
        fitness_values = []
        accuracy_values = []
        simplicity_values = []
        interpretability_values = []
        generalization_values = []
        validity_values = []

        for result in evaluation_results:
            if 'overall_fitness' in result:
                fitness_values.append(result['overall_fitness'])
            if 'accuracy' in result:
                accuracy_values.append(result['accuracy'])
            if 'simplicity' in result:
                simplicity_values.append(result['simplicity'])
            if 'interpretability' in result:
                interpretability_values.append(result['interpretability'])
            if 'generalization' in result:
                generalization_values.append(result['generalization'])
            if 'validity' in result:
                validity_values.append(result['validity'])

        # çµ±è¨ˆè¨ˆç®—
        fitness_stats = self._calculate_stats(fitness_values)
        accuracy_stats = self._calculate_stats(accuracy_values)
        simplicity_stats = self._calculate_stats(simplicity_values)
        interpretability_stats = self._calculate_stats(interpretability_values)
        generalization_stats = self._calculate_stats(generalization_values)
        validity_stats = self._calculate_stats(validity_values)

        # å¤šæ§˜æ€§è¨ˆç®—
        diversity_score = self._calculate_diversity(population)

        # ä¸–ä»£çµ±è¨ˆä½œæˆ
        stats = GenerationStats(
            generation=generation,
            timestamp=datetime.now(),
            best_fitness=fitness_stats['max'],
            worst_fitness=fitness_stats['min'],
            avg_fitness=fitness_stats['mean'],
            median_fitness=fitness_stats['median'],
            std_fitness=fitness_stats['std'],
            best_accuracy=accuracy_stats['max'],
            best_simplicity=simplicity_stats['max'],
            best_interpretability=interpretability_stats['max'],
            best_generalization=generalization_stats['max'],
            best_validity=validity_stats['max'],
            avg_accuracy=accuracy_stats['mean'],
            avg_simplicity=simplicity_stats['mean'],
            avg_interpretability=interpretability_stats['mean'],
            avg_generalization=generalization_stats['mean'],
            avg_validity=validity_stats['mean'],
            diversity_score=diversity_score,
            unique_individuals=len(set(id(ind) for ind in population)),
            evaluation_time=time.time() - start_time,
            memory_usage=self._get_memory_usage()
        )

        self.generation_stats.append(stats)
        self.current_generation = generation

        # æœ€è‰¯å€‹ä½“è¨˜éŒ²
        if fitness_values:
            best_idx = fitness_values.index(max(fitness_values))
            best_individual = population[best_idx]
            individual_id = f"gen{generation}_ind{best_idx}"
            self.best_individuals_history.append(individual_id)

            # å€‹ä½“è¨˜éŒ²
            self.record_individual(
                individual=best_individual,
                individual_id=individual_id,
                generation=generation,
                fitness_components=evaluation_results[best_idx] if best_idx < len(
                    evaluation_results) else {},
                overall_fitness=fitness_values[best_idx]
            )

        # ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£è¨ˆç®—
        pareto_front = self._calculate_pareto_front(evaluation_results)
        self.pareto_front_history.append(pareto_front)

        # ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–
        if self.enable_realtime_monitoring:
            self.monitoring_queue.put(('GENERATION', stats))

        print(f"ğŸ“Š Generation {generation}: Best={stats.best_fitness:.4f}, "
              f"Avg={stats.avg_fitness:.4f}, Diversity={stats.diversity_score:.3f}")

        return stats

    def record_individual(self, individual: Any, individual_id: str, generation: int,
                          fitness_components: Dict[str, float], overall_fitness: float,
                          parents: List[str] = None, notes: str = ""):
        """å€‹ä½“è¨˜éŒ²"""

        record = IndividualRecord(
            individual_id=individual_id,
            generation=generation,
            timestamp=datetime.now(),
            fitness_components=fitness_components,
            overall_fitness=overall_fitness,
            parents=parents or [],
            notes=notes
        )

        # ã‚²ãƒãƒ æƒ…å ±ï¼ˆå¯èƒ½ãªå ´åˆï¼‰
        if hasattr(individual, 'genome'):
            record.genome = individual.genome
        elif hasattr(individual, '__dict__'):
            record.genome = {k: str(v) for k, v in individual.__dict__.items()}

        # è¤‡é›‘åº¦æƒ…å ±
        if hasattr(individual, 'calculate_complexity'):
            record.model_complexity = individual.calculate_complexity()

        self.individual_records[individual_id] = record

    def generate_performance_plots(self) -> List[str]:
        """æ€§èƒ½ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆ"""

        plot_files = []

        if not self.generation_stats:
            return plot_files

        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        generations = [stats.generation for stats in self.generation_stats]
        best_fitness = [stats.best_fitness for stats in self.generation_stats]
        avg_fitness = [stats.avg_fitness for stats in self.generation_stats]
        diversity = [stats.diversity_score for stats in self.generation_stats]

        # ãƒ—ãƒ­ãƒƒãƒˆ1: é©å¿œåº¦æ¨ç§»
        plt.figure(figsize=(12, 8))

        plt.subplot(2, 2, 1)
        plt.plot(generations, best_fitness, 'b-',
                 linewidth=2, label='Best Fitness')
        plt.plot(generations, avg_fitness, 'g--',
                 linewidth=1, label='Average Fitness')
        plt.xlabel('Generation')
        plt.ylabel('Fitness')
        plt.title('Fitness Evolution')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # ãƒ—ãƒ­ãƒƒãƒˆ2: å¤šæ§˜æ€§æ¨ç§»
        plt.subplot(2, 2, 2)
        plt.plot(generations, diversity, 'r-', linewidth=2, label='Diversity')
        plt.xlabel('Generation')
        plt.ylabel('Diversity Score')
        plt.title('Population Diversity')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # ãƒ—ãƒ­ãƒƒãƒˆ3: å¤šç›®çš„çµ±è¨ˆ
        plt.subplot(2, 2, 3)
        accuracy = [stats.best_accuracy for stats in self.generation_stats]
        simplicity = [stats.best_simplicity for stats in self.generation_stats]
        interpretability = [
            stats.best_interpretability for stats in self.generation_stats]

        plt.plot(generations, accuracy, label='Accuracy', linewidth=1)
        plt.plot(generations, simplicity, label='Simplicity', linewidth=1)
        plt.plot(generations, interpretability,
                 label='Interpretability', linewidth=1)
        plt.xlabel('Generation')
        plt.ylabel('Score')
        plt.title('Multi-objective Evolution')
        plt.legend()
        plt.grid(True, alpha=0.3)

        # ãƒ—ãƒ­ãƒƒãƒˆ4: è©•ä¾¡æ™‚é–“
        plt.subplot(2, 2, 4)
        eval_times = [stats.evaluation_time for stats in self.generation_stats]
        plt.plot(generations, eval_times, 'm-',
                 linewidth=2, label='Evaluation Time')
        plt.xlabel('Generation')
        plt.ylabel('Time (seconds)')
        plt.title('Evaluation Performance')
        plt.legend()
        plt.grid(True, alpha=0.3)

        plt.tight_layout()

        # ä¿å­˜
        fitness_plot_path = os.path.join(
            self.save_dir, f"{self.run_id}_fitness_evolution.png")
        plt.savefig(fitness_plot_path, dpi=150, bbox_inches='tight')
        plt.close()
        plot_files.append(fitness_plot_path)

        # ãƒ—ãƒ­ãƒƒãƒˆ2: ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£æ¨ç§»
        if self.pareto_front_history:
            plt.figure(figsize=(10, 6))
            pareto_sizes = [len(front) for front in self.pareto_front_history]
            plt.plot(generations[:len(pareto_sizes)],
                     pareto_sizes, 'o-', linewidth=2)
            plt.xlabel('Generation')
            plt.ylabel('Pareto Front Size')
            plt.title('Pareto Front Evolution')
            plt.grid(True, alpha=0.3)

            pareto_plot_path = os.path.join(
                self.save_dir, f"{self.run_id}_pareto_evolution.png")
            plt.savefig(pareto_plot_path, dpi=150, bbox_inches='tight')
            plt.close()
            plot_files.append(pareto_plot_path)

        # ãƒ—ãƒ­ãƒƒãƒˆ3: ãƒ’ãƒ¼ãƒˆãƒãƒƒãƒ—ï¼ˆä¸–ä»£Ã—ç›®çš„é–¢æ•°ï¼‰
        if len(self.generation_stats) > 1:
            objectives = ['best_accuracy', 'best_simplicity', 'best_interpretability',
                          'best_generalization', 'best_validity']

            heatmap_data = []
            for stats in self.generation_stats:
                row = [getattr(stats, obj, 0.0) for obj in objectives]
                heatmap_data.append(row)

            plt.figure(figsize=(10, 8))
            sns.heatmap(np.array(heatmap_data).T,
                        xticklabels=[f"Gen {i}" for i in generations],
                        yticklabels=[
                            'Accuracy', 'Simplicity', 'Interpretability', 'Generalization', 'Validity'],
                        cmap='viridis', annot=False, cbar=True)
            plt.title('Multi-objective Evolution Heatmap')
            plt.xlabel('Generation')
            plt.ylabel('Objective')

            heatmap_plot_path = os.path.join(
                self.save_dir, f"{self.run_id}_objectives_heatmap.png")
            plt.savefig(heatmap_plot_path, dpi=150, bbox_inches='tight')
            plt.close()
            plot_files.append(heatmap_plot_path)

        print(f"ğŸ“Š Performance plots generated: {len(plot_files)} files")
        return plot_files

    def get_convergence_analysis(self) -> Dict[str, Any]:
        """åæŸåˆ†æ"""

        if len(self.generation_stats) < 3:
            return {
                'convergence_detected': False,
                'stagnation_generations': 0,
                'max_fitness_achieved': 0.0,
                'convergence_rate': 0.0
            }

        fitness_values = [
            stats.best_fitness for stats in self.generation_stats]

        # åœæ»ä¸–ä»£æ•°è¨ˆç®—
        stagnation_threshold = 1e-6
        stagnation_count = 0
        max_stagnation = 0

        for i in range(1, len(fitness_values)):
            if abs(fitness_values[i] - fitness_values[i-1]) < stagnation_threshold:
                stagnation_count += 1
            else:
                max_stagnation = max(max_stagnation, stagnation_count)
                stagnation_count = 0

        max_stagnation = max(max_stagnation, stagnation_count)

        # åæŸåˆ¤å®š
        convergence_detected = max_stagnation >= 5  # 5ä¸–ä»£é€£ç¶šåœæ»ã§åæŸåˆ¤å®š

        # åæŸç‡è¨ˆç®—
        convergence_rate = 0.0
        if len(fitness_values) > 1:
            total_improvement = fitness_values[-1] - fitness_values[0]
            convergence_rate = total_improvement / len(fitness_values)

        return {
            'convergence_detected': bool(convergence_detected),
            'stagnation_generations': int(max_stagnation),
            'max_fitness_achieved': float(max(fitness_values)),
            'convergence_rate': float(convergence_rate),
            'final_fitness': float(fitness_values[-1]),
            'initial_fitness': float(fitness_values[0]),
            'total_improvement': float(total_improvement) if len(fitness_values) > 1 else 0.0
        }

    def get_diversity_analysis(self) -> Dict[str, Any]:
        """å¤šæ§˜æ€§åˆ†æ"""

        if not self.generation_stats:
            return {
                'final_diversity': 0.0,
                'max_diversity': 0.0,
                'min_diversity': 0.0,
                'avg_diversity': 0.0,
                'diversity_trend': 'unknown'
            }

        diversity_values = [
            stats.diversity_score for stats in self.generation_stats]

        # å¤šæ§˜æ€§å‚¾å‘åˆ†æ
        if len(diversity_values) > 1:
            slope = (diversity_values[-1] -
                     diversity_values[0]) / len(diversity_values)
            if slope > 0.01:
                trend = 'increasing'
            elif slope < -0.01:
                trend = 'decreasing'
            else:
                trend = 'stable'
        else:
            trend = 'unknown'

        return {
            'final_diversity': float(diversity_values[-1]),
            'max_diversity': float(max(diversity_values)),
            'min_diversity': float(min(diversity_values)),
            'avg_diversity': float(sum(diversity_values) / len(diversity_values)),
            'diversity_trend': trend,
            'diversity_variance': float(np.var(diversity_values)) if len(diversity_values) > 1 else 0.0
        }

    def get_best_individual_history(self) -> List[Dict[str, Any]]:
        """æœ€è‰¯å€‹ä½“å±¥æ­´å–å¾—"""

        history = []
        for individual_id in self.best_individuals_history:
            if individual_id in self.individual_records:
                record = self.individual_records[individual_id]
                history.append({
                    'generation': int(record.generation),
                    'individual_id': individual_id,
                    'fitness': float(record.overall_fitness),
                    'fitness_components': record.fitness_components,
                    'complexity': int(record.model_complexity)
                })

        return history

    def _calculate_stats(self, values: List[float]) -> Dict[str, float]:
        """çµ±è¨ˆå€¤è¨ˆç®—"""

        if not values:
            return {
                'min': 0.0,
                'max': 0.0,
                'mean': 0.0,
                'median': 0.0,
                'std': 0.0
            }

        values = np.array(values)
        return {
            'min': float(np.min(values)),
            'max': float(np.max(values)),
            'mean': float(np.mean(values)),
            'median': float(np.median(values)),
            'std': float(np.std(values))
        }

    def _calculate_diversity(self, population: List[Any]) -> float:
        """å€‹ä½“ç¾¤å¤šæ§˜æ€§è¨ˆç®—"""

        if len(population) <= 1:
            return 0.0

        # éºä¼çš„è·é›¢ãƒ™ãƒ¼ã‚¹å¤šæ§˜æ€§è¨ˆç®—ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        try:
            distances = []
            for i in range(len(population)):
                for j in range(i + 1, len(population)):
                    distance = self._genetic_distance(
                        population[i], population[j])
                    distances.append(distance)

            return float(np.mean(distances)) if distances else 0.0

        except Exception:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ¦ãƒ‹ãƒ¼ã‚¯å€‹ä½“æ•°ãƒ™ãƒ¼ã‚¹
            unique_count = len(set(str(ind) for ind in population))
            return float(unique_count / len(population))

    def _genetic_distance(self, ind1: Any, ind2: Any) -> float:
        """2å€‹ä½“é–“ã®éºä¼çš„è·é›¢"""

        try:
            # ã‚²ãƒãƒ ãƒ™ãƒ¼ã‚¹è·é›¢
            if hasattr(ind1, 'genome') and hasattr(ind2, 'genome'):
                genome1 = ind1.genome
                genome2 = ind2.genome

                if isinstance(genome1, dict) and isinstance(genome2, dict):
                    common_keys = set(genome1.keys()) & set(genome2.keys())
                    if common_keys:
                        diffs = []
                        for key in common_keys:
                            try:
                                diff = abs(
                                    float(genome1[key]) - float(genome2[key]))
                                diffs.append(diff)
                            except (ValueError, TypeError):
                                # æ–‡å­—åˆ—æ¯”è¼ƒ
                                diff = 0.0 if genome1[key] == genome2[key] else 1.0
                                diffs.append(diff)
                        return float(np.mean(diffs)) if diffs else 1.0

            # é©å¿œåº¦ãƒ™ãƒ¼ã‚¹è·é›¢
            if hasattr(ind1, 'fitness') and hasattr(ind2, 'fitness'):
                if hasattr(ind1.fitness, 'values') and hasattr(ind2.fitness, 'values'):
                    values1 = ind1.fitness.values
                    values2 = ind2.fitness.values
                    return float(np.linalg.norm(np.array(values1) - np.array(values2)))

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
            return 1.0

        except Exception:
            return 1.0

    def _calculate_pareto_front(self, evaluation_results: List[Dict[str, Any]]) -> List[str]:
        """ãƒ‘ãƒ¬ãƒ¼ãƒˆæœ€é©è§£è¨ˆç®—"""

        if not evaluation_results:
            return []

        pareto_front = []
        for i, result_i in enumerate(evaluation_results):
            individual_id_i = f"ind_{i}"
            is_dominated = False

            for j, result_j in enumerate(evaluation_results):
                if i != j and self._dominates(result_j, result_i):
                    is_dominated = True
                    break

            if not is_dominated:
                pareto_front.append(individual_id_i)

        return pareto_front

    def _dominates(self, components_a: Dict[str, float], components_b: Dict[str, float]) -> bool:
        """æ”¯é…é–¢ä¿‚ãƒã‚§ãƒƒã‚¯"""

        objectives = ['accuracy', 'simplicity',
                      'interpretability', 'generalization', 'validity']

        all_better_or_equal = True
        at_least_one_better = False

        for obj in objectives:
            val_a = components_a.get(obj, 0.0)
            val_b = components_b.get(obj, 0.0)

            if val_a < val_b:
                all_better_or_equal = False
                break
            elif val_a > val_b:
                at_least_one_better = True

        return all_better_or_equal and at_least_one_better

    def _get_memory_usage(self) -> float:
        """ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡å–å¾—ï¼ˆMBï¼‰"""

        try:
            import psutil
            process = psutil.Process()
            memory_info = process.memory_info()
            return memory_info.rss / (1024 * 1024)  # MB
        except:
            return 0.0

    def _save_config(self):
        """è¨­å®šä¿å­˜"""

        config_path = os.path.join(self.save_dir, f"{self.run_id}_config.json")

        def custom_json_serializer(obj):
            """ã‚«ã‚¹ã‚¿ãƒ JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼"""
            if isinstance(obj, (np.bool_, bool)):
                return bool(obj)
            elif isinstance(obj, (np.integer, int)):
                return int(obj)
            elif isinstance(obj, (np.floating, float)):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, datetime):
                return obj.isoformat()
            elif hasattr(obj, '__dict__'):
                return obj.__dict__
            else:
                return str(obj)

        with open(config_path, 'w', encoding='utf-8') as f:
            json.dump(self.config, f, indent=2,
                      ensure_ascii=False, default=custom_json_serializer)

    def _save_intermediate_results(self):
        """ä¸­é–“çµæœä¿å­˜"""

        def custom_json_serializer(obj):
            """ã‚«ã‚¹ã‚¿ãƒ JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼"""
            if isinstance(obj, (np.bool_, bool)):
                return bool(obj)
            elif isinstance(obj, (np.integer, int)):
                return int(obj)
            elif isinstance(obj, (np.floating, float)):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, datetime):
                return obj.isoformat()
            elif hasattr(obj, '__dict__'):
                return obj.__dict__
            else:
                return str(obj)

        # ä¸–ä»£çµ±è¨ˆä¿å­˜
        stats_path = os.path.join(
            self.save_dir, f"{self.run_id}_generation_stats.json")

        stats_data = []
        for stats in self.generation_stats:
            stats_dict = asdict(stats)
            stats_dict['timestamp'] = stats.timestamp.isoformat()
            stats_data.append(stats_dict)

        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(stats_data, f, indent=2, ensure_ascii=False,
                      default=custom_json_serializer)

        # å€‹ä½“è¨˜éŒ²ä¿å­˜
        individuals_path = os.path.join(
            self.save_dir, f"{self.run_id}_individuals.json")

        individuals_data = {}
        for individual_id, record in self.individual_records.items():
            record_dict = asdict(record)
            record_dict['timestamp'] = record.timestamp.isoformat()
            individuals_data[individual_id] = record_dict

        with open(individuals_path, 'w', encoding='utf-8') as f:
            json.dump(individuals_data, f, indent=2,
                      ensure_ascii=False, default=custom_json_serializer)

    def _generate_final_report(self):
        """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆï¼ˆJSONå®‰å…¨ç‰ˆï¼‰"""

        def custom_json_serializer(obj):
            """ã‚«ã‚¹ã‚¿ãƒ JSONã‚·ãƒªã‚¢ãƒ©ã‚¤ã‚¶ãƒ¼"""
            if isinstance(obj, (np.bool_, bool)):
                return bool(obj)
            elif isinstance(obj, (np.integer, int)):
                return int(obj)
            elif isinstance(obj, (np.floating, float)):
                return float(obj)
            elif isinstance(obj, np.ndarray):
                return obj.tolist()
            elif isinstance(obj, datetime):
                return obj.isoformat()
            elif hasattr(obj, '__dict__'):
                return obj.__dict__
            else:
                return str(obj)

        def make_json_safe(data):
            """ãƒ‡ãƒ¼ã‚¿ã‚’JSONå®‰å…¨ã«ã™ã‚‹å†å¸°é–¢æ•°"""
            if isinstance(data, dict):
                return {k: make_json_safe(v) for k, v in data.items()}
            elif isinstance(data, list):
                return [make_json_safe(item) for item in data]
            elif isinstance(data, tuple):
                return [make_json_safe(item) for item in data]
            elif isinstance(data, (np.bool_, bool)):
                return bool(data)
            elif isinstance(data, (np.integer, int)):
                return int(data)
            elif isinstance(data, (np.floating, float)):
                return float(data)
            elif isinstance(data, np.ndarray):
                return data.tolist()
            elif isinstance(data, datetime):
                return data.isoformat()
            elif hasattr(data, '__dict__'):
                return make_json_safe(data.__dict__)
            else:
                return str(data) if data is not None else None

        # å…¨ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        self._save_intermediate_results()

        # æ€§èƒ½ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆ
        plot_files = self.generate_performance_plots()

        # åæŸåˆ†æ
        convergence_analysis = self.get_convergence_analysis()

        # å¤šæ§˜æ€§åˆ†æ
        diversity_analysis = self.get_diversity_analysis()

        # æœ€è‰¯å€‹ä½“å±¥æ­´
        best_history = self.get_best_individual_history()

        # æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆ
        report = {
            'run_info': {
                'run_id': self.run_id,
                'start_time': self.start_time.isoformat() if self.start_time else None,
                'end_time': self.end_time.isoformat() if self.end_time else None,
                'duration_seconds': (self.end_time - self.start_time).total_seconds() if self.start_time and self.end_time else None,
                'total_generations': len(self.generation_stats),
                'total_individuals': len(self.individual_records)
            },
            'configuration': self.config,
            'convergence_analysis': convergence_analysis,
            'diversity_analysis': diversity_analysis,
            'best_individual_history': best_history,
            'final_statistics': {
                'best_fitness': float(self.generation_stats[-1].best_fitness) if self.generation_stats else 0.0,
                'final_diversity': float(self.generation_stats[-1].diversity_score) if self.generation_stats else 0.0,
                'pareto_front_size': len(self.pareto_front_history[-1]) if self.pareto_front_history else 0
            },
            'plot_files': plot_files
        }

        # ãƒ‡ãƒ¼ã‚¿ã‚’JSONå®‰å…¨ã«ã™ã‚‹
        safe_report = make_json_safe(report)

        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
        report_path = os.path.join(
            self.save_dir, f"{self.run_id}_final_report.json")

        try:
            with open(report_path, 'w', encoding='utf-8') as f:
                json.dump(safe_report, f, indent=2, ensure_ascii=False,
                          default=custom_json_serializer)

            print(f"ğŸ“Š Final report saved: {report_path}")
            return safe_report

        except Exception as e:
            print(f"âš ï¸ JSONä¿å­˜ã‚¨ãƒ©ãƒ¼: {e}")
            # ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜
            text_report_path = report_path.replace('.json', '_backup.txt')
            with open(text_report_path, 'w', encoding='utf-8') as f:
                f.write(str(safe_report))
            print(f"ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆå½¢å¼ã§ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ä¿å­˜: {text_report_path}")
            return safe_report

    def _start_monitoring_thread(self):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ç›£è¦–ã‚¹ãƒ¬ãƒƒãƒ‰é–‹å§‹"""

        def monitoring_worker():
            while True:
                try:
                    message_type, data = self.monitoring_queue.get(timeout=1.0)

                    if message_type == 'STOP':
                        break
                    elif message_type == 'GENERATION':
                        self._handle_realtime_generation_update(data)

                except queue.Empty:
                    continue
                except Exception as e:
                    print(f"âš ï¸ Monitoring error: {e}")

        self.monitoring_thread = threading.Thread(
            target=monitoring_worker, daemon=True)
        self.monitoring_thread.start()

    def _handle_realtime_generation_update(self, stats: GenerationStats):
        """ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ä¸–ä»£æ›´æ–°å‡¦ç†"""

        # ç°¡æ˜“çš„ãªãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ å‡ºåŠ›
        print(f"âš¡ Real-time update - Gen {stats.generation}: "
              f"Best={stats.best_fitness:.4f}, "
              f"Diversity={stats.diversity_score:.3f}, "
              f"Time={stats.evaluation_time:.2f}s")

        # å¿…è¦ã«å¿œã˜ã¦å¤–éƒ¨ã‚·ã‚¹ãƒ†ãƒ ã¸ã®é€šçŸ¥ãªã©ã‚’è¿½åŠ å¯èƒ½


class OptimizationReporter:
    """æœ€é©åŒ–çµæœãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""

    @staticmethod
    def generate_html_report(tracker: OptimizationTracker) -> str:
        """HTMLå½¢å¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""

        convergence_analysis = tracker.get_convergence_analysis()
        diversity_analysis = tracker.get_diversity_analysis()

        html_content = f"""
        <!DOCTYPE html>
        <html lang="ja">
        <head>
            <meta charset="UTF-8">
            <title>Optimization Report - {tracker.run_id}</title>
            <style>
                body {{ font-family: Arial, sans-serif; margin: 40px; }}
                .header {{ background: #f0f0f0; padding: 20px; border-radius: 8px; }}
                .section {{ margin: 20px 0; padding: 15px; border-left: 4px solid #007acc; }}
                .metric {{ display: inline-block; margin: 10px; padding: 10px; background: #f9f9f9; border-radius: 4px; }}
                .chart {{ text-align: center; margin: 20px 0; }}
            </style>
        </head>
        <body>
            <div class="header">
                <h1>Fuzzy Decision Tree Optimization Report</h1>
                <p>Run ID: {tracker.run_id}</p>
                <p>Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>
            </div>
            
            <div class="section">
                <h2>Execution Summary</h2>
                <div class="metric">
                    <strong>Generations:</strong> {len(tracker.generation_stats)}
                </div>
                <div class="metric">
                    <strong>Best Fitness:</strong> {tracker.generation_stats[-1].best_fitness:.4f if tracker.generation_stats else 'N/A'}
                </div>
                <div class="metric">
                    <strong>Final Diversity:</strong> {tracker.generation_stats[-1].diversity_score:.3f if tracker.generation_stats else 'N/A'}
                </div>
            </div>
            
            <div class="section">
                <h2>Convergence Analysis</h2>
                <div class="metric">
                    <strong>Convergence Detected:</strong> {'Yes' if convergence_analysis.get('convergence_detected', False) else 'No'}
                </div>
                <div class="metric">
                    <strong>Stagnation Generations:</strong> {convergence_analysis.get('stagnation_generations', 0)}
                </div>
                <div class="metric">
                    <strong>Max Fitness:</strong> {convergence_analysis.get('max_fitness_achieved', 0.0):.4f}
                </div>
            </div>
            
            <div class="section">
                <h2>Diversity Analysis</h2>
                <div class="metric">
                    <strong>Final Diversity:</strong> {diversity_analysis.get('final_diversity', 0.0):.3f}
                </div>
                <div class="metric">
                    <strong>Max Diversity:</strong> {diversity_analysis.get('max_diversity', 0.0):.3f}
                </div>
                <div class="metric">
                    <strong>Trend:</strong> {diversity_analysis.get('diversity_trend', 'Unknown')}
                </div>
            </div>
            
            <div class="section">
                <h2>Performance Charts</h2>
                <div class="chart">
                    <p>Performance visualization charts have been generated.</p>
                    <p>Check the optimization logs directory for detailed plots.</p>
                </div>
            </div>
            
            <div class="section">
                <h2>Best Individual History</h2>
                <table border="1" style="border-collapse: collapse; width: 100%;">
                    <thead>
                        <tr>
                            <th>Generation</th>
                            <th>Fitness</th>
                            <th>Complexity</th>
                            <th>Individual ID</th>
                        </tr>
                    </thead>
                    <tbody>
        """

        # æœ€è‰¯å€‹ä½“å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«
        best_history = tracker.get_best_individual_history()
        for entry in best_history[-10:]:  # æœ€æ–°10ä¸–ä»£ã®ã¿è¡¨ç¤º
            html_content += f"""
                        <tr>
                            <td>{entry['generation']}</td>
                            <td>{entry['fitness']:.4f}</td>
                            <td>{entry['complexity']}</td>
                            <td>{entry['individual_id']}</td>
                        </tr>
            """

        html_content += """
                    </tbody>
                </table>
            </div>
        </body>
        </html>
        """

        # HTMLãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
        html_path = os.path.join(
            tracker.save_dir, f"{tracker.run_id}_report.html")
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)

        print(f"ğŸ“Š HTML report generated: {html_path}")
        return html_path

    @staticmethod
    def export_results_to_csv(tracker: OptimizationTracker) -> List[str]:
        """CSVå½¢å¼ã§ã®ãƒ‡ãƒ¼ã‚¿ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ"""

        csv_files = []

        # ä¸–ä»£çµ±è¨ˆCSV
        if tracker.generation_stats:
            import pandas as pd

            stats_data = []
            for stats in tracker.generation_stats:
                stats_dict = asdict(stats)
                stats_dict['timestamp'] = stats.timestamp.isoformat()
                stats_data.append(stats_dict)

            df_stats = pd.DataFrame(stats_data)
            stats_csv_path = os.path.join(
                tracker.save_dir, f"{tracker.run_id}_generation_stats.csv")
            df_stats.to_csv(stats_csv_path, index=False, encoding='utf-8')
            csv_files.append(stats_csv_path)

        # å€‹ä½“è¨˜éŒ²CSV
        if tracker.individual_records:
            individual_data = []
            for individual_id, record in tracker.individual_records.items():
                record_dict = asdict(record)
                record_dict['individual_id'] = individual_id
                record_dict['timestamp'] = record.timestamp.isoformat()

                # fitness_componentsã‚’å±•é–‹
                for component, value in record.fitness_components.items():
                    record_dict[f'fitness_{component}'] = value

                individual_data.append(record_dict)

            df_individuals = pd.DataFrame(individual_data)
            individuals_csv_path = os.path.join(
                tracker.save_dir, f"{tracker.run_id}_individuals.csv")
            df_individuals.to_csv(individuals_csv_path,
                                  index=False, encoding='utf-8')
            csv_files.append(individuals_csv_path)

        print(f"ğŸ“ CSV files exported: {len(csv_files)} files")
        return csv_files

    @staticmethod
    def generate_summary_statistics(tracker: OptimizationTracker) -> Dict[str, Any]:
        """è¦ç´„çµ±è¨ˆç”Ÿæˆ"""

        if not tracker.generation_stats:
            return {'error': 'No generation statistics available'}

        fitness_values = [
            stats.best_fitness for stats in tracker.generation_stats]
        diversity_values = [
            stats.diversity_score for stats in tracker.generation_stats]

        # åŸºæœ¬çµ±è¨ˆ
        summary = {
            'run_info': {
                'run_id': tracker.run_id,
                'total_generations': len(tracker.generation_stats),
                'total_individuals_evaluated': len(tracker.individual_records),
                'duration_seconds': (tracker.end_time - tracker.start_time).total_seconds() if tracker.start_time and tracker.end_time else None
            },
            'fitness_statistics': {
                'initial_best': float(fitness_values[0]) if fitness_values else 0.0,
                'final_best': float(fitness_values[-1]) if fitness_values else 0.0,
                'max_achieved': float(max(fitness_values)) if fitness_values else 0.0,
                'improvement': float(fitness_values[-1] - fitness_values[0]) if len(fitness_values) > 1 else 0.0,
                'improvement_percentage': float((fitness_values[-1] - fitness_values[0]) / max(fitness_values[0], 1e-8) * 100) if len(fitness_values) > 1 else 0.0
            },
            'diversity_statistics': {
                'initial_diversity': float(diversity_values[0]) if diversity_values else 0.0,
                'final_diversity': float(diversity_values[-1]) if diversity_values else 0.0,
                'max_diversity': float(max(diversity_values)) if diversity_values else 0.0,
                'min_diversity': float(min(diversity_values)) if diversity_values else 0.0,
                'avg_diversity': float(sum(diversity_values) / len(diversity_values)) if diversity_values else 0.0
            },
            'convergence_info': tracker.get_convergence_analysis(),
            'performance_metrics': {
                'avg_evaluation_time': float(sum(stats.evaluation_time for stats in tracker.generation_stats) / len(tracker.generation_stats)),
                'total_evaluation_time': float(sum(stats.evaluation_time for stats in tracker.generation_stats)),
                'avg_memory_usage': float(sum(stats.memory_usage for stats in tracker.generation_stats) / len(tracker.generation_stats)),
                'max_memory_usage': float(max(stats.memory_usage for stats in tracker.generation_stats))
            }
        }

        return summary


# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
def create_optimization_tracker(run_id: str = None, save_dir: str = "optimization_logs") -> OptimizationTracker:
    """æœ€é©åŒ–ãƒˆãƒ©ãƒƒã‚«ãƒ¼ä½œæˆ"""
    return OptimizationTracker(run_id=run_id, save_dir=save_dir)


def generate_optimization_report(tracker: OptimizationTracker, format: str = 'html') -> str:
    """æœ€é©åŒ–ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""

    if format.lower() == 'html':
        return OptimizationReporter.generate_html_report(tracker)
    elif format.lower() == 'csv':
        files = OptimizationReporter.export_results_to_csv(tracker)
        return f"CSV files exported: {', '.join(files)}"
    else:
        raise ValueError(f"Unsupported format: {format}")


if __name__ == "__main__":
    # ãƒ‡ãƒ¢ãƒ³ã‚¹ãƒˆãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ç”¨ãƒ†ã‚¹ãƒˆã‚³ãƒ¼ãƒ‰
    print("ğŸ§¬ OptimizationTracker Demo")

    # ãƒˆãƒ©ãƒƒã‚«ãƒ¼ä½œæˆ
    tracker = OptimizationTracker("demo_test")

    # è¨­å®šä¾‹
    config = {
        'population_size': 30,
        'generations': 10,
        'mutation_rate': 0.15,
        'crossover_rate': 0.8
    }

    # æœ€é©åŒ–é–‹å§‹
    tracker.start_optimization(config)

    # ãƒ€ãƒŸãƒ¼ãƒ‡ãƒ¼ã‚¿ã§ä¸–ä»£è¨˜éŒ²
    import random
    for gen in range(5):
        population = [f"individual_{i}" for i in range(30)]
        evaluation_results = [
            {
                'overall_fitness': random.uniform(0.5, 0.9),
                'accuracy': random.uniform(0.6, 0.9),
                'simplicity': random.uniform(0.4, 0.8),
                'interpretability': random.uniform(0.5, 0.9),
                'generalization': random.uniform(0.4, 0.8),
                'validity': random.uniform(0.6, 0.95)
            }
            for _ in range(30)
        ]

        tracker.record_generation(gen, population, evaluation_results)
        time.sleep(0.1)  # çŸ­ã„å¾…æ©Ÿ

    # æœ€é©åŒ–çµ‚äº†
    tracker.end_optimization()

    # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
    summary = OptimizationReporter.generate_summary_statistics(tracker)
    print("\nğŸ“Š Summary Statistics:")
    print(
        f"   Final Best Fitness: {summary['fitness_statistics']['final_best']:.4f}")
    print(
        f"   Total Improvement: {summary['fitness_statistics']['improvement']:.4f}")
    print(
        f"   Convergence Detected: {summary['convergence_info']['convergence_detected']}")

    print("âœ… Demo completed!")
