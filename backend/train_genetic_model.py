# backend/train_genetic_model.py
"""
éºä¼çš„ãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨å­¦ç¿’å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ä½¿ç”¨ä¾‹:
    python train_genetic_model.py --generations 50 --population_size 30
    python train_genetic_model.py --config config.json
"""

import argparse
import json
import logging
import time
import sys
import os
from pathlib import Path
from typing import Dict, List, Tuple, Optional, Any

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
import matplotlib.pyplot as plt

# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from genetic_fuzzy_tree import GeneticFuzzyTreeOptimizer, GeneticParameters, GeneticIndividual
from optimization_tracker import OptimizationTracker
from evaluation_metrics import MultiObjectiveEvaluator
from model_persistence import ModelPersistence
from explanation_engine import AdvancedExplanationEngine

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('genetic_training.log'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger(__name__)


class TrainingConfiguration:
    """å­¦ç¿’è¨­å®šã‚¯ãƒ©ã‚¹"""

    def __init__(self, config_dict: Dict[str, Any] = None):
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        self.genetic_parameters = GeneticParameters(
            population_size=50,
            generations=30,
            crossover_rate=0.8,
            mutation_rate=0.2,
            tournament_size=3,
            elitism_ratio=0.1,
            max_tree_depth=5,
            min_samples_split=5,
            min_samples_leaf=2
        )

        # ãƒ‡ãƒ¼ã‚¿è¨­å®š
        self.data_settings = {
            'train_test_split_ratio': 0.8,
            'validation_split_ratio': 0.2,
            'random_state': 42,
            'normalize_features': True,
            'feature_selection': True,
            'max_features': 10
        }

        # å‡ºåŠ›è¨­å®š
        self.output_settings = {
            'save_model': True,
            'save_plots': True,
            'save_explanations': True,
            'output_directory': 'genetic_training_output',
            'model_name_prefix': 'genetic_fuzzy_tree'
        }

        # è¿½è·¡è¨­å®š
        self.tracking_settings = {
            'enable_tracking': True,
            'detailed_logging': True,
            'save_genealogy': True,
            'create_visualizations': True
        }

        # è¨­å®šè¾æ›¸ã§ä¸Šæ›¸ã
        if config_dict:
            self._update_from_dict(config_dict)

    def _update_from_dict(self, config_dict: Dict[str, Any]):
        """è¨­å®šè¾æ›¸ã‹ã‚‰æ›´æ–°"""

        # éºä¼çš„ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿æ›´æ–°
        if 'genetic_parameters' in config_dict:
            genetic_config = config_dict['genetic_parameters']
            for key, value in genetic_config.items():
                if hasattr(self.genetic_parameters, key):
                    setattr(self.genetic_parameters, key, value)

        # ãã®ä»–ã®è¨­å®šæ›´æ–°
        for section_name in ['data_settings', 'output_settings', 'tracking_settings']:
            if section_name in config_dict:
                getattr(self, section_name).update(config_dict[section_name])

    def save_to_file(self, filepath: str):
        """è¨­å®šã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
        config_dict = {
            'genetic_parameters': self.genetic_parameters.__dict__,
            'data_settings': self.data_settings,
            'output_settings': self.output_settings,
            'tracking_settings': self.tracking_settings
        }

        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(config_dict, f, indent=2, ensure_ascii=False)

    @classmethod
    def load_from_file(cls, filepath: str) -> 'TrainingConfiguration':
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è¨­å®šã‚’èª­ã¿è¾¼ã¿"""
        with open(filepath, 'r', encoding='utf-8') as f:
            config_dict = json.load(f)

        return cls(config_dict)


class GeneticTrainingPipeline:
    """éºä¼çš„å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³"""

    def __init__(self, config: TrainingConfiguration):
        self.config = config
        self.output_dir = Path(config.output_settings['output_directory'])
        self.output_dir.mkdir(parents=True, exist_ok=True)

        # ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–
        self.optimizer = None
        self.tracker = None
        self.evaluator = None
        self.persistence = None
        self.explanation_engine = None

        # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿
        self.training_data = None
        self.validation_data = None
        self.target_values = None
        self.validation_targets = None
        self.feature_names = None

        # çµæœ
        self.best_individual = None
        self.training_history = None

        logger.info("ğŸ§¬ éºä¼çš„å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³åˆæœŸåŒ–å®Œäº†")

    def setup_components(self):
        """ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"""

        # æœ€é©åŒ–å™¨
        self.optimizer = GeneticFuzzyTreeOptimizer(
            self.config.genetic_parameters)

        # è¿½è·¡å™¨
        if self.config.tracking_settings['enable_tracking']:
            tracking_db_path = self.output_dir / "optimization_tracking.db"
            self.tracker = OptimizationTracker(
                tracking_db_path=str(tracking_db_path),
                enable_detailed_logging=self.config.tracking_settings['detailed_logging']
            )

        # è©•ä¾¡å™¨
        self.evaluator = MultiObjectiveEvaluator()

        # æ°¸ç¶šåŒ–
        models_dir = self.output_dir / "models"
        metadata_db_path = self.output_dir / "model_metadata.db"
        self.persistence = ModelPersistence(
            models_directory=str(models_dir),
            metadata_db_path=str(metadata_db_path)
        )

        # èª¬æ˜ã‚¨ãƒ³ã‚¸ãƒ³
        self.explanation_engine = AdvancedExplanationEngine()

        logger.info("âœ… å…¨ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆåˆæœŸåŒ–å®Œäº†")

    def load_research_lab_data(self) -> Tuple[pd.DataFrame, np.ndarray, List[str]]:
        """ç ”ç©¶å®¤ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ï¼ˆãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—äº’æ›ï¼‰"""

        # ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‹ã‚‰èª­ã¿è¾¼ã¿
        try:
            import sqlite3

            # ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—ã®ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«æ¥ç¶š
            conn = sqlite3.connect('fdtlss.db')

            # ç ”ç©¶å®¤ãƒ‡ãƒ¼ã‚¿å–å¾—
            labs_df = pd.read_sql_query("""
                SELECT 
                    research_intensity,
                    advisor_style,
                    team_work,
                    workload,
                    theory_practice,
                    (research_intensity + advisor_style + team_work + workload + theory_practice) / 5.0 as target_score
                FROM labs 
                WHERE is_active = 1
            """, conn)

            conn.close()

            # ç‰¹å¾´é‡ã¨ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†é›¢
            feature_columns = ['research_intensity', 'advisor_style',
                               'team_work', 'workload', 'theory_practice']
            X = labs_df[feature_columns]
            y = labs_df['target_score'].values

            logger.info(f"ğŸ“Š ç ”ç©¶å®¤ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(X)}ä»¶")
            return X, y, feature_columns

        except Exception as e:
            logger.warning(f"ãƒ—ãƒ­ãƒˆã‚¿ã‚¤ãƒ—DBã‹ã‚‰ã®èª­ã¿è¾¼ã¿å¤±æ•—: {e}")
            return self._generate_synthetic_data()

    def _generate_synthetic_data(self) -> Tuple[pd.DataFrame, np.ndarray, List[str]]:
        """åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆï¼ˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""

        logger.info("ğŸ”„ åˆæˆç ”ç©¶å®¤ãƒ‡ãƒ¼ã‚¿ã‚’ç”Ÿæˆä¸­...")

        np.random.seed(42)
        n_samples = 300  # ã‚ˆã‚Šå¤šãã®ã‚µãƒ³ãƒ—ãƒ«ç”Ÿæˆ

        # ç‰¹å¾´é‡å®šç¾©
        feature_names = [
            'research_intensity',     # ç ”ç©¶å¼·åº¦
            'advisor_style',         # æŒ‡å°ã‚¹ã‚¿ã‚¤ãƒ«
            'team_work',            # ãƒãƒ¼ãƒ ãƒ¯ãƒ¼ã‚¯
            'workload',             # ãƒ¯ãƒ¼ã‚¯ãƒ­ãƒ¼ãƒ‰
            'theory_practice',      # ç†è«–ãƒ»å®Ÿè·µãƒãƒ©ãƒ³ã‚¹
            'international_focus',  # å›½éš›æ€§
            'industry_connection',  # ç”£æ¥­é€£æº
            'publication_rate',     # è«–æ–‡ç™ºè¡¨ç‡
            'student_satisfaction',  # å­¦ç”Ÿæº€è¶³åº¦
            'career_support'        # ã‚­ãƒ£ãƒªã‚¢æ”¯æ´
        ]

        # ç›¸é–¢ã‚’è€ƒæ…®ã—ãŸç‰¹å¾´é‡ç”Ÿæˆ
        data = {}

        # åŸºæœ¬ç‰¹å¾´é‡ï¼ˆ1-10ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰
        data['research_intensity'] = np.random.normal(7.0, 1.5, n_samples)
        data['advisor_style'] = np.random.normal(6.0, 2.0, n_samples)
        data['team_work'] = np.random.normal(6.5, 1.8, n_samples)
        data['workload'] = np.random.normal(6.8, 1.6, n_samples)
        data['theory_practice'] = np.random.normal(6.2, 2.2, n_samples)

        # æ‹¡å¼µç‰¹å¾´é‡ï¼ˆç›¸é–¢ã‚’æŒãŸã›ã‚‹ï¼‰
        data['international_focus'] = (
            0.3 * data['research_intensity'] +
            0.2 * data['advisor_style'] +
            np.random.normal(0, 1.0, n_samples)
        )

        data['industry_connection'] = (
            0.4 * data['theory_practice'] +
            0.2 * data['workload'] +
            np.random.normal(0, 1.2, n_samples)
        )

        data['publication_rate'] = (
            0.5 * data['research_intensity'] +
            0.3 * data['workload'] +
            np.random.normal(0, 1.0, n_samples)
        )

        data['student_satisfaction'] = (
            -0.2 * data['workload'] +
            0.3 * data['advisor_style'] +
            0.2 * data['team_work'] +
            np.random.normal(0, 1.0, n_samples)
        )

        data['career_support'] = (
            0.2 * data['advisor_style'] +
            0.3 * data['industry_connection'] +
            np.random.normal(0, 1.0, n_samples)
        )

        # 1-10ã®ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
        for feature in feature_names:
            data[feature] = np.clip(data[feature], 1.0, 10.0)

        # DataFrameä½œæˆ
        X = pd.DataFrame(data)

        # è¤‡é›‘ãªéç·šå½¢ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé–¢æ•°
        y = (
            0.25 * X['research_intensity'] +
            0.20 * X['advisor_style'] +
            0.15 * X['team_work'] +
            0.10 * X['workload'] +
            0.10 * X['theory_practice'] +
            0.08 * X['international_focus'] +
            0.07 * X['industry_connection'] +
            0.05 * X['publication_rate'] +
            # éç·šå½¢é …
            0.02 * (X['research_intensity'] * X['theory_practice']) / 10.0 +
            0.02 * np.sin(X['advisor_style'] / 2.0) +
            0.01 * (X['team_work'] ** 1.5) / 10.0 +
            np.random.normal(0, 0.3, n_samples)  # ãƒã‚¤ã‚º
        ) / 10.0  # æ­£è¦åŒ–

        # 0-1ã®ç¯„å›²ã«ã‚¯ãƒªãƒƒãƒ—
        y = np.clip(y, 0.0, 1.0)

        logger.info(f"ğŸ“Š åˆæˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆå®Œäº†: {len(X)}ä»¶, {len(feature_names)}ç‰¹å¾´é‡")

        return X, y, feature_names

    def prepare_data(self, X: pd.DataFrame, y: np.ndarray, feature_names: List[str]):
        """ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†"""

        logger.info("ğŸ”„ ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†é–‹å§‹...")

        # è¨“ç·´ãƒ»æ¤œè¨¼åˆ†å‰²
        X_train, X_val, y_train, y_val = train_test_split(
            X, y,
            test_size=self.config.data_settings['validation_split_ratio'],
            random_state=self.config.data_settings['random_state'],
            stratify=None  # å›å¸°å•é¡Œã®ãŸã‚
        )

        # ç‰¹å¾´é‡é¸æŠï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if self.config.data_settings['feature_selection']:
            selected_features = self._select_features(
                X_train, y_train, feature_names)
            X_train = X_train[selected_features]
            X_val = X_val[selected_features]
            feature_names = selected_features
            logger.info(f"ğŸ“‰ ç‰¹å¾´é‡é¸æŠ: {len(selected_features)}å€‹é¸æŠ")

        # æ­£è¦åŒ–ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
        if self.config.data_settings['normalize_features']:
            scaler = StandardScaler()
            X_train_scaled = pd.DataFrame(
                scaler.fit_transform(X_train),
                columns=X_train.columns,
                index=X_train.index
            )
            X_val_scaled = pd.DataFrame(
                scaler.transform(X_val),
                columns=X_val.columns,
                index=X_val.index
            )

            # ã‚¹ã‚±ãƒ¼ãƒ©ãƒ¼ä¿å­˜
            import pickle
            scaler_path = self.output_dir / "feature_scaler.pkl"
            with open(scaler_path, 'wb') as f:
                pickle.dump(scaler, f)

            X_train, X_val = X_train_scaled, X_val_scaled
            logger.info("ğŸ“ ç‰¹å¾´é‡æ­£è¦åŒ–å®Œäº†")

        # ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹å¤‰æ•°è¨­å®š
        self.training_data = X_train
        self.validation_data = X_val
        self.target_values = y_train
        self.validation_targets = y_val
        self.feature_names = feature_names

        logger.info(f"âœ… ãƒ‡ãƒ¼ã‚¿å‰å‡¦ç†å®Œäº†")
        logger.info(f"   è¨“ç·´ãƒ‡ãƒ¼ã‚¿: {len(X_train)}ä»¶")
        logger.info(f"   æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: {len(X_val)}ä»¶")
        logger.info(f"   ç‰¹å¾´é‡æ•°: {len(feature_names)}")

    def _select_features(self, X: pd.DataFrame, y: np.ndarray, feature_names: List[str]) -> List[str]:
        """ç‰¹å¾´é‡é¸æŠ"""

        from sklearn.feature_selection import SelectKBest, f_regression

        max_features = min(
            self.config.data_settings['max_features'],
            len(feature_names)
        )

        selector = SelectKBest(score_func=f_regression, k=max_features)
        X_selected = selector.fit_transform(X, y)

        # é¸æŠã•ã‚ŒãŸç‰¹å¾´é‡ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å–å¾—
        selected_indices = selector.get_support(indices=True)
        selected_features = [feature_names[i] for i in selected_indices]

        return selected_features

    def run_optimization(self) -> GeneticIndividual:
        """éºä¼çš„æœ€é©åŒ–å®Ÿè¡Œ"""

        logger.info("ğŸ§¬ éºä¼çš„æœ€é©åŒ–é–‹å§‹...")

        # è¿½è·¡é–‹å§‹
        if self.tracker:
            self.tracker.start_optimization_tracking()

        start_time = time.time()

        # æœ€é©åŒ–å®Ÿè¡Œ
        best_individual = self.optimizer.optimize(
            training_data=self.training_data,
            target_values=self.target_values,
            validation_data=self.validation_data,
            validation_targets=self.validation_targets,
            feature_names=self.feature_names
        )

        end_time = time.time()
        optimization_time = end_time - start_time

        # è¿½è·¡çµ‚äº†
        if self.tracker:
            self.tracker.finish_optimization_tracking()

        self.best_individual = best_individual

        logger.info("ğŸ‰ éºä¼çš„æœ€é©åŒ–å®Œäº†!")
        logger.info(f"â±ï¸ å®Ÿè¡Œæ™‚é–“: {optimization_time:.2f}ç§’")
        logger.info(
            f"ğŸ† æœ€è‰¯é©å¿œåº¦: {best_individual.fitness_components.overall:.4f}")
        logger.info(f"ğŸ“Š é©å¿œåº¦è©³ç´°:")
        logger.info(
            f"   ç²¾åº¦: {best_individual.fitness_components.accuracy:.4f}")
        logger.info(
            f"   å˜ç´”æ€§: {best_individual.fitness_components.simplicity:.4f}")
        logger.info(
            f"   è§£é‡ˆå¯èƒ½æ€§: {best_individual.fitness_components.interpretability:.4f}")

        return best_individual

    def evaluate_model(self, individual: GeneticIndividual) -> Dict[str, Any]:
        """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡"""

        logger.info("ğŸ“Š ãƒ¢ãƒ‡ãƒ«è©³ç´°è©•ä¾¡é–‹å§‹...")

        evaluation_results = {}

        # åŸºæœ¬æ€§èƒ½è©•ä¾¡
        train_predictions = []
        val_predictions = []

        # è¨“ç·´ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬
        for i in range(len(self.training_data)):
            feature_vector = self.training_data.iloc[i].values.tolist()
            prediction = individual.tree.predict(
                feature_vector, self.feature_names)
            train_predictions.append(prediction)

        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§ã®äºˆæ¸¬
        for i in range(len(self.validation_data)):
            feature_vector = self.validation_data.iloc[i].values.tolist()
            prediction = individual.tree.predict(
                feature_vector, self.feature_names)
            val_predictions.append(prediction)

        # æ€§èƒ½æŒ‡æ¨™è¨ˆç®—
        from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

        train_mse = mean_squared_error(self.target_values, train_predictions)
        train_mae = mean_absolute_error(self.target_values, train_predictions)
        train_r2 = r2_score(self.target_values, train_predictions)

        val_mse = mean_squared_error(self.validation_targets, val_predictions)
        val_mae = mean_absolute_error(self.validation_targets, val_predictions)
        val_r2 = r2_score(self.validation_targets, val_predictions)

        evaluation_results['performance_metrics'] = {
            'train': {'mse': train_mse, 'mae': train_mae, 'r2': train_r2},
            'validation': {'mse': val_mse, 'mae': val_mae, 'r2': val_r2}
        }

        # æ§‹é€ åˆ†æ
        node_count = self._count_nodes(individual.tree)
        tree_depth = self._calculate_depth(individual.tree)
        leaf_count = self._count_leaves(individual.tree)

        evaluation_results['structure_analysis'] = {
            'node_count': node_count,
            'tree_depth': tree_depth,
            'leaf_count': leaf_count,
            'balance_ratio': leaf_count / max(1, node_count - leaf_count)
        }

        # ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ
        feature_importance = self._analyze_feature_importance(individual.tree)
        evaluation_results['feature_importance'] = feature_importance

        logger.info("âœ… ãƒ¢ãƒ‡ãƒ«è©•ä¾¡å®Œäº†")
        logger.info(f"ğŸ“ˆ æ¤œè¨¼RÂ²ã‚¹ã‚³ã‚¢: {val_r2:.4f}")
        logger.info(f"ğŸŒ³ æœ¨æ§‹é€ : {node_count}ãƒãƒ¼ãƒ‰, æ·±åº¦{tree_depth}")

        return evaluation_results

    def generate_explanations(self, individual: GeneticIndividual) -> Dict[str, Any]:
        """èª¬æ˜ç”Ÿæˆ"""

        logger.info("ğŸ’¡ èª¬æ˜ç”Ÿæˆé–‹å§‹...")

        explanations = {}

        # ã‚µãƒ³ãƒ—ãƒ«ã‚±ãƒ¼ã‚¹ã§ã®èª¬æ˜ç”Ÿæˆ
        sample_indices = np.random.choice(
            len(self.validation_data),
            size=min(5, len(self.validation_data)),
            replace=False
        )

        sample_explanations = []

        for idx in sample_indices:
            feature_vector = self.validation_data.iloc[idx].values.tolist()
            actual_value = self.validation_targets[idx]

            # èª¬æ˜ä»˜ãäºˆæ¸¬
            prediction, explanation = individual.tree.predict_with_explanation(
                feature_vector, self.feature_names
            )

            # åŒ…æ‹¬çš„èª¬æ˜ç”Ÿæˆ
            comprehensive_explanation = self.explanation_engine.generate_comprehensive_explanation(
                prediction=prediction,
                explanation=explanation,
                feature_vector=feature_vector,
                feature_names=self.feature_names,
                decision_tree=individual.tree,
                context={'actual_value': actual_value, 'sample_index': idx}
            )

            sample_explanations.append({
                'sample_index': idx,
                'prediction': prediction,
                'actual_value': actual_value,
                'error': abs(prediction - actual_value),
                'explanation': comprehensive_explanation
            })

        explanations['sample_explanations'] = sample_explanations

        # å…¨ä½“çš„ãªè§£é‡ˆå¯èƒ½æ€§åˆ†æ
        explanations['global_interpretability'] = self._analyze_global_interpretability(
            individual.tree)

        logger.info(f"âœ… èª¬æ˜ç”Ÿæˆå®Œäº†: {len(sample_explanations)}ä»¶ã®ã‚µãƒ³ãƒ—ãƒ«èª¬æ˜")

        return explanations

    def save_results(self,
                     individual: GeneticIndividual,
                     evaluation_results: Dict[str, Any],
                     explanations: Dict[str, Any]):
        """çµæœä¿å­˜"""

        logger.info("ğŸ’¾ çµæœä¿å­˜é–‹å§‹...")

        # ãƒ¢ãƒ‡ãƒ«ä¿å­˜
        if self.config.output_settings['save_model']:
            model_id = self.persistence.save_model(
                genetic_individual=individual,
                optimizer=self.optimizer,
                feature_names=self.feature_names,
                training_sample_count=len(self.training_data),
                validation_sample_count=len(self.validation_data),
                version="1.0",
                tags=['genetic_algorithm',
                      'fuzzy_decision_tree', 'multi_objective'],
                description="éºä¼çš„ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã§æœ€é©åŒ–ã•ã‚ŒãŸãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨"
            )
            logger.info(f"ğŸ“ ãƒ¢ãƒ‡ãƒ«ä¿å­˜å®Œäº†: {model_id}")

        # è¿½è·¡ãƒ‡ãƒ¼ã‚¿ä¿å­˜
        if self.tracker and self.config.tracking_settings['enable_tracking']:
            export_path = self.output_dir / "optimization_history.json"
            self.tracker.export_tracking_data(str(export_path))
            logger.info(f"ğŸ“Š è¿½è·¡ãƒ‡ãƒ¼ã‚¿ä¿å­˜: {export_path}")

        # è©•ä¾¡çµæœä¿å­˜
        results_path = self.output_dir / "evaluation_results.json"
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(evaluation_results, f, indent=2,
                      ensure_ascii=False, default=str)

        # èª¬æ˜ä¿å­˜
        if self.config.output_settings['save_explanations']:
            explanations_path = self.output_dir / "model_explanations.json"
            with open(explanations_path, 'w', encoding='utf-8') as f:
                json.dump(explanations, f, indent=2,
                          ensure_ascii=False, default=str)

        # å¯è¦–åŒ–ä¿å­˜
        if self.config.output_settings['save_plots']:
            self._create_and_save_visualizations(
                individual, evaluation_results)

        logger.info("âœ… çµæœä¿å­˜å®Œäº†")

    def _create_and_save_visualizations(self,
                                        individual: GeneticIndividual,
                                        evaluation_results: Dict[str, Any]):
        """å¯è¦–åŒ–ä½œæˆãƒ»ä¿å­˜"""

        plots_dir = self.output_dir / "plots"
        plots_dir.mkdir(exist_ok=True)

        # 1. é©å¿œåº¦é€²åŒ–ãƒ—ãƒ­ãƒƒãƒˆ
        if self.tracker:
            fitness_plot = self.tracker.create_fitness_evolution_plot()
            if fitness_plot.get('type') == 'plotly':
                import plotly.io as pio
                pio.write_html(
                    fitness_plot['data'],
                    file=str(plots_dir / "fitness_evolution.html")
                )

        # 2. å¤šç›®çš„æœ€é©åŒ–åˆ†æ
        if self.tracker:
            multi_obj_plot = self.tracker.create_multi_objective_analysis()
            if multi_obj_plot.get('type') == 'plotly':
                import plotly.io as pio
                pio.write_html(
                    multi_obj_plot['data'],
                    file=str(plots_dir / "multi_objective_analysis.html")
                )

        # 3. ç‰¹å¾´é‡é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆ
        if 'feature_importance' in evaluation_results:
            self._create_feature_importance_plot(
                evaluation_results['feature_importance'],
                plots_dir / "feature_importance.png"
            )

        # 4. äºˆæ¸¬ vs å®Ÿéš›å€¤ãƒ—ãƒ­ãƒƒãƒˆ
        self._create_prediction_plot(
            individual, plots_dir / "prediction_vs_actual.png")

        logger.info(f"ğŸ“ˆ å¯è¦–åŒ–ä¿å­˜å®Œäº†: {plots_dir}")

    def _create_feature_importance_plot(self, importance_data: Dict, save_path: Path):
        """ç‰¹å¾´é‡é‡è¦åº¦ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ"""

        plt.figure(figsize=(10, 6))

        features = list(importance_data.keys())
        importances = list(importance_data.values())

        # é‡è¦åº¦é †ã§ã‚½ãƒ¼ãƒˆ
        sorted_data = sorted(zip(features, importances),
                             key=lambda x: x[1], reverse=True)
        features, importances = zip(*sorted_data)

        plt.barh(features, importances)
        plt.xlabel('é‡è¦åº¦')
        plt.title('ç‰¹å¾´é‡é‡è¦åº¦')
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()

    def _create_prediction_plot(self, individual: GeneticIndividual, save_path: Path):
        """äºˆæ¸¬ãƒ—ãƒ­ãƒƒãƒˆä½œæˆ"""

        # æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿ã§äºˆæ¸¬
        predictions = []
        for i in range(len(self.validation_data)):
            feature_vector = self.validation_data.iloc[i].values.tolist()
            prediction = individual.tree.predict(
                feature_vector, self.feature_names)
            predictions.append(prediction)

        plt.figure(figsize=(8, 8))
        plt.scatter(self.validation_targets, predictions, alpha=0.6)

        # å¯¾è§’ç·šï¼ˆå®Œç’§ãªäºˆæ¸¬ï¼‰
        min_val = min(min(self.validation_targets), min(predictions))
        max_val = max(max(self.validation_targets), max(predictions))
        plt.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)

        plt.xlabel('å®Ÿéš›å€¤')
        plt.ylabel('äºˆæ¸¬å€¤')
        plt.title('äºˆæ¸¬ vs å®Ÿéš›å€¤')
        plt.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        plt.close()

    def run_complete_pipeline(self) -> Dict[str, Any]:
        """å®Œå…¨ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""

        logger.info("ğŸš€ éºä¼çš„ãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨å­¦ç¿’ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³é–‹å§‹")

        # 1. ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
        self.setup_components()

        # 2. ãƒ‡ãƒ¼ã‚¿æº–å‚™
        X, y, feature_names = self.load_research_lab_data()
        self.prepare_data(X, y, feature_names)

        # 3. æœ€é©åŒ–å®Ÿè¡Œ
        best_individual = self.run_optimization()

        # 4. è©•ä¾¡
        evaluation_results = self.evaluate_model(best_individual)

        # 5. èª¬æ˜ç”Ÿæˆ
        explanations = self.generate_explanations(best_individual)

        # 6. çµæœä¿å­˜
        self.save_results(best_individual, evaluation_results, explanations)

        # æœ€çµ‚ã‚µãƒãƒªãƒ¼
        final_summary = {
            'best_fitness': best_individual.fitness_components.overall,
            'fitness_components': best_individual.fitness_components.to_dict(),
            'performance_metrics': evaluation_results['performance_metrics'],
            'structure_analysis': evaluation_results['structure_analysis'],
            'feature_count': len(self.feature_names),
            'training_samples': len(self.training_data),
            'validation_samples': len(self.validation_data),
            'output_directory': str(self.output_dir)
        }

        logger.info("ğŸ‰ ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œå®Œäº†!")
        logger.info(f"ğŸ“Š æœ€çµ‚é©å¿œåº¦: {final_summary['best_fitness']:.4f}")
        logger.info(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {final_summary['output_directory']}")

        return final_summary

    def _count_nodes(self, node) -> int:
        """ãƒãƒ¼ãƒ‰æ•°ã‚«ã‚¦ãƒ³ãƒˆ"""
        if node is None:
            return 0
        count = 1
        for child in node.children.values():
            count += self._count_nodes(child)
        return count

    def _calculate_depth(self, node) -> int:
        """æœ¨ã®æ·±åº¦è¨ˆç®—"""
        if node is None or node.is_leaf:
            return 1
        max_child_depth = 0
        for child in node.children.values():
            child_depth = self._calculate_depth(child)
            max_child_depth = max(max_child_depth, child_depth)
        return 1 + max_child_depth

    def _count_leaves(self, node) -> int:
        """ãƒªãƒ¼ãƒ•æ•°ã‚«ã‚¦ãƒ³ãƒˆ"""
        if node is None:
            return 0
        if node.is_leaf:
            return 1
        leaf_count = 0
        for child in node.children.values():
            leaf_count += self._count_leaves(child)
        return leaf_count

    def _analyze_feature_importance(self, node) -> Dict[str, float]:
        """ç‰¹å¾´é‡é‡è¦åº¦åˆ†æ"""
        feature_usage = {}

        def _count_usage(current_node):
            if current_node is None or current_node.is_leaf or not current_node.split_info:
                return

            feature_name = current_node.split_info.feature_name
            info_gain = current_node.split_info.information_gain

            feature_usage[feature_name] = feature_usage.get(
                feature_name, 0) + info_gain

            for child in current_node.children.values():
                _count_usage(child)

        _count_usage(node)

        # æ­£è¦åŒ–
        if feature_usage:
            max_importance = max(feature_usage.values())
            if max_importance > 0:
                feature_usage = {k: v / max_importance for k,
                                 v in feature_usage.items()}

        return feature_usage

    def _analyze_global_interpretability(self, node) -> Dict[str, Any]:
        """ã‚°ãƒ­ãƒ¼ãƒãƒ«è§£é‡ˆå¯èƒ½æ€§åˆ†æ"""

        # æ±ºå®šãƒ«ãƒ¼ãƒ«æŠ½å‡º
        rules = []

        def _extract_rules(current_node, path=[]):
            if current_node is None:
                return

            if current_node.is_leaf:
                rules.append({
                    'path': path.copy(),
                    'prediction': current_node.leaf_value,
                    'complexity': len(path)
                })
                return

            if current_node.split_info:
                feature_name = current_node.split_info.feature_name
                for term, child in current_node.children.items():
                    new_path = path + [f"{feature_name} is {term}"]
                    _extract_rules(child, new_path)

        _extract_rules(node)

        # çµ±è¨ˆ
        rule_complexities = [rule['complexity'] for rule in rules]

        return {
            'total_rules': len(rules),
            'avg_rule_complexity': np.mean(rule_complexities) if rule_complexities else 0,
            'max_rule_complexity': max(rule_complexities) if rule_complexities else 0,
            'min_rule_complexity': min(rule_complexities) if rule_complexities else 0,
            'sample_rules': rules[:5]  # æœ€åˆã®5ã¤ã®ãƒ«ãƒ¼ãƒ«
        }


def main():
    """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°"""

    parser = argparse.ArgumentParser(description='éºä¼çš„ãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨å­¦ç¿’')

    parser.add_argument('--config', type=str,
                        help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ (JSON)')
    parser.add_argument('--generations', type=int, default=30,
                        help='ä¸–ä»£æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 30)')
    parser.add_argument('--population_size', type=int, default=50,
                        help='é›†å›£ã‚µã‚¤ã‚º (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 50)')
    parser.add_argument('--crossover_rate', type=float, default=0.8,
                        help='äº¤å‰ç‡ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.8)')
    parser.add_argument('--mutation_rate', type=float, default=0.2,
                        help='çªç„¶å¤‰ç•°ç‡ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 0.2)')
    parser.add_argument('--output_dir', type=str, default='genetic_training_output',
                        help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: genetic_training_output)')
    parser.add_argument('--no_tracking', action='store_true',
                        help='è¿½è·¡ã‚’ç„¡åŠ¹åŒ–')
    parser.add_argument('--no_plots', action='store_true',
                        help='ãƒ—ãƒ­ãƒƒãƒˆç”Ÿæˆã‚’ç„¡åŠ¹åŒ–')

    args = parser.parse_args()

    # è¨­å®šèª­ã¿è¾¼ã¿
    if args.config:
        config = TrainingConfiguration.load_from_file(args.config)
        logger.info(f"ğŸ“‹ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿: {args.config}")
    else:
        config = TrainingConfiguration()

        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ä¸Šæ›¸ã
        config.genetic_parameters.generations = args.generations
        config.genetic_parameters.population_size = args.population_size
        config.genetic_parameters.crossover_rate = args.crossover_rate
        config.genetic_parameters.mutation_rate = args.mutation_rate
        config.output_settings['output_directory'] = args.output_dir
        config.tracking_settings['enable_tracking'] = not args.no_tracking
        config.output_settings['save_plots'] = not args.no_plots

    # è¨­å®šã‚’å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜
    output_dir = Path(config.output_settings['output_directory'])
    output_dir.mkdir(parents=True, exist_ok=True)
    config.save_to_file(str(output_dir / "training_config.json"))

    try:
        # ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ
        pipeline = GeneticTrainingPipeline(config)
        summary = pipeline.run_complete_pipeline()

        # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
        print("\n" + "="*60)
        print("ğŸ‰ éºä¼çš„ãƒ•ã‚¡ã‚¸ã‚£æ±ºå®šæœ¨å­¦ç¿’å®Œäº†!")
        print("="*60)
        print(f"ğŸ† æœ€è‰¯é©å¿œåº¦: {summary['best_fitness']:.4f}")
        print(
            f"ğŸ“Š æ¤œè¨¼RÂ²ã‚¹ã‚³ã‚¢: {summary['performance_metrics']['validation']['r2']:.4f}")
        print(f"ğŸŒ³ æœ¨æ§‹é€ : {summary['structure_analysis']['node_count']}ãƒãƒ¼ãƒ‰")
        print(f"ğŸ“ çµæœ: {summary['output_directory']}")
        print("="*60)

        return 0

    except KeyboardInterrupt:
        logger.info("âŒ ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ã‚ˆã£ã¦ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
        return 1
    except Exception as e:
        logger.error(f"âŒ å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return 1


if __name__ == "__main__":
    exit(main())
